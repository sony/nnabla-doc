

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Parametric Functions &mdash; Neural Network Libraries 1.0.14 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Solvers" href="solver.html" />
    <link rel="prev" title="Functions" href="function.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Neural Network Libraries
          

          
          </a>

          
            
            
              <div class="version">
                1.0.14
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../python.html">Python Package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../installation.html">Python Package Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial.html">Python API Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../command_line_interface.html">Python Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html">Python API Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html">Python API Reference</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="common.html">Common</a></li>
<li class="toctree-l3"><a class="reference internal" href="nd_array.html">NdArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="variable.html">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="function.html">Functions</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Parametric Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-nnabla.parameter">Parameter Management API</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-nnabla.parametric_functions">List of Parametric Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parameter-initializer">Parameter Initializer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="solver.html">Solvers</a></li>
<li class="toctree-l3"><a class="reference internal" href="communicator.html">Communicator API</a></li>
<li class="toctree-l3"><a class="reference internal" href="monitor.html">Monitors</a></li>
<li class="toctree-l3"><a class="reference internal" href="utils.html">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="ext.html">Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="models.html">Pretrained Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="experimental.html">Experimental</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neural Network Libraries</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../python.html">Python Package</a> &raquo;</li>
        
          <li><a href="../api.html">Python API Reference</a> &raquo;</li>
        
      <li>Parametric Functions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/python/api/parametric_function.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="parametric-functions">
<h1>Parametric Functions<a class="headerlink" href="#parametric-functions" title="Permalink to this headline">¶</a></h1>
<p>In NNabla, trainable models are created by composing functions that have optimizable parameters.
These functions are called parametric functions.
Parametric functions are provided by <a class="reference internal" href="#module-nnabla.parametric_functions" title="nnabla.parametric_functions"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nnabla.parametric_functions</span></code></a>.</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><a class="reference external" href="http://nnabla.readthedocs.io/en/latest/python/tutorial/python_api.html">Python API Tutorial</a>.</dd>
</dl>
<div class="section" id="module-nnabla.parameter">
<span id="parameter-management-api"></span><span id="parameter"></span><h2>Parameter Management API<a class="headerlink" href="#module-nnabla.parameter" title="Permalink to this headline">¶</a></h2>
<p>The parameters registered by <a class="reference internal" href="#id1"><span class="std std-ref">List of Parametric Functions</span></a>
can be managed using APIs listed in this section.</p>
<dl class="function">
<dt id="nnabla.parameter.parameter_scope">
<code class="descclassname">nnabla.parameter.</code><code class="descname">parameter_scope</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwds</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#parameter_scope"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.parameter_scope" title="Permalink to this definition">¶</a></dt>
<dd><p>Grouping parameters registered by parametric functions
listed in <a class="reference internal" href="#module-nnabla.parametric_functions" title="nnabla.parametric_functions"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nnabla.parametric_functions</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Parameter scope name.</li>
<li><strong>scope</strong> (<em>OrderedDict</em><em>, </em><em>optional</em>) – Specifiy current parameter scope as a local dictionary.
The default value is <code class="docutils literal notranslate"><span class="pre">None</span></code>. In this case,
the current parameter scope maintained in global is used.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.functions</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;conv1&#39;</span><span class="p">):</span>
    <span class="n">conv_out1</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">bn_out1</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">conv_out1</span><span class="p">)</span>
    <span class="n">act_out1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn_out1</span><span class="p">)</span>
<span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;conv2&#39;</span><span class="p">):</span>
    <span class="n">conv_out2</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">act_out1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">bn_out2</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">conv_out2</span><span class="p">)</span>
    <span class="n">act_out2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn_out2</span><span class="p">)</span>
</pre></div>
</div>
<p>Nesting <cite>with</cite> blocks allows you to nest parameter scopes.
This can also be done by using “/” inside the parameter names.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;network1&#39;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;conv1&#39;</span><span class="p">):</span>
        <span class="n">conv_out1</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">bn_out1</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">conv_out1</span><span class="p">)</span>
        <span class="n">act_out1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn_out1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;conv2&#39;</span><span class="p">):</span>
        <span class="n">conv_out2</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">act_out1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">bn_out2</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">conv_out2</span><span class="p">)</span>
        <span class="n">act_out2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn_out2</span><span class="p">)</span>
</pre></div>
</div>
<p>is equivalent to</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;network1/conv1&#39;</span><span class="p">):</span>
    <span class="n">conv_out1</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">bn_out1</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">conv_out1</span><span class="p">)</span>
    <span class="n">act_out1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn_out1</span><span class="p">)</span>
<span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="s1">&#39;network1/conv2&#39;</span><span class="p">):</span>
    <span class="n">conv_out2</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">act_out1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">bn_out2</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">conv_out2</span><span class="p">)</span>
    <span class="n">act_out2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn_out2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parameter.get_current_parameter_scope">
<code class="descclassname">nnabla.parameter.</code><code class="descname">get_current_parameter_scope</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#get_current_parameter_scope"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.get_current_parameter_scope" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns current parameter scope.</p>
</dd></dl>

<dl class="function">
<dt id="nnabla.parameter.get_parameters">
<code class="descclassname">nnabla.parameter.</code><code class="descname">get_parameters</code><span class="sig-paren">(</span><em>params=None</em>, <em>path=''</em>, <em>grad_only=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#get_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.get_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameter Variables under the current parameter scope.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Internal use. User doesn’t set it manually.</li>
<li><strong>path</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Internal use.  User doesn’t set it manually.</li>
<li><strong>grad_only</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Retrieve all parameters under the current scope if
False, while only parameters with need_grad=True are retrieved
if True.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">{<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a> : <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a>}</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nnabla.parameter.clear_parameters">
<code class="descclassname">nnabla.parameter.</code><code class="descname">clear_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#clear_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.clear_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear all parameters in the current scope.</p>
</dd></dl>

<dl class="function">
<dt id="nnabla.parameter.save_parameters">
<code class="descclassname">nnabla.parameter.</code><code class="descname">save_parameters</code><span class="sig-paren">(</span><em>path</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#save_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.save_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Save all parameters into a file with the specified format.</p>
<p>Currently hdf5 and protobuf formats are supported.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>path</strong> – path or file object</li>
<li><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – Parameters to be saved. Dictionary is of a parameter name (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>) to <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nnabla.parameter.load_parameters">
<code class="descclassname">nnabla.parameter.</code><code class="descname">load_parameters</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#load_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.load_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Load parameters from a file with the specified format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – path or file object</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nnabla.parameter.get_parameter_or_create">
<code class="descclassname">nnabla.parameter.</code><code class="descname">get_parameter_or_create</code><span class="sig-paren">(</span><em>name</em>, <em>shape=None</em>, <em>initializer=None</em>, <em>need_grad=True</em>, <em>as_need_grad=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parameter.html#get_parameter_or_create"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parameter.get_parameter_or_create" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an existing parameter variable with the provided name.
If a variable with the provided name does not exist,
a new variable with the provided name is returned.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The name under the current scope. If it already exists, the name is queried from the
parameter manager.</li>
<li><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Shape of created parameter. The shape of the specified
parameter must match with this shape. The default is None which is only valid if initializer is given as an <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.</li>
<li><strong>initializer</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – An initialization function to be applied to the parameter. <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a> can also be given to initialize parameters from numpy array data.</li>
<li><strong>need_grad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Register the parameter with the specified <code class="docutils literal notranslate"><span class="pre">need_grad</span></code> flag.
The default is True. If the flag is different from the previously
specified one, the flag will be overwritten, but the values will be
kept.</li>
<li><strong>as_need_grad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Get a parameter variable with the specified <code class="docutils literal notranslate"><span class="pre">need_grad</span></code> flag.
Note that this doesn’t overwrite the flag of the registered parameter
variable with the provided name. Instead, if the given flag
mismatches with the previously registered <code class="docutils literal notranslate"><span class="pre">need_grad</span></code> flag, it
returns a new variable referring to the same array contents but with
<code class="docutils literal notranslate"><span class="pre">need_grad=as_need_grad</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nnabla.parametric_functions">
<span id="list-of-parametric-functions"></span><span id="id1"></span><h2>List of Parametric Functions<a class="headerlink" href="#module-nnabla.parametric_functions" title="Permalink to this headline">¶</a></h2>
<p>Parametric functions are provided by <a class="reference internal" href="#module-nnabla.parametric_functions" title="nnabla.parametric_functions"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nnabla.parametric_functions</span></code></a> , as listed below.
Like functions listed in <a class="reference internal" href="function.html#functions"><span class="std std-ref">Functions</span></a>, they take <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a> (s) as
first argument(s) followed by options specific to a parametric function. In addition,
they register parameter <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a> (s) into the parameter scope.</p>
<p>The parameter variables are registered with <code class="docutils literal notranslate"><span class="pre">need_grad</span></code> properties specific
to a parametric function. The variables with <code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code> flag will not
be updated by gradient descent. Hence, backward computation is not executed for
those variables. <code class="docutils literal notranslate"><span class="pre">False</span></code> is usually specified when the parameters are updated
during foward pass and/or backward pass, e.g., batch normalization.</p>
<p>All parametric functions take an optional argument <code class="docutils literal notranslate"><span class="pre">fix_parameters=False</span></code>.
By giving <code class="docutils literal notranslate"><span class="pre">True</span></code>, the associated parameter variables are connected to a
computation graph with a property <code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code> regardless properties
of the registered variables, then backward gradient
computation is not executed for those variables. This is useful when you create
a computation graph for evaluation purpose, fixing parameters partially in a
graph, and so on.</p>
<p>All parametric functions listed below are decorated with the following decorator.</p>
<dl class="function">
<dt id="nnabla.parametric_functions.parametric_function_api">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">parametric_function_api</code><span class="sig-paren">(</span><em>scope_name=None</em>, <em>param_desc=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#parametric_function_api"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.parametric_function_api" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator for parametric functions.</p>
<p>The decorated function is always called under
a parameter scope <code class="docutils literal notranslate"><span class="pre">scope_name</span></code>.
Also, the decorator adds an additional argument <code class="docutils literal notranslate"><span class="pre">name</span></code> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>,
default is <code class="docutils literal notranslate"><span class="pre">None</span></code>) at the end. If <code class="docutils literal notranslate"><span class="pre">name</span></code> is specified, the
scope <code class="docutils literal notranslate"><span class="pre">scope_name</span></code> comes under a scope <code class="docutils literal notranslate"><span class="pre">name</span></code>. This feature
could reduce vertical space usage of the source code.
Any parametric function should be decorated by this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scope_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>optional</em>) – The original function will be called
under a parameter scope named by <code class="docutils literal notranslate"><span class="pre">scope_name</span></code>.</li>
<li><strong>param_desc</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>, </em><em>optional</em>) – Descriptions of parameters will be automatically included into docstring.
This must be a list of tuples with 4 elements composed of
(name (str), description (str), shape info (str), need_grad (bool)).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A decorated parametric function.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">function</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>See <a class="reference internal" href="#parameter"><span class="std std-ref">Parameter Management API</span></a> to know how to query and manipulate registered variables.</p>
<p>Here is the list of parametric functions.</p>
<dl class="function">
<dt id="nnabla.parametric_functions.affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.affine" title="Permalink to this definition">¶</a></dt>
<dd><p>The affine layer, also known as the fully connected layer. Computes</p>
<div class="math notranslate nohighlight">
\[{\mathbf y} = {\mathbf A} {\mathbf x} + {\mathbf b}.\]</div>
<p>where <span class="math notranslate nohighlight">\({\mathbf x}, {\mathbf y}\)</span> are the inputs and outputs respectively,
and <span class="math notranslate nohighlight">\({\mathbf A}, {\mathbf b}\)</span> are constants.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it is a matrix.</li>
<li><strong>n_outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a> or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array. (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)f</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outputs,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>N-D Convolution with a bias term.</p>
<p>For Dilated Convolution (a.k.a. Atrous Convolution), refer to:</p>
<ul class="simple">
<li>Chen et al., DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. <a class="reference external" href="https://arxiv.org/abs/1606.00915">https://arxiv.org/abs/1606.00915</a></li>
<li>Yu et al., Multi-Scale Context Aggregation by Dilated Convolutions. <a class="reference external" href="https://arxiv.org/abs/1511.07122">https://arxiv.org/abs/1511.07122</a></li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Convolution is a computationally intensive operation that
should preferrably be run with the <cite>cudnn</cite> backend. NNabla
then uses CuDNN library functions to determine and cache the
fastest algorithm for the given set of convolution parameters,
which results in additional memory consumption which may pose
a problem for GPUs with insufficient memory size. In that
case, the <cite>NNABLA_CUDNN_WORKSPACE_LIMIT</cite> environment variable
can be used to restrict the choice of algorithms to those that
fit the given workspace memory limit, expressed in bytes. In
some cases it may also be desired to restrict the automatic
search to algorithms that produce deterministic (reproducable)
results. This can be requested by setting the the environment
variable <cite>NNABLA_CUDNN_DETERMINISTIC</cite> to a non-zero value.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels more sparse by grouping connections along map direction.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array. See <a class="reference internal" href="function.html#nnabla.functions.convolution" title="nnabla.functions.convolution"><code class="xref py py-obj docutils literal notranslate"><span class="pre">convolution</span></code></a> for the output shape.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.depthwise_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">depthwise_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>multiplier=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#depthwise_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.depthwise_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>N-D Depthwise Convolution with a bias term.</p>
<p>Reference:</p>
<ul class="simple">
<li><ol class="first upperalpha" start="6">
<li>Chollet: Chollet, Francois. “Xception: Deep Learning with Depthwise Separable Convolutions. <a class="reference external" href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a></li>
</ol>
</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>multiplier</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output feature maps per input feature map.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight.  By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array. See <a class="reference internal" href="function.html#nnabla.functions.depthwise_convolution" title="nnabla.functions.depthwise_convolution"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_convolution</span></code></a> for the output shape.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;depthwise_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps</span> <span class="pre">*</span> <span class="pre">multiplier,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps</span> <span class="pre">*</span> <span class="pre">multiplier,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">depthwise_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.deconvolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">deconvolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#deconvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.deconvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Deconvolution layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of deconvolution kernels (which is equal to the number of output channels). For example, to apply deconvolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply deconvolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array. See <a class="reference internal" href="function.html#nnabla.functions.deconvolution" title="nnabla.functions.deconvolution"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deconvolution</span></code></a> for the output shape.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;deconv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">deconvolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.depthwise_deconvolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">depthwise_deconvolution</code><span class="sig-paren">(</span><em>inp</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>divisor=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#depthwise_deconvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.depthwise_deconvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Depthwise deconvolution computes the transposed depthwise
convolution for one-dimensional and two-dimensional input data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>divisor</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of input feature maps per output feature map.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array. See <a class="reference internal" href="function.html#nnabla.functions.depthwise_deconvolution" title="nnabla.functions.depthwise_deconvolution"><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_deconvolution</span></code></a> for the output shape.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;depthwise_deconv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,)</span> <span class="pre">+</span> <span class="pre">kernel</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps</span> <span class="pre">/</span> <span class="pre">divisor,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">depthwise_deconvolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.batch_normalization">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">batch_normalization</code><span class="sig-paren">(</span><em>inp, axes=[1], decay_rate=0.9, eps=1e-05, batch_stat=True, output_stat=False, fix_parameters=False, param_init=None, name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#batch_normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.batch_normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch normalization layer.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{lcl}
\mu &amp;=&amp; \frac{1}{M} \sum x_i\\
\sigma^2 &amp;=&amp; \frac{1}{M} \left(\sum x_i - \mu\right)^2\\
\hat{x}_i &amp;=&amp; \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon }}\\
y_i &amp;= &amp; \hat{x}_i \gamma + \beta.
\end{array}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i, y_i\)</span> are the inputs.
In testing, the mean and variance computed by moving average calculated during training are used.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array of input.</li>
<li><strong>axes</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Mean and variance for each element in <code class="docutils literal notranslate"><span class="pre">axes</span></code> are calculated using
elements on the rest axes. For example, if an input is 4 dimensions,
and <code class="docutils literal notranslate"><span class="pre">axes</span></code> is <code class="docutils literal notranslate"><span class="pre">[1]</span></code>,  batch mean is calculated as
<code class="docutils literal notranslate"><span class="pre">np.mean(inp.d,</span> <span class="pre">axis=(0,</span> <span class="pre">2,</span> <span class="pre">3),</span> <span class="pre">keepdims=True)</span></code>
(using numpy expression as an example).</li>
<li><strong>decay_rate</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Decay rate of running mean and variance.</li>
<li><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Tiny value to avoid zero division by std.</li>
<li><strong>batch_stat</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use mini-batch statistics rather than running ones.</li>
<li><strong>output_stat</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Output batch mean and variance.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the beta and gamma will not be updated.</li>
<li><strong>param_init</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Parameter initializers can be set with a dict. A key of the dict must
be <code class="docutils literal notranslate"><span class="pre">'beta'</span></code>, <code class="docutils literal notranslate"><span class="pre">'gamma'</span></code>, <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> or <code class="docutils literal notranslate"><span class="pre">'var'</span></code>.
A value of the dict must be an <code class="xref py py-obj docutils literal notranslate"><span class="pre">Initializer</span></code>
or a <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.
E.g. <code class="docutils literal notranslate"><span class="pre">{'beta':</span> <span class="pre">ConstantIntializer(0),</span> <span class="pre">'gamma':</span> <span class="pre">np.ones(gamma_shape)</span> <span class="pre">*</span> <span class="pre">2}</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<ul class="simple">
<li>Ioffe and Szegedy, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. <a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a></li>
</ul>
<p>The shape of parameters has the same number of dimensions with the input
data, and the shapes in <code class="docutils literal notranslate"><span class="pre">axes</span></code> has the same dimensions with the input, while the rest has <code class="docutils literal notranslate"><span class="pre">1</span></code>.
If an input is 4-dim and <code class="docutils literal notranslate"><span class="pre">axes=[1]</span></code>, the parameter shape will be
<code class="docutils literal notranslate"><span class="pre">param_shape</span>&#160; <span class="pre">=</span> <span class="pre">np.mean(inp.d,</span> <span class="pre">axis=(0,</span> <span class="pre">2,</span> <span class="pre">3),</span> <span class="pre">keepdims=True).shape</span></code>
(using numpy expression as an example).</p>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;bn&quot;</span></code>;</p>
<ul class="last simple">
<li>beta (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Trainable bias <span class="math notranslate nohighlight">\(\beta\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">&lt;see</span> <span class="pre">above&gt;</span></code>)</li>
<li>gamma (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Trainable scaling factor <span class="math notranslate nohighlight">\(\gamma\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">&lt;see</span> <span class="pre">above&gt;</span></code>)</li>
<li>mean (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Moving average of batch mean. (shape: <code class="docutils literal notranslate"><span class="pre">&lt;see</span> <span class="pre">above&gt;</span></code>)</li>
<li>var (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Moving average of batch variance. (shape: <code class="docutils literal notranslate"><span class="pre">&lt;see</span> <span class="pre">above&gt;</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">batch_normalization</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.mean_subtraction">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">mean_subtraction</code><span class="sig-paren">(</span><em>inp</em>, <em>base_axis=1</em>, <em>update_running_mean=True</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#mean_subtraction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.mean_subtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean subtraction layer.</p>
<p>It subtracts the mean of the elements of the input array,
and normalizes it to <span class="math notranslate nohighlight">\(0\)</span>. Preprocessing arrays with this function has the effect of improving accuracy
in various tasks such as image classification.</p>
<p>At training time, this function is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{lcl}
\mu &amp;=&amp; \frac{1}{M} \sum x_i \\
y_i &amp;=&amp; x_i - \mu
\end{array}\end{split}\]</div>
<p>At testing time, the mean values used are those that were computed during training by moving average.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The backward performs an approximated differentiation that takes into account only the latest mini-batch.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array of input.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Base axis of Mean Subtraction operation. Dimensions up to base_axis is treated as sample dimension.</li>
<li><strong>update_running_mean</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the running mean will not be updated.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – dummy parameter. This argument dose not affect anything.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;mean_subtraction&quot;</span></code>;</p>
<ul class="last simple">
<li>mean (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Moving average. (shape: <code class="docutils literal notranslate"><span class="pre">inp.shape[base_axis:]</span></code>)</li>
<li>t (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Minibatch counter used in forward pass. (shape: <code class="docutils literal notranslate"><span class="pre">(1,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">mean_subtraction</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.rnn">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">rnn</code><span class="sig-paren">(</span><em>x</em>, <em>h</em>, <em>w0_init=None</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>num_layers=1</em>, <em>nonlinearity='tanh'</em>, <em>dropout=0.0</em>, <em>bidirectional=False</em>, <em>training=True</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#rnn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.rnn" title="Permalink to this definition">¶</a></dt>
<dd><p>N-Step RNN (recurrent neural networks).</p>
<p>N-Step RNN function implements Elman RNN with nonlineraity to input sequence.
N-Step RNN function is defined as following:</p>
<div class="math notranslate nohighlight">
\[h_t = \tanh(w_{ih}x_t+b_{ih}+w_{hh}h_{(t-1)}).\]</div>
<p>We use the following notations to describe the inputs and outputs below.
<span class="math notranslate nohighlight">\(T\)</span>: sequcne length, <span class="math notranslate nohighlight">\(B\)</span>: batch size, <span class="math notranslate nohighlight">\(I\)</span>: input size, <span class="math notranslate nohighlight">\(L\)</span>: number of layers, <span class="math notranslate nohighlight">\(D\)</span>: number of directions, can be either 1 or 2, <span class="math notranslate nohighlight">\(H\)</span>: hidden size.</p>
<p class="rubric">References</p>
<p>Jeffrey L. Elman. “Finding Structure in Time.”
Cognitive Science. 1990.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((T, B, I)\)</span>.</li>
<li><strong>h</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span>.</li>
<li><strong>w0_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weight at the first layer. Shape is <span class="math notranslate nohighlight">\((D, H, I + H)\)</span>.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weights at the second layer and up. Shape is <span class="math notranslate nohighlight">\((L-1, D, H, D*H + H)\)</span>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for bias. Shape is <span class="math notranslate nohighlight">\((L, D, H)\)</span>.</li>
<li><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>optional</em>) – Number of layers in the network. If set to 1, only the weights for the first layer will be invoked. Default is 1.</li>
<li><strong>nonlinearity</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>optional</em>) – Type of nonlinearity applied to input sequcne. Must be either tanh or relu. Default is tanh.</li>
<li><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout ratio applied to parameters. Default is 0.0.</li>
<li><strong>bidirectional</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, bidirectional computation will be performed in each layer. Default is False.</li>
<li><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Backpropagation will be performed only when it is true. Default is True.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Output <span class="math notranslate nohighlight">\(y\)</span> with shape <span class="math notranslate nohighlight">\((T, B, D * H)\)</span>
~nnabla.Variable: Output <span class="math notranslate nohighlight">\(h_n\)</span> with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_directions</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
<span class="n">y</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.lstm">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">lstm</code><span class="sig-paren">(</span><em>x</em>, <em>h</em>, <em>c</em>, <em>w0_init=None</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>num_layers=1</em>, <em>dropout=0.0</em>, <em>bidirectional=False</em>, <em>training=True</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#lstm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.lstm" title="Permalink to this definition">¶</a></dt>
<dd><p>LSTM (long short-term memory).</p>
<p>Long Short-Term Memory, or LSTM, is a building block for recurrent neural networks (RNN) layers.
LSTM unit consists of a cell and input, output, forget gates whose functions are defined as following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f_t&amp;&amp;=\sigma(W_fx_t+U_fh_{t-1}+b_f) \\
i_t&amp;&amp;=\sigma(W_ix_t+U_ih_{t-1}+b_i) \\
o_t&amp;&amp;=\sigma(W_ox_t+U_oh_{t-1}+b_o) \\
c_t&amp;&amp;=f_t\odot c_{t-1}+i_t\odot\tanh(W_cx_t+U_ch_{t-1}+b_c) \\
h_t&amp;&amp;=o_t\odot\tanh(c_t).\end{split}\]</div>
<p>We use the following notations to describe the inputs and outputs below.
<span class="math notranslate nohighlight">\(T\)</span>: sequcne length, <span class="math notranslate nohighlight">\(B\)</span>: batch size, <span class="math notranslate nohighlight">\(I\)</span>: input size, <span class="math notranslate nohighlight">\(L\)</span>: number of layers, <span class="math notranslate nohighlight">\(D\)</span>: number of directions, can be either 1 or 2, <span class="math notranslate nohighlight">\(H\)</span>: hidden size.</p>
<p class="rubric">References</p>
<p>S. Hochreiter, and J. Schmidhuber. “Long Short-Term Memory.”
Neural Computation. 1997.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((T, B, I)\)</span>.</li>
<li><strong>h</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span>.</li>
<li><strong>c</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span> .</li>
<li><strong>w0_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weight at the first layer. Shape is <span class="math notranslate nohighlight">\((D, 4, H, I + H)\)</span>.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weights at the second layer and up. Shape is <span class="math notranslate nohighlight">\((L-1, D, 4, H, D * H + H)\)</span>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for bias. Shape is <span class="math notranslate nohighlight">\((L, D, 4, H)\)</span>.</li>
<li><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>optional</em>) – Number of layers in the network. If set to 1, only the weights for the first layer will be invoked. Default is 1.</li>
<li><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout ratio applied to parameters. Default is 0.0.</li>
<li><strong>bidirectional</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, bidirectional computation will be performed in each layer. Default is False.</li>
<li><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Backpropagation will be performed only when it is true. Default is True.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Specify whether to include the bias term.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Output <span class="math notranslate nohighlight">\(y\)</span> with shape <span class="math notranslate nohighlight">\((T, B, D * H)\)</span>
~nnabla.Variable: Output <span class="math notranslate nohighlight">\(h_n\)</span> with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span>
~nnabla.Variable: Output <span class="math notranslate nohighlight">\(c_n\)</span> with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_directions</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_directions</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
<span class="n">y</span><span class="p">,</span> <span class="n">hn</span><span class="p">,</span> <span class="n">cn</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.gru">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">gru</code><span class="sig-paren">(</span><em>x</em>, <em>h</em>, <em>w0_init=None</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>num_layers=1</em>, <em>dropout=0.0</em>, <em>bidirectional=False</em>, <em>training=True</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#gru"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.gru" title="Permalink to this definition">¶</a></dt>
<dd><p>GRU (gated recurrent units).</p>
<p>GRU is defined as following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}r_t&amp;&amp;=\sigma(W_rx_t+U_rh_{t-1}+b_r) \\
z_t&amp;&amp;=\sigma(W_zx_t+U_zh_{t-1}+b_z) \\
n_t&amp;&amp;=\tanh(W_nx_t+b_{in}+r_n(U_nh_{t-1}+b_{hn})) \\
h_t&amp;&amp;=(1-z_t)n_t+z_th_{t-1}.\end{split}\]</div>
<p>We use the following notations to describe the inputs and outputs below.
<span class="math notranslate nohighlight">\(T\)</span>: sequcne length, <span class="math notranslate nohighlight">\(B\)</span>: batch size, <span class="math notranslate nohighlight">\(I\)</span>: input size, <span class="math notranslate nohighlight">\(L\)</span>: number of layers, <span class="math notranslate nohighlight">\(D\)</span>: number of directions, can be either 1 or 2, <span class="math notranslate nohighlight">\(H\)</span>: hidden size.</p>
<p class="rubric">References</p>
<p>K. Cho et al. “Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.”
Empirical Methods in Natural Language Processing. 2014.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((T, B, I)\)</span>.</li>
<li><strong>h</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span>.</li>
<li><strong>w0_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weight at the first layer. Shape is <span class="math notranslate nohighlight">\((D, 3, H, I + H)\)</span>.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weights at the second layer and up. Shape is <span class="math notranslate nohighlight">\((L-1, D, 3, H, D * H + H)\)</span>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for bias. Shape is <span class="math notranslate nohighlight">\((L, D, 4, H)\)</span>.</li>
<li><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>optional</em>) – Number of layers in the network. If set to 1, only the weights for the first layer will be invoked. Default is 1.</li>
<li><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout ratio applied to parameters. Default is 0.0.</li>
<li><strong>bidirectional</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, bidirectional computation will be performed in each layer. Default is False.</li>
<li><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Backpropagation will be performed only when it is true. Default is True.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Output <span class="math notranslate nohighlight">\(y\)</span> with shape <span class="math notranslate nohighlight">\((T, B, D * H)\)</span>
~nnabla.Variable: Output <span class="math notranslate nohighlight">\(h_n\)</span> with shape <span class="math notranslate nohighlight">\((L, D, B, H)\)</span></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_directions</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
<span class="n">y</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">gru</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.embed">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">embed</code><span class="sig-paren">(</span><em>inp</em>, <em>n_inputs</em>, <em>n_features</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#embed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.embed" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed.</p>
<p>Embed slices a matrix/tensor with indexing array/tensor. Weights are initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range of <span class="math notranslate nohighlight">\(-\sqrt{3}\)</span> and <span class="math notranslate nohighlight">\(\sqrt{3}\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – [Integer] Indices with shape <span class="math notranslate nohighlight">\((I_0, ..., I_N)\)</span></li>
<li><strong>n_inputs</strong> – number of possible inputs, words or vocabraries</li>
<li><strong>n_features</strong> – number of embedding features</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the embedding weight matrix
will not be updated.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Output with shape <span class="math notranslate nohighlight">\((I_0, ..., I_N, W_1, ..., W_M)\)</span></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;embed&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Embedding matrix. (shape: <code class="docutils literal notranslate"><span class="pre">(n_inputs,</span> <span class="pre">n_features)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.prelu">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">prelu</code><span class="sig-paren">(</span><em>inp</em>, <em>base_axis=1</em>, <em>shared=True</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#prelu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.prelu" title="Permalink to this definition">¶</a></dt>
<dd><p>Parametrized Rectified Linear Unit function defined as</p>
<div class="math notranslate nohighlight">
\[y_i = \max(0, x_i) + w_i \min(0, -x_i)\]</div>
<p>where negative slope <span class="math notranslate nohighlight">\(w\)</span> is learned and can vary across channels (an
axis specified with base_axis). Weights are initialized with <span class="math notranslate nohighlight">\(-1\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array as input</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to base_axis is treated as sample dimension.</li>
<li><strong>shared</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use shared weight value or not</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the negative slope values
will not be updated.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;prelu&quot;</span></code>;</p>
<ul class="last simple">
<li>slope (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Negative slope. (shape: <code class="docutils literal notranslate"><span class="pre">tuple()</span> <span class="pre">if</span> <span class="pre">shared</span> <span class="pre">else</span> <span class="pre">(inp.shape[base_axis],)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">prelu</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.svd_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">svd_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>r</em>, <em>base_axis=1</em>, <em>uv_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#svd_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.svd_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>SVD affine is a low rank approximation of the affine layer. It can
be seen as two consecutive affine layers with a bottleneck. It
computes:</p>
<div class="math notranslate nohighlight">
\[{\mathbf y} = {\mathbf U} {\mathbf V} {\mathbf x} + {\mathbf b}.\]</div>
<p>where <span class="math notranslate nohighlight">\({\mathbf x}, {\mathbf y}\)</span> are the inputs and
outputs respectively, and <span class="math notranslate nohighlight">\({\mathbf U}, {\mathbf V},
{\mathbf b}\)</span> are constants.</p>
<p>The weights <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and <span class="math notranslate nohighlight">\({\mathbf V}\)</span> are
approximated with singular value decomposition (SVD) of the
original weight matrix <span class="math notranslate nohighlight">\({\mathbf W}\)</span> and by selecting the
<span class="math notranslate nohighlight">\({R}\)</span> dominant singular values and the corresponding
singular vectors. Therefore the low rank <span class="math notranslate nohighlight">\({R}\)</span> is the size
of the bottleneck.</p>
<p>If <cite>uv_init</cite> is a numpy array, <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and
<span class="math notranslate nohighlight">\({\mathbf V}\)</span> are computed such that <cite>uv_init</cite> is
approximated by <span class="math notranslate nohighlight">\({\mathbf{UV}}\)</span>. If <cite>uv_init</cite> is <cite>None</cite> or
an initializer, the product of <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and
<span class="math notranslate nohighlight">\({\mathbf V}\)</span> approximates the random initialization.</p>
<p>If <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and <span class="math notranslate nohighlight">\({\mathbf V}\)</span> exist in the context,
they take precedence over <cite>uv_init</cite>.</p>
<p>Suppose the weight of the affine is of <span class="math notranslate nohighlight">\({I \times O}\)</span> and
the compression rate you want to specify is <span class="math notranslate nohighlight">\({CR}\)</span>, then you
set <span class="math notranslate nohighlight">\({R}\)</span> as</p>
<div class="math notranslate nohighlight">
\[R = \left\lfloor \frac{(1 - CR)OI}{O + I} \right\rfloor.\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0
\times \ldots \times M_{B-1} \times D_B \times \ldots
\times D_N\)</span>). Dimensions before and after base_axis are
flattened as if it is a matrix.</li>
<li><strong>n_outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – Number of output neurons per data.</li>
<li><strong>r</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – rank of the factorized layer (size of the bottleneck)</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as
the sample dimensions.</li>
<li><strong>uv_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights
and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array.
(<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable">Variable</a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;svd_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>U (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : <span class="math notranslate nohighlight">\({\mathbf U}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">r)</span></code>)</li>
<li>V (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : <span class="math notranslate nohighlight">\({\mathbf V}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">svd_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.svd_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">svd_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>r</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>uv_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#svd_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.svd_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>SVD convolution is a low rank approximation of the convolution
layer. It can be seen as a depth wise convolution followed by a
1x1 convolution.</p>
<p>The flattened kernels for the i-th input map are expressed by
their low rank approximation. The kernels for the i-th input
<span class="math notranslate nohighlight">\({\mathbf W_i}\)</span> are approximated with the singular value
decomposition (SVD) and by selecting the <span class="math notranslate nohighlight">\({R}\)</span> dominant
singular values and the corresponding singular vectors.</p>
<div class="math notranslate nohighlight">
\[{\mathbf W_{:,i,:}} ~ {\mathbf U_i} {\mathbf V_i}.\]</div>
<p><span class="math notranslate nohighlight">\({\mathbf U}\)</span> contains the weights of the depthwise
convolution with multiplier <span class="math notranslate nohighlight">\({R}\)</span> and <span class="math notranslate nohighlight">\({\mathbf V}\)</span>
contains the weights of the 1x1 convolution.</p>
<p>If <cite>uv_init</cite> is a numpy array, <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and
<span class="math notranslate nohighlight">\({\mathbf V}\)</span> are computed such that <cite>uv_init</cite> is
approximated by <span class="math notranslate nohighlight">\({\mathbf{UV}}\)</span>. If <cite>uv_init</cite> is <cite>None</cite> or
an initializer, the product of <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and
<span class="math notranslate nohighlight">\({\mathbf V}\)</span> approximates the random initialization.</p>
<p>If <span class="math notranslate nohighlight">\({\mathbf U}\)</span> and <span class="math notranslate nohighlight">\({\mathbf V}\)</span> exist in the
context, they take precedence over <cite>uv_init</cite>.</p>
<p>Suppose the kernel tensor of the convolution is of <span class="math notranslate nohighlight">\({O \times I \times K \times K}\)</span> and
the compression rate you want to specify is <span class="math notranslate nohighlight">\({CR}\)</span>, then you
set <span class="math notranslate nohighlight">\({R}\)</span> as</p>
<div class="math notranslate nohighlight">
\[R = \left\lfloor \frac{(1 - CR)OIK^2}{I(O + K^2)} \right\rfloor.\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal
to the number of output channels). For example, to apply
convolution on an input with 16 types of filters, specify
16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – Convolution kernel size. For example,
to apply convolution on an image with a 3 (height) by 5
(width) two-dimensional kernel, specify (3, 5).</li>
<li><strong>r</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Rank of the factorized layer.</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – Padding sizes (<cite>int</cite>) for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – Stride sizes (<cite>int</cite>) for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – Dilation sizes (<cite>int</cite>) for dimensions.</li>
<li><strong>uv_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the
sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and
biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array.
(<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;svd_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>U (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Decomposed filter weights <span class="math notranslate nohighlight">\({\mathbf U}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps</span> <span class="pre">*</span> <span class="pre">r,</span> <span class="pre">*kernel)</span></code>)</li>
<li>V (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Decomposed filter weights <span class="math notranslate nohighlight">\({\mathbf V}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">*</span> <span class="pre">r,</span> <span class="pre">1,</span> <span class="pre">...)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">svd_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.cpd3_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">cpd3_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>r</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>oik_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>max_iter=500</em>, <em>stopping_criterion=1e-05</em>, <em>lambda_reg=0.0</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#cpd3_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.cpd3_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>CP convolution is a low rank approximation of a convolution layer. A 3D tensor containing the parameter is built by collapsing the N-D kernels into 1D, then the tensor is decomposed into three matrices. The decomposed layer can be seen as linear combinations of the input feature maps to <span class="math notranslate nohighlight">\({R}\)</span> feature maps followed by a depthwise convolution and followed by linear combinations of the feature maps to compute the output feature maps.</p>
<p>The CP decomposition allows to approximate the kernel tensor by <span class="math notranslate nohighlight">\({R}\)</span> rank-1 tensors of the form:</p>
<div class="math notranslate nohighlight">
\[\sum_{r=1}^{R} \lambda_r {\mathbf{o}^{(r)} \otimes \mathbf{i}^{(r)} \otimes \mathbf{k}^{(r)}},\]</div>
<p>where <span class="math notranslate nohighlight">\({\lambda}_r\)</span> is the normalization coefficient and <span class="math notranslate nohighlight">\({\otimes}\)</span> is the outer product.</p>
<p>If <cite>oik_init</cite> is a numpy array, U and V are computed so that uv_init can be approximates from UV
If <cite>oik_init</cite> is None or an initializer, the product of U and V approximate the randomly initialized array</p>
<p>If <cite>O</cite>, <cite>I</cite> and <cite>K</cite> exist in context, they are used to initialize the layer and oik_init is not used.</p>
<p>Suppose the kernel tensor of the affine is of <span class="math notranslate nohighlight">\({I \times O}\)</span> and
the compression rate you want to specify is <span class="math notranslate nohighlight">\({CR}\)</span>, then you
set <span class="math notranslate nohighlight">\({R}\)</span> as</p>
<div class="math notranslate nohighlight">
\[R = \left\lfloor \frac{(1 - CR)OIK^2}{O + I + K^2} \right\rfloor.\]</div>
<p class="rubric">References</p>
<ul class="simple">
<li>Lebedev, Vadim, Yaroslav Ganin, Maksim Rakhuba, Ivan Oseledets, and Victor Lempitsky,  “Speeding-up convolutional neural networks using fine-tuned cp-decomposition.”, arXiv preprint arXiv:1412.6553 (2014).</li>
<li>Marcella Astrid, Seung-Ik Lee, “CP-decomposition with Tensor Power Method for Convolutional Neural Networks Compression”, BigComp 2017.</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>r</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – rank of the factorized layer</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>oik_init</strong> (numpy array or <a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a>) – Initializer for weight. Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. It is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Max iteration of the ALS.</li>
<li><strong>stopping_criterion</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Threshold for stopping the ALS.
If the value is negative, the convergence check is ignored;
in other words, it may reduce the computation time.</li>
<li><strong>lambda_reg</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – regularization parameter for the ALS. Larger
lambda_reg means larger regularization.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array. (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;cpd3_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>I (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Decomposed filter weights <span class="math notranslate nohighlight">\({\mathbf I}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">inmaps,</span> <span class="pre">1,</span> <span class="pre">...)</span></code>)</li>
<li>K (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Decomposed filter weights <span class="math notranslate nohighlight">\({\mathbf K}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">*kernel)</span></code>)</li>
<li>O (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Decomposed filter weights <span class="math notranslate nohighlight">\({\mathbf O}\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">r,</span> <span class="pre">1,</span> <span class="pre">...)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">cpd3_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.binary_connect_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">binary_connect_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>quantize_zero_to=1.0</em>, <em>w_init=None</em>, <em>wb_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#binary_connect_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.binary_connect_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary Connect Affine, multiplier-less inner-product.</p>
<p>Binary Connect Affine is an affine function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_i = \sum_{i} sign(w_i) x_i.\]</div>
<p>Therefore <span class="math notranslate nohighlight">\(sign(w_i)\)</span> is either <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(-1\)</span> and the inner product
simplifies to addition.</p>
<p>This function should be used together with Batch Normalization.</p>
<p class="rubric">References</p>
<p>M. Courbariaux, Y. Bengio, and J.-P. David. “BinaryConnect:
Training Deep Neural Networks with binary weights during propagations.”
Advances in Neural Information Processing Systems. 2015.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the binarized weights (<cite>binary_weight</cite>)</p>
<p>2) The weights and the binary weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the binary weights will not be in sync.</p>
<p class="last">3) Quantized values are stored as floating point number for <cite>binary_weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it is a matrix.</li>
<li><strong>n_outmaps</strong> (int or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>quantize_zero_to</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Input value at zero is quantized to this value.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>wb_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for binary weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;bicon_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix in floating type. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>Wb (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Binarized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">binary_connect_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.binary_connect_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">binary_connect_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>quantize_zero_to=1.0</em>, <em>w_init=None</em>, <em>wb_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#binary_connect_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.binary_connect_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary Connect Convolution, multiplier-less inner-product.</p>
<p>Binary Connect Convolution is the convolution function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_{n, a, b} = \sum_{m} \sum_{i} \sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}.\]</div>
<p>Therefore <span class="math notranslate nohighlight">\(sign(w_i)\)</span> is either <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(-1\)</span> and the inner product
simplifies to addition.</p>
<p>This function should be used together with BatchNormalization.</p>
<p class="rubric">References</p>
<p>M. Courbariaux, Y. Bengio, and J.-P. David. “BinaryConnect:
Training Deep Neural Networks with binary weights during propagations.”
Advances in Neural Information Processing Systems. 2015.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the binarized weights (<cite>binary_weight</cite>)</p>
<p>2) The weights and the binary weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the binary weights will not be in sync.</p>
<p class="last">3) Quantized values are stored as floating point number for <cite>binary_weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction.</li>
<li><strong>quantize_zero_to</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Input value at zero is quantized to this value.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>wb_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for binary weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;bicon_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps,</span> <span class="pre">*kernel)</span></code>)</li>
<li>Wb (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Binarized filter weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">binary_connect_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.binary_weight_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">binary_weight_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>quantize_zero_to=1.0</em>, <em>w_init=None</em>, <em>wb_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#binary_weight_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.binary_weight_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary Weight Affine, multiplier-less inner-product with a scale factor.</p>
<p>Binary Weight Affine is the affine function, but the inner product
in this function is the following,</p>
<div class="math notranslate nohighlight">
\[y_j = \frac{1}{\|\mathbf{w}_j\|_{\ell_1}} \sum_{i} sign(w_{ji}) x_i\]</div>
<p>Therefore <span class="math notranslate nohighlight">\(sign(w_{ji})\)</span> is either <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(-1\)</span> and the inner product
simplifies to addition followed by scaling factor <span class="math notranslate nohighlight">\(\alpha = \frac{1}{\|\mathbf{w}_j\|_{\ell_1}}\)</span>.
The number of :<span class="math notranslate nohighlight">\(\alpha\)</span> is the outmaps of the affine function.</p>
<p class="rubric">References</p>
<p>Rastegari, Mohammad, et al. “XNOR-Net: ImageNet Classification Using
Binary Convolutional Neural Networks.” arXiv preprint
arXiv:1603.05279 (2016).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the binarized weights (<cite>binary_weight</cite>)</p>
<p>2) The weights and the binary weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the binary weights will not be in sync.</p>
<p class="last">3) Quantized values are stored as floating point number for <cite>binary_weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it was a matrix.</li>
<li><strong>n_outmaps</strong> (int or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>quantize_zero_to</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Input value at zero is quantized to this value.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for the weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>wb_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for the binary weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for the bias. By defalut, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weight and bias will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;bwn_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix in floating type. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>Wb (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Binarized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>alpha (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Scaling factor <span class="math notranslate nohighlight">\(\alpha\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">binary_weight_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.binary_weight_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">binary_weight_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>quantize_zero_to=1.0</em>, <em>w_init=None</em>, <em>wb_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#binary_weight_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.binary_weight_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary Weight Convolution, multiplier-less inner-product with a scale factor.</p>
<p>Binary Weight Convolution is the convolution function, but the
inner product in this function is the following,</p>
<div class="math notranslate nohighlight">
\[y_{n, a, b} = \frac{1}{\|\mathbf{w}_n\|_{\ell_1}} \sum_{m} \sum_{i} \sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}.\]</div>
<p>Therefore <span class="math notranslate nohighlight">\(sign(w_{n, m, i, j})\)</span>  is either <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(-1\)</span> and the inner product
simplifies to addition followed by scaling factor <span class="math notranslate nohighlight">\(\alpha = \frac{1}{\|\mathbf{w}_n\|_{\ell_1}}\)</span>.
The number of <span class="math notranslate nohighlight">\(n\)</span> is the number of outmaps of the convolution
function.</p>
<p class="rubric">References</p>
<p>Rastegari, Mohammad, et al. “XNOR-Net: ImageNet Classification Using
Binary Convolutional Neural Networks.” arXiv preprint
arXiv:1603.05279 (2016).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the binarized weights (<cite>binary_weight</cite>)</p>
<p>2) The weights and the binary weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the binary weights will not be in sync.</p>
<p class="last">3) Quantized values are stored as floating point number for <cite>binary_weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction.</li>
<li><strong>quantize_zero_to</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Input value at zero is quantized to this value.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>wb_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for binary weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;bwn_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps,</span> <span class="pre">*kernel)</span></code>)</li>
<li>Wb (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Binarized filter weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps,</span> <span class="pre">*kernel)</span></code>)</li>
<li>alpha (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Scaling factor <span class="math notranslate nohighlight">\(\alpha\)</span>. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">binary_weight_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.inq_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">inq_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>num_bits=4</em>, <em>inq_iterations=()</em>, <em>selection_algorithm='random'</em>, <em>seed=-1</em>, <em>w_init=None</em>, <em>i_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#inq_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.inq_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Incremental Network Quantization Affine Layer</p>
<p>During training, the weights are sequentially quantized to power-of-two
values, which allows the training of a multiplierless network.</p>
<p>Using <cite>inq_iterations</cite>, one can specify after how many forward passes
half of the learnable weights are fixed and quantized to powers-of-two.
After reaching the last value in <cite>inq_iterations</cite>, all weights are fixed.</p>
<p>For more details, please refer to the reference.</p>
<p>Reference:
Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization:
Towards lossless CNNs with low-precision weights.
&lt;<a class="reference external" href="https://arxiv.org/abs/1702.03044">https://arxiv.org/abs/1702.03044</a>&gt;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it was a matrix.</li>
<li><strong>n_outmaps</strong> (int or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>quantize_zero_to</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Input value at zero is quantized to this value.</li>
<li><strong>num_bits</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of bits per weight. Value has to be larger than 1 as one bit is already used to code the value “0”</li>
<li><strong>inq_iterations</strong> (<em>tuple of int</em>) – Tuple of iteration numbers at which we fix half of the weights.</li>
<li><strong>selection_algorithm</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Chooses algorithm that is used to decide which weights are fixed. (“largest_abs” … fix weights with largest absolute value, “random” … fix weights randomly)</li>
<li><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Random seed for INQ algorithm</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>i_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for indicators (0 … learnable, 1 … fixed). By default, it is initialized with zeros.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weight and bias will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;inq_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix in floating type. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>I (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Binary indicator matrix of fixed weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">inq_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.inq_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">inq_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>num_bits=4</em>, <em>inq_iterations=()</em>, <em>selection_algorithm='random'</em>, <em>seed=-1</em>, <em>w_init=None</em>, <em>i_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#inq_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.inq_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Incremental Network Quantization Convolution Layer</p>
<p>During training, the weights are sequentially quantized to power-of-two
values, which allows the training of a multiplierless network.</p>
<p>Using <cite>inq_iterations</cite>, one can specify after how many forward passes
half of the learnable weights are fixed and quantized to powers-of-two.
After reaching the last value in <cite>inq_iterations</cite>, all weights are fixed.</p>
<p>For more details, please refer to the reference.</p>
<p>Reference:
Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization:
Towards lossless CNNs with low-precision weights.
&lt;<a class="reference external" href="https://arxiv.org/abs/1702.03044">https://arxiv.org/abs/1702.03044</a>&gt;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it was a matrix.</li>
<li><strong>n_outmaps</strong> (int or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>num_bits</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of bits per weight. Value has to be larger than 1 as one bit is already used to code the value “0”</li>
<li><strong>inq_iterations</strong> (<em>tuple of int</em>) – Tuple of iteration numbers at which we fix half of the weights.</li>
<li><strong>selection_algorithm</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Chooses algorithm that is used to decide which weights are fixed. (“largest_abs” … fix weights with largest absolute value, “random” … fix weights randomly)</li>
<li><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Random seed for INQ algorithm</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for the weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>i_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for the indicators (0 … learnable, 1 … fixed). By default, it is initialized with zeros.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for the bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weight and bias will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;inq_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps,</span> <span class="pre">*kernel)</span></code>)</li>
<li>I (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Binary indicator matrix of fixed weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">inq_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.fixed_point_quantized_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">fixed_point_quantized_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>quantize_w=True</em>, <em>sign_w=True</em>, <em>n_w=8</em>, <em>delta_w=0.0625</em>, <em>ste_fine_grained_w=True</em>, <em>quantize_b=True</em>, <em>sign_b=True</em>, <em>n_b=8</em>, <em>delta_b=0.0625</em>, <em>ste_fine_grained_b=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#fixed_point_quantized_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.fixed_point_quantized_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Fixed-Point Quantized Affine.</p>
<p>Fixed-Point Quantized Affine is the affine function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_j = \sum_{i} Q(w_{ji}) x_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(w_{ji})\)</span> is the fixed-point quantization function.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the quantized weights (<cite>quantized weight</cite>)</p>
<p>2) The weights and the quantized weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the quantized weights will not be in sync.</p>
<p class="last">3) CPU and GPU implementations now use float value for <cite>quantized weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it is a matrix.</li>
<li><strong>n_outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a> or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>quantize_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize weights if <cite>True</cite>.</li>
<li><strong>sign_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use signed quantization if <cite>True</cite>.</li>
<li><strong>n_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for weight.</li>
<li><strong>delta_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Step size for weight.</li>
<li><strong>ste_fine_grained_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
<li><strong>quantize_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>n_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for bias.</li>
<li><strong>delta_w</strong> – Step size for bias.</li>
<li><strong>ste_fine_grained_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array. (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;fp_quantized_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix in float. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>W_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized biases. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">fixed_point_quantized_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.fixed_point_quantized_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">fixed_point_quantized_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>quantize_w=True</em>, <em>sign_w=True</em>, <em>n_w=8</em>, <em>delta_w=0.0625</em>, <em>ste_fine_grained_w=True</em>, <em>quantize_b=True</em>, <em>sign_b=True</em>, <em>n_b=8</em>, <em>delta_b=0.0625</em>, <em>ste_fine_grained_b=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#fixed_point_quantized_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.fixed_point_quantized_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Fixed-Point Quantized Convolution.</p>
<p>Fixed-Point Quantized Convolution is the convolution function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_{n, a, b} = \sum_{m} \sum_{i} \sum_{j} Q(w_{n, m, i, j}) x_{m, a + i, b + j},\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(w_{n, m, i, j})\)</span> is the fixed-point quantization function.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the quantized weights (<cite>quantized weight</cite>)</p>
<p>2) The weights and the quantized weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the quantized weights will not be in sync.</p>
<p class="last">3) CPU and GPU implementations now use float value for <cite>quantized weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels more sparse by grouping connections along map direction.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>quantize_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize weights if <cite>True</cite>.</li>
<li><strong>quantize_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>sign_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use signed quantization if <cite>True</cite>.</li>
<li><strong>n_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for weight.</li>
<li><strong>delta_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Step size for weight.</li>
<li><strong>ste_fine_grained_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
<li><strong>quantize_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>n_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for bias.</li>
<li><strong>delta_w</strong> – Step size for bias.</li>
<li><strong>ste_fine_grained_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;fp_quantized_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>W_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized biases. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">fixed_point_quantized_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.pow2_quantized_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">pow2_quantized_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>quantize_w=True</em>, <em>sign_w=True</em>, <em>with_zero_w=False</em>, <em>n_w=8</em>, <em>m_w=2</em>, <em>ste_fine_grained_w=True</em>, <em>quantize_b=True</em>, <em>sign_b=True</em>, <em>with_zero_b=False</em>, <em>n_b=8</em>, <em>m_b=2</em>, <em>ste_fine_grained_b=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#pow2_quantized_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.pow2_quantized_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Pow2 Quantized Affine.</p>
<p>Pow2 Quantized Affine is the affine function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_j = \sum_{i} Q(w_{ji}) x_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(w_{ji})\)</span> is the power-of-2 quantization function.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the quantized weights (<cite>quantized weight</cite>)</p>
<p>2) The weights and the quantized weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the quantized weights will not be in sync.</p>
<p class="last">3) Quantized values are stored as floating point number for <cite>quantized weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it is a matrix.</li>
<li><strong>n_outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a> or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>quantize_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize weights if <cite>True</cite>.</li>
<li><strong>sign_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use signed quantization if <cite>True</cite>.</li>
<li><strong>with_zero_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Indicate using zero as a quantized value. Default is false.</li>
<li><strong>n_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for weight.</li>
<li><strong>m_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – <span class="math notranslate nohighlight">\(2^m\)</span> is upper bound and <span class="math notranslate nohighlight">\(-2^m\)</span> is lower bound for weights. Default is 2.</li>
<li><strong>ste_fine_grained_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
<li><strong>quantize_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>with_zero_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Indicate using zero as a quantized value. Default is false.</li>
<li><strong>n_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for bias.</li>
<li><strong>m_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – <span class="math notranslate nohighlight">\(2^m\)</span> is upper bound and <span class="math notranslate nohighlight">\(-2^m\)</span> is lower bound for bias. Default is 2.</li>
<li><strong>ste_fine_grained_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array. (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;pow2_quantized_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix in float. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>W_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized biases. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">pow2_quantized_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.pow2_quantized_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">pow2_quantized_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>quantize_w=True</em>, <em>with_zero_w=False</em>, <em>sign_w=True</em>, <em>n_w=8</em>, <em>m_w=2</em>, <em>ste_fine_grained_w=True</em>, <em>quantize_b=True</em>, <em>with_zero_b=False</em>, <em>sign_b=True</em>, <em>n_b=8</em>, <em>m_b=2</em>, <em>ste_fine_grained_b=True</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#pow2_quantized_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.pow2_quantized_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Pow2 Quantized Convolution.</p>
<p>Pow2 Quantized Convolution is the convolution function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_{n, a, b} = \sum_{m} \sum_{i} \sum_{j} Q(w_{n, m, i, j}) x_{m, a + i, b + j},\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(w_{n, m, i, j})\)</span> is the power-of-2 quantization function.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the quantized weights (<cite>quantized weight</cite>)</p>
<p>2) The weights and the quantized weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the quantized weights will not be in sync.</p>
<p class="last">3) Quantized values are stored as floating point number for <cite>quantized weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels more sparse by grouping connections along map direction.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>quantize_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize weights if <cite>True</cite>.</li>
<li><strong>sign_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use signed quantization if <cite>True</cite>.</li>
<li><strong>n_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for weight.</li>
<li><strong>m_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – <span class="math notranslate nohighlight">\(2^m\)</span> is upper bound and <span class="math notranslate nohighlight">\(-2^m\)</span> is lower bound for weights. Default is 2.</li>
<li><strong>ste_fine_grained_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
<li><strong>quantize_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>sign_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Use signed quantization if <cite>True</cite>.</li>
<li><strong>n_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Bit width used for bias.</li>
<li><strong>m_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – <span class="math notranslate nohighlight">\(2^m\)</span> is upper bound and <span class="math notranslate nohighlight">\(-2^m\)</span> is lower bound for bias. Default is 2.</li>
<li><strong>ste_fine_grained_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – STE is fine-grained if <cite>True</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;pow2_quantized_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>W_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized biases. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">pow2_quantized_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.pruned_affine">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">pruned_affine</code><span class="sig-paren">(</span><em>inp</em>, <em>n_outmaps</em>, <em>base_axis=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>prune_w=True</em>, <em>rate_w=0.9</em>, <em>prune_b=True</em>, <em>rate_b=0.9</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#pruned_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.pruned_affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Pruned Affine.</p>
<p>Pruned Affine is the affine function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_j = \sum_{i} Q(w_{ji}) x_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(w_{ji})\)</span> is the pruning function, i.e., <cite>F.prune</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the quantized weights (<cite>quantized weight</cite>)</p>
<p>2) The weights and the quantized weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the quantized weights will not be in sync.</p>
<p class="last">3) CPU and GPU implementations now use float value for <cite>quantized weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times D_B \times \ldots \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it is a matrix.</li>
<li><strong>n_outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a> or <a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of output neurons per data.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>prune_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize weights if <cite>True</cite>.</li>
<li><strong>rate_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Pruning rate for weights.</li>
<li><strong>prune_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>rate_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Pruning rate for bias.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array. (<span class="math notranslate nohighlight">\(M_0 \times \ldots \times M_{B-1} \times L\)</span>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;pruned_affine&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Weight matrix in float. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>W_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Qunatized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">outmaps)</span></code>)</li>
<li>b_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized biases. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">pruned_affine</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.pruned_convolution">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">pruned_convolution</code><span class="sig-paren">(</span><em>inp</em>, <em>outmaps</em>, <em>kernel</em>, <em>pad=None</em>, <em>stride=None</em>, <em>dilation=None</em>, <em>group=1</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>base_axis=1</em>, <em>fix_parameters=False</em>, <em>rng=None</em>, <em>with_bias=True</em>, <em>prune_w=True</em>, <em>rate_w=0.9</em>, <em>prune_b=True</em>, <em>rate_b=0.9</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#pruned_convolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.pruned_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Pruned Convolution.</p>
<p>Pruned Convolution is the convolution function,
except the definition of the inner product is modified.
The input-output relation of this function is as follows:</p>
<div class="math notranslate nohighlight">
\[y_{n, a, b} = \sum_{m} \sum_{i} \sum_{j} Q(w_{n, m, i, j}) x_{m, a + i, b + j},\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(w_{ji})\)</span> is the pruning function, i.e., <cite>F.prune</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>1) if you would like to share weights between some layers, please
make sure to share the standard, floating value weights (<cite>weight</cite>)
and not the quantized weights (<cite>quantized weight</cite>)</p>
<p>2) The weights and the quantized weights become synced only after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> is called,
and not after a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
To access the parameters of the network, remember to call <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> once before doing so, otherwise the
float weights and the quantized weights will not be in sync.</p>
<p class="last">3) CPU and GPU implementations now use float value for <cite>quantized weight</cite>,
since this function is only for simulation purposes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inp</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – N-D array.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).</li>
<li><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Padding sizes for dimensions.</li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Stride sizes for dimensions.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Dilation sizes for dimensions.</li>
<li><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of groups of channels. This makes connections across channels more sparse by grouping connections along map direction.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for weight.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>) – Initializer for bias.</li>
<li><strong>base_axis</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Dimensions up to <cite>base_axis</cite> are treated as the sample dimensions.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random generator for Initializer.</li>
<li><strong>with_bias</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Specify whether to include the bias term.</li>
<li><strong>prune_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize weights if <cite>True</cite>.</li>
<li><strong>rate_w</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Pruning rate for weights.</li>
<li><strong>prune_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Quantize bias if <cite>True</cite>.</li>
<li><strong>rate_b</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Pruning rate for bias.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-D array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;pruned_conv&quot;</span></code>;</p>
<ul class="last simple">
<li>W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Filter weights in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Bias vector in float. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
<li>W_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Qunatized weights. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,</span> <span class="pre">inmaps</span> <span class="pre">//</span> <span class="pre">group,</span> <span class="pre">*kernel)</span></code>)</li>
<li>b_q (<code class="docutils literal notranslate"><span class="pre">need_grad=False</span></code>) : Quantized biases. (shape: <code class="docutils literal notranslate"><span class="pre">(outmaps,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">pruned_convolution</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.parametric_functions.lstm_cell">
<code class="descclassname">nnabla.parametric_functions.</code><code class="descname">lstm_cell</code><span class="sig-paren">(</span><em>x</em>, <em>h</em>, <em>c</em>, <em>state_size</em>, <em>w_init=None</em>, <em>b_init=None</em>, <em>fix_parameters=False</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#lstm_cell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.lstm_cell" title="Permalink to this definition">¶</a></dt>
<dd><p>Long Short-Term Memory.</p>
<p>Long Short-Term Memory, or LSTM, is a building block for recurrent neural networks (RNN) layers.
LSTM unit consists of a cell and input, output, forget gates whose functions are defined as following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f_t&amp;&amp;=\sigma(W_fx_t+U_fh_{t-1}+b_f) \\
i_t&amp;&amp;=\sigma(W_ix_t+U_ih_{t-1}+b_i) \\
o_t&amp;&amp;=\sigma(W_ox_t+U_oh_{t-1}+b_o) \\
c_t&amp;&amp;=f_t\odot c_{t-1}+i_t\odot\tanh(W_cx_t+U_ch_{t-1}+b_c) \\
h_t&amp;&amp;=o_t\odot\tanh(c_t).\end{split}\]</div>
<p class="rubric">References</p>
<p>S. Hochreiter, and J. Schmidhuber. “Long Short-Term Memory.”
Neural Computation. 1997.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (batch_size, input_size).</li>
<li><strong>h</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (batch_size, state_size).</li>
<li><strong>c</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (batch_size, state_size).</li>
<li><strong>state_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Internal state size is set to <cite>state_size</cite>.</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a></p>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Parameters to be registered</dt>
<dd><p class="first">The following variables are registered in a parameter scope <code class="docutils literal notranslate"><span class="pre">&quot;lstm&quot;</span></code>;</p>
<ul class="last simple">
<li>affine/W (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Stacked weight matrixes of LSTM block. (shape: <code class="docutils literal notranslate"><span class="pre">(inmaps,</span> <span class="pre">4,</span> <span class="pre">state_size)</span></code>)</li>
<li>affine/b (<code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code>) : Stacked bias vectors of LSTM block. (shape: <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">state_size,)</span></code>)</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">name</span></code> option is passed, the parameters become wrapped inside the parameter scope
with the specified name, yielding the same results as the following code.
This can be used to simplify the code.</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parametric_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">lstm_cell</span><span class="p">(</span><span class="o">&lt;</span><span class="n">args</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="class">
<dt id="nnabla.parametric_functions.LSTMCell">
<em class="property">class </em><code class="descclassname">nnabla.parametric_functions.</code><code class="descname">LSTMCell</code><span class="sig-paren">(</span><em>batch_size</em>, <em>state_size</em>, <em>h=None</em>, <em>c=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#LSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.LSTMCell" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="nnabla.parametric_functions.LSTMCell.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em>, <em>w_init</em>, <em>b_init</em>, <em>fix_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/parametric_functions.html#LSTMCell.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.parametric_functions.LSTMCell.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates h and c by calling lstm function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>x</strong> (<a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a>) – Input N-D array with shape (batch_size, input_size).</li>
<li><strong>w_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for weight. By default, it is initialized with <a class="reference internal" href="#nnabla.initializer.UniformInitializer" title="nnabla.initializer.UniformInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.UniformInitializer</span></code></a> within the range determined by <a class="reference internal" href="#nnabla.initializer.calc_uniform_lim_glorot" title="nnabla.initializer.calc_uniform_lim_glorot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.calc_uniform_lim_glorot</span></code></a>.</li>
<li><strong>b_init</strong> (<a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a> or <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional) – Initializer for bias. By default, it is initialized with zeros if <cite>with_bias</cite> is <cite>True</cite>.</li>
<li><strong>fix_parameters</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to <cite>True</cite>, the weights and biases will not be updated.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="parameter-initializer">
<h2>Parameter Initializer<a class="headerlink" href="#parameter-initializer" title="Permalink to this headline">¶</a></h2>
<p>Some of the parametric functions optionally takes parameter initializer
listed below.</p>
<span class="target" id="module-nnabla.initializer"></span><dl class="class">
<dt id="nnabla.initializer.BaseInitializer">
<em class="property">class </em><code class="descclassname">nnabla.initializer.</code><code class="descname">BaseInitializer</code><a class="reference internal" href="../../_modules/nnabla/initializer.html#BaseInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.BaseInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class of the parameter initializer.</p>
<dl class="method">
<dt id="nnabla.initializer.BaseInitializer.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>shape</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#BaseInitializer.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.BaseInitializer.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates an array with an initializer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a> with the shape created.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Array.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.16)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Subclasses of <a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInitializer</span></code></a> must override this method.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nnabla.initializer.ConstantInitializer">
<em class="property">class </em><code class="descclassname">nnabla.initializer.</code><code class="descname">ConstantInitializer</code><span class="sig-paren">(</span><em>value=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#ConstantInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.ConstantInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-class docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a></p>
<p>Generates a constant valued array.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – A constant value.</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">ConstantInitializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">ConstantInitializer</span><span class="p">()</span> <span class="c1"># this generates constant valued array of default value 0</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="nnabla.initializer.NormalInitializer">
<em class="property">class </em><code class="descclassname">nnabla.initializer.</code><code class="descname">NormalInitializer</code><span class="sig-paren">(</span><em>sigma=1.0</em>, <em>rng=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#NormalInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.NormalInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-class docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a></p>
<p>Generates a random array from a specified normal distribution.</p>
<div class="math notranslate nohighlight">
\[\mathbf x \sim {\cal N} (\mathbf 0 | \sigma^2 \mathbf I)\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – <span class="math notranslate nohighlight">\(\sigma\)</span>.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random number generator.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">NormalInitializer</span><span class="p">(</span><span class="mf">5e-5</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">NormalInitializer</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="nnabla.initializer.UniformInitializer">
<em class="property">class </em><code class="descclassname">nnabla.initializer.</code><code class="descname">UniformInitializer</code><span class="sig-paren">(</span><em>lim=(-1</em>, <em>1)</em>, <em>rng=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#UniformInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.UniformInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nnabla.initializer.BaseInitializer" title="nnabla.initializer.BaseInitializer"><code class="xref py py-class docutils literal notranslate"><span class="pre">nnabla.initializer.BaseInitializer</span></code></a></p>
<p>Generates a random array from a specified uniform distribution.</p>
<div class="math notranslate nohighlight">
\[\mathbf x \sim {\cal U} (a, b)\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>lim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>) – A tuple of two floats, <span class="math notranslate nohighlight">\((a, b)\)</span>.</li>
<li><strong>rng</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState" title="(in NumPy v1.16)"><em>numpy.random.RandomState</em></a>) – Random number generator.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">UniformInitializer</span><span class="p">()</span> <span class="c1"># this generates uniform distribution within the default range of (-1,1)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">UniformInitializer</span><span class="p">((</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.initializer.calc_normal_std_he_forward">
<code class="descclassname">nnabla.initializer.</code><code class="descname">calc_normal_std_he_forward</code><span class="sig-paren">(</span><em>inmaps</em>, <em>outmaps</em>, <em>kernel=(1</em>, <em>1)</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#calc_normal_std_he_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.calc_normal_std_he_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the standard deviation proposed by He et al.</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{\frac{2}{NK}}\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an input Variable, <span class="math notranslate nohighlight">\(N\)</span>.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an output Variable, <span class="math notranslate nohighlight">\(M\)</span>.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel spatial shape.
In above definition, <span class="math notranslate nohighlight">\(K\)</span> is the product of shape dimensions.
In Affine, the default value should be used.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">calc_normal_std_he_forward</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">64</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">NormalInitializer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">ConstantInitializer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/abs/1502.01852">He, et al. Delving Deep into Rectifiers: Surpassing Human-Level
Performance on ImageNet Classification.</a></li>
</ul>
</dd></dl>

<dl class="function">
<dt id="nnabla.initializer.calc_normal_std_he_backward">
<code class="descclassname">nnabla.initializer.</code><code class="descname">calc_normal_std_he_backward</code><span class="sig-paren">(</span><em>inmaps</em>, <em>outmaps</em>, <em>kernel=(1</em>, <em>1)</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#calc_normal_std_he_backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.calc_normal_std_he_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the standard deviation of He et al. (backward case).</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{\frac{2}{MK}}\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an input Variable, <span class="math notranslate nohighlight">\(N\)</span>.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an output Variable, <span class="math notranslate nohighlight">\(M\)</span>.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel spatial shape.
In above definition, <span class="math notranslate nohighlight">\(K\)</span> is the product of shape dimensions.
In Affine, the default value should be used.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">calc_normal_std_he_backward</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">64</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">NormalInitializer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">ConstantInitializer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/abs/1502.01852">He, et al. Delving Deep into Rectifiers: Surpassing Human-Level
Performance on ImageNet Classification.</a></li>
</ul>
</dd></dl>

<dl class="function">
<dt id="nnabla.initializer.calc_normal_std_glorot">
<code class="descclassname">nnabla.initializer.</code><code class="descname">calc_normal_std_glorot</code><span class="sig-paren">(</span><em>inmaps</em>, <em>outmaps</em>, <em>kernel=(1</em>, <em>1)</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#calc_normal_std_glorot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.calc_normal_std_glorot" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the standard deviation proposed by Glorot et al.</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{\frac{2}{NK + M}}\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an input Variable, <span class="math notranslate nohighlight">\(N\)</span>.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an output Variable, <span class="math notranslate nohighlight">\(M\)</span>.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel spatial shape.
In above definition, <span class="math notranslate nohighlight">\(K\)</span> is the product of shape dimensions.
In Affine, the default value should be used.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">calc_normal_std_glorot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">64</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">NormalInitializer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">ConstantInitializer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><a class="reference external" href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf">Glorot and Bengio. Understanding the difficulty of training deep
feedforward neural networks</a></li>
</ul>
</dd></dl>

<dl class="function">
<dt id="nnabla.initializer.calc_uniform_lim_glorot">
<code class="descclassname">nnabla.initializer.</code><code class="descname">calc_uniform_lim_glorot</code><span class="sig-paren">(</span><em>inmaps</em>, <em>outmaps</em>, <em>kernel=(1</em>, <em>1)</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/initializer.html#calc_uniform_lim_glorot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnabla.initializer.calc_uniform_lim_glorot" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the lower bound and the upper bound of the uniform distribution proposed by Glorot et al.</p>
<div class="math notranslate nohighlight">
\[\begin{split}b &amp;= \sqrt{\frac{6}{NK + M}}\\
a &amp;= -b\end{split}\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an input Variable, <span class="math notranslate nohighlight">\(N\)</span>.</li>
<li><strong>outmaps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Map size of an output Variable, <span class="math notranslate nohighlight">\(M\)</span>.</li>
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>) – Convolution kernel spatial shape.
In above definition, <span class="math notranslate nohighlight">\(K\)</span> is the product of shape dimensions.
In Affine, the default value should be used.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="kn">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">nnabla.initializer</span> <span class="kn">as</span> <span class="nn">I</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">calc_uniform_lim_glorot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">64</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">UniformInitializer</span><span class="p">((</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">ConstantInitializer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">w_init</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">b_init</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<ul class="simple">
<li><a class="reference external" href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf">Glorot and Bengio. Understanding the difficulty of training deep
feedforward neural networks</a></li>
</ul>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="solver.html" class="btn btn-neutral float-right" title="Solvers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="function.html" class="btn btn-neutral float-left" title="Functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Sony Corporation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>