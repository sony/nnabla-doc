<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>nnabla.functions &mdash; Neural Network Libraries 1.24.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Neural Network Libraries
          </a>
              <div class="version">
                1.24.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../python.html">Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>nnabla.functions</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for nnabla.functions</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2017,2018,2019,2020,2021 Sony Corporation.</span>
<span class="c1"># Copyright 2021 Sony Group Corporation.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">dtypes</span>
<span class="kn">import</span> <span class="nn">nnabla</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">.normalization_functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.numpy_compat_functions</span> <span class="kn">import</span> <span class="o">*</span>


<div class="viewcode-block" id="sum"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.sum">[docs]</a><span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction along axes with sum operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which the sum is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">sum_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">sum_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<div class="viewcode-block" id="mean"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.mean">[docs]</a><span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction along axes with mean operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which mean is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">mean</span> <span class="k">as</span> <span class="n">mean_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mean_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<div class="viewcode-block" id="max"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.max">[docs]</a><span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_index</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduce the input N-D array `x` along the given `axis` using the max</span>
<span class="sd">    operation. The `axis` argument may be a single integer to reduce</span>
<span class="sd">    over one axis, a tuple of integers to reduce over multiple axes,</span>
<span class="sd">    or ``None`` to reduce over all axes. If `keepdims` is ``True``,</span>
<span class="sd">    the output will keep all reduced dimensions with size 1. If</span>
<span class="sd">    `with_index` is True, result is a tuple ``(sorted, indices)`` or</span>
<span class="sd">    only ``indices`` if `only_index` is True. Setting `only_index` to</span>
<span class="sd">    True implies that `with_index` is also True.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        nn.set_auto_forward(True)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))</span>

<span class="sd">        maxval = F.max(x, axis=1)</span>
<span class="sd">        assert np.allclose(maxval.d, np.max(x.d, axis=1))</span>

<span class="sd">        maxval, indices = F.max(x, axis=1, with_index=True)</span>
<span class="sd">        assert np.allclose(maxval.d, np.max(x.d, axis=1))</span>
<span class="sd">        assert np.all(indices.d == np.argmax(x.d, axis=1))</span>

<span class="sd">        indices = F.max(x, axis=1, only_index=True)</span>
<span class="sd">        assert np.all(indices.d == np.argmax(x.d, axis=1))</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which max is</span>
<span class="sd">            calculated. The default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims(bool): Keep reduced axes as dimension with 1 element.</span>
<span class="sd">        with_index(bool): Return tuple of max values and index.</span>
<span class="sd">        only_index(bool): Return only the index of max values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="nb">max</span> <span class="k">as</span> <span class="n">max_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">with_index</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">only_index</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">max_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">with_index</span><span class="p">,</span> <span class="n">only_index</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="min"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.min">[docs]</a><span class="k">def</span> <span class="nf">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_index</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduce the input N-D array `x` along the given `axis` using the min</span>
<span class="sd">    operation. The `axis` argument may be a single integer to reduce</span>
<span class="sd">    over one axis, a tuple of integers to reduce over multiple axes,</span>
<span class="sd">    or ``None`` to reduce over all axes. If `keepdims` is ``True``,</span>
<span class="sd">    the output will keep all reduced dimensions with size 1. If</span>
<span class="sd">    `with_index` is True, result is a tuple ``(sorted, indices)`` or</span>
<span class="sd">    only ``indices`` if `only_index` is True. Setting `only_index` to</span>
<span class="sd">    True implies that `with_index` is also True.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        nn.set_auto_forward(True)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))</span>

<span class="sd">        minval = F.min(x, axis=1)</span>
<span class="sd">        assert np.allclose(minval.d, np.min(x.d, axis=1))</span>

<span class="sd">        minval, indices = F.min(x, axis=1, with_index=True)</span>
<span class="sd">        assert np.allclose(minval.d, np.min(x.d, axis=1))</span>
<span class="sd">        assert np.all(indices.d == np.argmin(x.d, axis=1))</span>

<span class="sd">        indices = F.min(x, axis=1, only_index=True)</span>
<span class="sd">        assert np.all(indices.d == np.argmin(x.d, axis=1))</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which min is</span>
<span class="sd">            calculated. The default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims(bool): Keep reduced axes as dimension with 1 element.</span>
<span class="sd">        with_index(bool): Return tuple of min values and index.</span>
<span class="sd">        only_index(bool): Return only the index of min values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="nb">min</span> <span class="k">as</span> <span class="n">min_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">with_index</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">only_index</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">min_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">with_index</span><span class="p">,</span> <span class="n">only_index</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="norm"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.norm">[docs]</a><span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reduction along axes with norm operation.</span>

<span class="sd">    .. math::</span>
<span class="sd">        y = \|x\|_p = \left( \sum_i |x_i|^p \right)^{\frac{1}{p}}</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        p (float): Order of the norm.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which product is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">norm_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">norm_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<div class="viewcode-block" id="norm_normalization"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.norm_normalization">[docs]</a><span class="k">def</span> <span class="nf">norm_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Norm normalization.</span>

<span class="sd">    .. math::</span>
<span class="sd">        y = \frac{x_i}{\|x\|_p}</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array.</span>
<span class="sd">        p(float): Order of the norm.</span>
<span class="sd">            [default= `2` ]</span>
<span class="sd">        axes(repeated int64): Axes to be reduced. If empty list is given, all dimensions are reduced.</span>
<span class="sd">            [default= `range(x.ndim)` ]</span>
<span class="sd">        eps(float): Epsilon for the normalization. This `eps` is added before taking the p-th root in the norm computation.</span>
<span class="sd">            [default= `1e-12` ]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">norm_normalization</span> <span class="k">as</span> <span class="n">norm_normalization_base</span>
    <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">axes</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">norm_normalization_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span></div>


<div class="viewcode-block" id="spectral_norm"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.spectral_norm">[docs]</a><span class="k">def</span> <span class="nf">spectral_norm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">itr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_u</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Spectral Normalization.</span>

<span class="sd">    .. math::</span>

<span class="sd">        W_{sn} = \frac{W}{\sigma(W)}</span>

<span class="sd">    where :math:`W` is the input matrix, and the :math:`\sigma(W)` is the spectral norm of :math:`W`. The spectral norm is approximately computed by the power iteration.</span>

<span class="sd">    References:</span>

<span class="sd">        Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida, </span>
<span class="sd">        &quot;Spectral Normalization for Generative Adversarial Networks&quot;, </span>
<span class="sd">        International Conference on Learning Representations. 2018.</span>

<span class="sd">    Args:</span>
<span class="sd">        w(~nnabla.Variable): N-D array of learnable weights. This is normally network parameter.</span>
<span class="sd">        u(~nnabla.Variable): 1-D array of singular vector. When `test == False`, the data region of `u` will be updated during forward calculation.</span>
<span class="sd">        dim(int): Output dimension. Default is 0. If the dimension is not 0, then the specified dimension becomes the most-left dimension by transposing.</span>
<span class="sd">            [default= `0` ]</span>
<span class="sd">        itr(int): Number of power iterations. Default is 1.</span>
<span class="sd">            [default= `1` ]</span>
<span class="sd">        eps(float): Epsilon for the normalization. This `eps` is added before taking the sqrt in the norm computation.</span>
<span class="sd">            [default= `1e-12` ]</span>
<span class="sd">        test(bool): When in `True`, `u` will not be updated. Default is `False`.</span>
<span class="sd">            [default= `False` ]</span>
<span class="sd">        output_u(bool): Output original `u` or not. `u` is updated when `test == True` but you can get original `u` as output with this option. Default is `False`.</span>
<span class="sd">            [default= `False` ]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: Spectrally normalized :math:`W_{sn}` with the same shape as :math:`W`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">spectral_norm</span> <span class="k">as</span> <span class="n">spectral_norm_base</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">output_u</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">spectral_norm_base</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">itr</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">output_u</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="prod"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.prod">[docs]</a><span class="k">def</span> <span class="nf">prod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction along axes with product operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which product is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Backward computation is not accurate in a zero value input.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">prod</span> <span class="k">as</span> <span class="n">prod_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">prod_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">reduce</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction function with given operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input.</span>
<span class="sd">        op (str): &#39;sum&#39; or &#39;mean&#39;.</span>

<span class="sd">    Note:</span>
<span class="sd">        This is deprecated. Use ``mean`` or ``sum`` instead.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;Deprecated API. Use ``sum`` or ``mean`` instead.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">reduce_sum</span><span class="p">,</span> <span class="n">reduce_mean</span>
    <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>


<div class="viewcode-block" id="meshgrid"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.meshgrid">[docs]</a><span class="k">def</span> <span class="nf">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">ij_indexing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">meshgrid</span> <span class="k">as</span> <span class="n">meshgrid_base</span>
    <span class="k">return</span> <span class="n">meshgrid_base</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">ij_indexing</span><span class="o">=</span><span class="n">ij_indexing</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></div>


<div class="viewcode-block" id="split"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.split">[docs]</a><span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Split arrays at the specified axis.</span>

<span class="sd">    It returns a number corresponding the size of the given</span>
<span class="sd">    axis (i.e ``x.shape[axis]``) of :obj:`~nnabla.Variable` s.</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array</span>
<span class="sd">        axis(int): Axis</span>

<span class="sd">    Returns: A :obj:`tuple` of :obj:`~nnabla.Variable` s</span>

<span class="sd">    See Also:</span>
<span class="sd">        :func:`nnabla.function_bases.split`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">split</span> <span class="k">as</span> <span class="n">split_base</span>
    <span class="k">return</span> <span class="n">split_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">])</span></div>


<span class="nd">@function_api</span>
<span class="k">def</span> <span class="nf">slice</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Slice arrays along specified axis. This function </span>
<span class="sd">    complies with python slice wherre `slice(None, None, -1)` and </span>
<span class="sd">    `slice(-1, None, -1)` are the special case, which flips the </span>
<span class="sd">    input array and results in the output array from the end to the beginning</span>
<span class="sd">    of the input array along the corresponding dimension.</span>


<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array</span>
<span class="sd">        start(repeated int64): Start indices for each axis</span>
<span class="sd">            [default= `(0,) * len(x.shape)` ]</span>
<span class="sd">        stop(repeated int64): Stop indices for each axis</span>
<span class="sd">            [default= `tuple(x.shape)` ]</span>
<span class="sd">        step(repeated int64): Step indices for each axis</span>
<span class="sd">            [default= `(1,) * len(x.shape)` ]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: Sliced N-D array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">start</span><span class="p">[:])</span> <span class="k">if</span> <span class="n">start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">stop</span><span class="p">[:])</span> <span class="k">if</span> <span class="n">stop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">step</span><span class="p">[:])</span> <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">)):</span>
        <span class="c1"># SPECIAL CASE: slice(-1, None, &lt;0) or slice(None, None, &lt;0)</span>
        <span class="n">SLICE_NONE</span> <span class="o">=</span> <span class="mh">0x7fffffff</span>
        <span class="k">if</span> <span class="n">s0</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">start</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">SLICE_NONE</span>
        <span class="k">if</span> <span class="n">s1</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stop</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">SLICE_NONE</span>
        <span class="k">if</span> <span class="n">s2</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">step</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">SLICE_NONE</span>

    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="nb">slice</span> <span class="k">as</span> <span class="n">slice_base</span>
    <span class="k">return</span> <span class="n">slice_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>


<div class="viewcode-block" id="mean_subtraction"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.mean_subtraction">[docs]</a><span class="k">def</span> <span class="nf">mean_subtraction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">base_axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">update_running_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    It subtracts the mean of the elements of the input array,</span>
<span class="sd">    and normalizes it to :math:`0`. Preprocessing arrays with this function has the effect of improving accuracy</span>
<span class="sd">    in various tasks such as image classification.</span>

<span class="sd">    At training time, this function is defined as</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{eqnarray}</span>
<span class="sd">          \mu &amp;=&amp; \frac{1}{M} \sum x_i \\</span>
<span class="sd">          y_i &amp;=&amp; x_i - \mu</span>
<span class="sd">        \end{eqnarray}</span>

<span class="sd">    At testing time, the mean values used are those that were computed during training by moving average.</span>

<span class="sd">    Note:</span>
<span class="sd">        The backward performs an approximated differentiation that takes into account only the latest mini-batch.</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array of input.</span>
<span class="sd">        mean(~nnabla.Variable): N-D array of running mean (modified during forward execution).</span>
<span class="sd">        t(~nnabla.Variable): Scalar of num of iteration of running mean (modified during forward execution).</span>
<span class="sd">        base_axis(int): Base axis of Mean Subtraction operation. Dimensions up to base_axis is treated as sample dimension.</span>
<span class="sd">            [default= `1` ]</span>
<span class="sd">        update_running_mean(bool): Update running mean during forward execution.</span>
<span class="sd">            [default= `True` ]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.mean_subtraction``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">mean_subtraction</span> <span class="k">as</span> <span class="n">mean_subtraction_base</span>
    <span class="k">return</span> <span class="n">mean_subtraction_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>
                                 <span class="n">base_axis</span><span class="o">=</span><span class="n">base_axis</span><span class="p">,</span>
                                 <span class="n">update_running_mean</span><span class="o">=</span><span class="n">update_running_mean</span><span class="p">)</span></div>


<div class="viewcode-block" id="fixed_point_quantize"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.fixed_point_quantize">[docs]</a><span class="k">def</span> <span class="nf">fixed_point_quantize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mi">2</span><span class="o">**-</span><span class="mi">4</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fixed Point Quantize.</span>

<span class="sd">    This function simulates to uniformly quantize values in fixed-point number representation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        sign (bool): Indicate the signed number or the unsigned number. Default is true.</span>
<span class="sd">        n (int): Bit width used. Note that `sign` consumes one bit. :math:`n-1` is used for number representation in `signed` case.   </span>
<span class="sd">        delta (float): Step size.</span>
<span class="sd">        quantize (bool): If true, quantize input, otherwise not.</span>
<span class="sd">        ste_fine_grained (bool): If true, STE is not 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.fixed_point_quantize``.</span>

<span class="sd">    In the forward pass, </span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{equation}</span>
<span class="sd">            q_i= \left\{</span>
<span class="sd">               \begin{array}{ll}</span>
<span class="sd">                    max &amp; if \ \ \ x_i &gt; max \\</span>
<span class="sd">                    sign(x_i) \times floor(|x_i| \delta^{-1} + 2^{-1}) \times \delta &amp; if \ \ min \le x_i \le max \\</span>
<span class="sd">                    min &amp; if \ \ x_i &lt; min \\</span>
<span class="sd">               \end{array} \right.,</span>
<span class="sd">        \end{equation}</span>

<span class="sd">    where :math:`\delta` is the step size, </span>
<span class="sd">    :math:`(min, max) :=(- (2^{n-1} - 1)\delta, (2^{n-1} - 1)\delta)` if :math:`sign` is true, </span>
<span class="sd">    :math:`(min, max) := (0, (2^n - 1) \delta)` otherwise, and  </span>
<span class="sd">    :math:`n` is the total bit-width used.</span>

<span class="sd">    In the backward pass when using `ste_fine_grained` as false,  </span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{equation}</span>
<span class="sd">            \frac{\partial q_i}{\partial x_i} = 1.</span>
<span class="sd">        \end{equation}</span>

<span class="sd">    In the backward pass when using `ste_fine_grained` as true,  </span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{equation}</span>
<span class="sd">            \frac{\partial q_i}{\partial x_i}= \left\{</span>
<span class="sd">                    \begin{array}{ll}</span>
<span class="sd">                                0 &amp; if \ \ \ x_i &gt; max \\</span>
<span class="sd">                            1 &amp; if \ \ min \le x_i \le max \\</span>
<span class="sd">                            0 &amp; if \ \ x_i &lt; min \\</span>
<span class="sd">                    \end{array} \right..</span>
<span class="sd">        \end{equation}</span>

<span class="sd">    .. note::</span>

<span class="sd">        Quantized values are stored as floating point number, since this function is for simulation purposes.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">fixed_point_quantize</span> <span class="k">as</span> <span class="n">fixed_point_quantize_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">quantize</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">fixed_point_quantize_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="pow2_quantize"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.pow2_quantize">[docs]</a><span class="k">def</span> <span class="nf">pow2_quantize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pow2 Quantize.</span>

<span class="sd">    This function simulates to uniformly quantize values in fixed-point number representation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        sign (bool): Indicate the signed number or the unsigned number. Default is true.</span>
<span class="sd">        with_zero (bool): Indicate using zero as a quantized value. Default is true. Note that `zero` consumes one bit.</span>
<span class="sd">        n (int): Bit width used. Note that `sign` consumes one bit. :math:`n-1` is used for number representation in `signed` case. Default is 8.   </span>
<span class="sd">        m (int): :math:`2^m` is the upper bound of the dynamic range and :math:`-2^m` is the lower bound, :math:`m \in \mathcal{Z}`. Default is 1.</span>
<span class="sd">        quantize (bool): If true, quantize input, otherwise not.</span>
<span class="sd">        ste_fine_grained (bool): If true, STE is not 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.pow2_quantize``.</span>

<span class="sd">    In the forward pass of `signed` case,  </span>

<span class="sd">    .. math::</span>

<span class="sd">       q_i= \left\{</span>
<span class="sd">           \begin{array}{ll}</span>
<span class="sd">                        max_{+} &amp; if \ \ \overline{q_i} &gt; max_{+} \\</span>
<span class="sd">                        \overline{q_i} &amp; if \ \ min_{+} \le \overline{q_i} \le max_{+} \\</span>
<span class="sd">                  min_{+} &amp; if \ \ 0 \le \overline{q_i} &lt; min_{+} \\</span>
<span class="sd">                  min_{-} &amp; if \ \ min_{-} &lt; \overline{q_i} &lt; 0 \\</span>
<span class="sd">                  \overline{q_i} &amp; if \ \ max_{-} \le \overline{q_i} \le min_{-}\\</span>
<span class="sd">                max_{-} &amp; if \ \ \overline{q_i} &lt; max_{-} \\</span>
<span class="sd">           \end{array} \right.,</span>

<span class="sd">    where </span>

<span class="sd">    .. math::</span>

<span class="sd">       &amp;&amp; max_{+} = 2^{m}, min_{+} = 2^{m - (2^{n-1} - 1)},\\  </span>
<span class="sd">       &amp;&amp; max_{-} = -2^{m}, min_{-} = -2^{m - (2^{n-1} - 1)},\\</span>
<span class="sd">       &amp;&amp; \overline{q_i} = sign(x_i) \times 2^{round(\log_2 |x_i|)}.</span>

<span class="sd">    This quantization uses the geometric mean between two power-of-two numbers </span>
<span class="sd">    as quantization threshold.   </span>

<span class="sd">    In the forward pass of `unsigned` case,  </span>

<span class="sd">    .. math::</span>

<span class="sd">       q_i= \left\{</span>
<span class="sd">           \begin{array}{ll}</span>
<span class="sd">                        max &amp; if \ \ \overline{q_i} &gt; max \\</span>
<span class="sd">                        \overline{q_i} &amp; if \ \ min \le \overline{q_i} \le max \\</span>
<span class="sd">                  min &amp; if \ \ 0 &lt; \overline{q_i} &lt; min \\</span>
<span class="sd">           \end{array} \right.,</span>

<span class="sd">    where </span>

<span class="sd">    .. math::</span>

<span class="sd">       &amp;&amp; max = 2^{m}, min = 2^{m - (2^{n} - 1)},\\  </span>
<span class="sd">       &amp;&amp; \overline{q_i} = 2^{int(\log_2 |x_i|)}.</span>


<span class="sd">    When using `with_zero` as true, a pruning threshold is used to round an input to </span>
<span class="sd">    0 or :math:`min`. The pruning threshold is defined in this function as the following, </span>

<span class="sd">    .. math::</span>

<span class="sd">       pruning\ threshold = min \times 2^{-\frac{1}{2}}.</span>

<span class="sd">    If an absolute value of the input is lesser than this value, the input is rounded to 0, otherwise :math:`min`. </span>

<span class="sd">    In the backward pass when using ste_fine_grained as false,</span>

<span class="sd">    .. math::</span>

<span class="sd">       \frac{\partial q_i}{\partial x_i} = 1.</span>

<span class="sd">    In the backward pass when using ste_fine_grained as true,</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial q_i}{\partial x_i}= \left\{</span>
<span class="sd">           \begin{array}{ll}</span>
<span class="sd">                    0 &amp; if \ \ \overline{q_i} &gt; max_{+} \\</span>
<span class="sd">                        1 &amp; if \ \ otherwise \\</span>
<span class="sd">                0 &amp; if \ \ \overline{q_i} &lt; max_{-} \\</span>
<span class="sd">           \end{array} \right.. </span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">pow2_quantize</span> <span class="k">as</span> <span class="n">pow2_quantize_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">quantize</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">pow2_quantize_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">with_zero</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="min_max_quantize"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.min_max_quantize">[docs]</a><span class="k">def</span> <span class="nf">min_max_quantize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">qr_min</span><span class="p">,</span> <span class="n">qr_max</span><span class="p">,</span> <span class="n">ql_min</span><span class="p">,</span> <span class="n">ql_max</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">x_min_max</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ema</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">ste_fine_grained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Min-max quantization.</span>

<span class="sd">    This function simulates to uniformly quantize values in fixed-point number representation.</span>

<span class="sd">    Min-max quantization is defined as the following equation</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = round \left(\frac{\min(\max(x, m), M) - m}{scale} \right) \times scale + m, </span>

<span class="sd">    where the :math:`scale` is defined as </span>

<span class="sd">    .. math::</span>

<span class="sd">        scale = \frac{M - m}{M_q - m_q}, </span>

<span class="sd">    and </span>

<span class="sd">    .. math::</span>

<span class="sd">        m_q = ql_{min}, \\</span>
<span class="sd">        M_q = ql_{max}, \\</span>
<span class="sd">        m = qr_{min}, \\</span>
<span class="sd">        M = qr_{max}.</span>

<span class="sd">    In the backward pass when using `ste_fine_grained` as false,</span>

<span class="sd">        .. math::</span>

<span class="sd">          \frac{\partial q_i}{\partial x_i} = 1.</span>


<span class="sd">    In the backward pass when using `ste_fine_grained` as true,</span>

<span class="sd">        .. math::</span>

<span class="sd">           \frac{\partial q_i}{\partial x_i}= \left\{</span>
<span class="sd">         \begin{array}{ll}</span>
<span class="sd">           0 &amp; if \ \ \ x_i &gt; M \\</span>
<span class="sd">           1 &amp; if \ \ m \le x_i \le M \\</span>
<span class="sd">           0 &amp; if \ \ x_i &lt; m \\</span>
<span class="sd">         \end{array} \right..</span>

<span class="sd">    :math:`qr_{min}` and :math:`qr_{max}` are treaded as follows.</span>

<span class="sd">        * `x_min_max` is `True` and `ema` is `True`: </span>
<span class="sd">          Exponential moving average are computed for each :math:`min(x)` and :math:`max(x)` </span>
<span class="sd">          then stored in :math:`qr_{min}` and :math:`qr_{max}`.</span>
<span class="sd">        * `x_min_max` is `True` and `ema` is `False`:</span>
<span class="sd">          :math:`min(x)` and :math:`max(x)` are computed then stored in :math:`qr_{min}` and :math:`qr_{max}`.</span>
<span class="sd">        * `x_min_max` is `False` and `ema` is `True`:</span>
<span class="sd">          Exponential moving average stored in :math:`qr_{min}` and :math:`qr_{max}` are used.</span>
<span class="sd">        * `x_min_max` is `False` and `ema` is `False`</span>
<span class="sd">          Gradients of :math:`qr_{min}` and :math:`qr_{max}` are computed in the backward pass.</span>

<span class="sd">    More precisely, in inference of the min-max quantization, one has to consider *zero-point (zp)*</span>
<span class="sd">    which corresponds</span>
<span class="sd">    to the real value 0, and its data type is an integer. *zero-point* is defined as </span>

<span class="sd">        .. math::</span>

<span class="sd">           &amp;&amp; zp_f = ql_{min} -\frac{qr_{min}}{scale}, \\</span>
<span class="sd">           &amp;&amp; zp = \left\{</span>
<span class="sd">         \begin{array}{ll}</span>
<span class="sd">           ql_{max} &amp; if \ \ \ zp_f &gt;= ql_{max} \\</span>
<span class="sd">           round(zp_f) &amp; if \ \ otherwise \\</span>
<span class="sd">           ql_{min}  &amp; if \ \ zp_f &lt;= ql_{min} \\</span>
<span class="sd">         \end{array} \right..</span>

<span class="sd">    Accordingly, in order to simulate quantization effect of *zero-point*, </span>
<span class="sd">    during both forward and backward pass, :math:`qr_{min}` and :math:`qr_{max}` are adjusted as follows,</span>

<span class="sd">        .. math::</span>

<span class="sd">           qr_{min}^{adj} = ql_{min} - zp * scale, \\</span>
<span class="sd">           qr_{max}^{adj} = ql_{max} - zp * scale.</span>

<span class="sd">    These operations are often called *nudge*. </span>

<span class="sd">    Finally, in the formulas of the min-max quantization, :math:`m` and :math:`M` are replaced by</span>
<span class="sd">    :math:`qr_{min}^{adj}` and :math:`qr_{max}^{adj}` respectively.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (~nnabla.Variable): Input N-D array.</span>
<span class="sd">        qr_min (~nnabla.Variable): Minimum quantization range (modified during forward execution).</span>
<span class="sd">        qr_max (~nnabla.Variable): Maximum quantization range (modified during forward execution).</span>
<span class="sd">        ql_min (~nnabla.Variable): Minimum quantization level, typically 0.</span>
<span class="sd">        ql_max (~nnabla.Variable): Maximum quantization level, typically 255.</span>
<span class="sd">        decay (float): The decay rate for the exponential moving average.</span>
<span class="sd">        x_min_max (bool): Use the min and max of x to compute quantization ranges. Default is `False`.</span>
<span class="sd">        ema (bool): Use the exponential moving average for the min and max quantization ranges.</span>
<span class="sd">                    Default is `False`.</span>
<span class="sd">        ste_fine_grained (bool): If `True`, STE is not 1, the {0, 1}-mask computed from the min-max is</span>
<span class="sd">                                 applied to the gradient in the backward; otherwise, STE is 1.</span>
<span class="sd">        eps (float): Epsilon, or small value to ensure :math:`qr_{max} - qr_{min}` must be greater</span>
<span class="sd">                     than the epsilon.</span>
<span class="sd">        quantize (bool): Apply quantization or not.</span>

<span class="sd">    References:</span>
<span class="sd">        Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko, &quot;Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference&quot;, https://arxiv.org/abs/1712.05877</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">min_max_quantize</span> <span class="k">as</span> <span class="n">min_max_quantize_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">quantize</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">min_max_quantize_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">qr_min</span><span class="p">,</span> <span class="n">qr_max</span><span class="p">,</span> <span class="n">ql_min</span><span class="p">,</span> <span class="n">ql_max</span><span class="p">,</span> <span class="n">decay</span><span class="p">,</span> <span class="n">x_min_max</span><span class="p">,</span> <span class="n">ema</span><span class="p">,</span>
                                 <span class="n">ste_fine_grained</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">quantize</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="clip_by_value"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.clip_by_value">[docs]</a><span class="k">def</span> <span class="nf">clip_by_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Clip inputs by values.</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = \begin{cases}</span>
<span class="sd">                max &amp; (x &gt; max) \\</span>
<span class="sd">                x &amp; (otherwise) \\</span>
<span class="sd">                min &amp; (x &lt; min)</span>
<span class="sd">            \end{cases}.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        min (Variable or float): A min variable or float value by which `x` is clipped. Note that if Variable is given, its shape must be the same as `x`&#39;s.</span>
<span class="sd">        max (Variable or float): A max variable or float value by which `x` is clipped. Note that if Variable is given, its shape must be the same as `x`&#39;s</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="nb">min</span><span class="p">):</span>
        <span class="n">maximum_base</span> <span class="o">=</span> <span class="n">maximum_scalar</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">NdArray</span><span class="p">)):</span>
        <span class="n">maximum_base</span> <span class="o">=</span> <span class="n">maximum2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;min must be Variable, NdArray, or scalar.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="nb">max</span><span class="p">):</span>
        <span class="n">minimum_base</span> <span class="o">=</span> <span class="n">minimum_scalar</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">NdArray</span><span class="p">)):</span>
        <span class="n">minimum_base</span> <span class="o">=</span> <span class="n">minimum2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;max must be Variable, NdArray, or scalar.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">minimum_base</span><span class="p">(</span><span class="n">maximum_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="p">),</span> <span class="nb">max</span><span class="p">)</span></div>


<div class="viewcode-block" id="clip_by_norm"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.clip_by_norm">[docs]</a><span class="k">def</span> <span class="nf">clip_by_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clip inputs by its L2 norm when the L2 norm is larger than the threshold value (defined by clip_norm).</span>
<span class="sd">    If it is less than the threshold, inputs are not modified. If it is applied, the operation is represented as</span>

<span class="sd">    .. math::</span>
<span class="sd">      y = N \times \frac{x}{\|x\|_2}.</span>

<span class="sd">    where :math:`x` is the input, :math:`y` is the output,</span>
<span class="sd">    and :math:`N` is `clip_norm`. this is the case that `axes` is not set.</span>
<span class="sd">    When `axes` is set, the norm is computed over `axes`.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        clip_norm (Variable or float): An input scalar variable or float value. Must be positive.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which the reduction is performed. Passing the default value `None` will reduce all dimensions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">sum_base</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">x_norm</span> <span class="o">=</span> <span class="n">pow_scalar</span><span class="p">(</span><span class="n">sum_base</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clip_norm</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">NdArray</span><span class="p">)):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">clip_norm</span> <span class="o">/</span> <span class="n">maximum2</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">clip_norm</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;clip_norm must be positive.&quot;</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">clip_norm</span> <span class="o">/</span> <span class="n">maximum_scalar</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span></div>


<div class="viewcode-block" id="interpolate"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.interpolate">[docs]</a><span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">half_pixel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">half_pixel_for_nn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">channel_last</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Resize an ND array with interpolation.</span>

<span class="sd">    Scaling factors for spatial dimensions are determined by either</span>
<span class="sd">    ``scale`` or ``output_size``.</span>

<span class="sd">    ``nd = len(scale)`` or ``nd = len(output_size)`` determines the number of</span>
<span class="sd">    spatial dimensions, and the last ``nd`` dimensions of the input ``x`` are    </span>
<span class="sd">    considered as the spatial dimensions to be resized.</span>


<span class="sd">    If ``scale`` is given, the ``output_size`` is calculated by</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">      output_size[i] = floor(scale[i] * x.shape[i - len(scale)]).</span>

<span class="sd">    Calculation of the coordinate transformation are as follows.</span>

<span class="sd">    The input coordinate i_input is computed by the output coordinate i_output,</span>
<span class="sd">    the input size size_input, and the output size size_output as</span>

<span class="sd">    .. table:: </span>
<span class="sd">        :align: center</span>
<span class="sd">        :widths: auto</span>

<span class="sd">        ================= ============== =================================================================</span>
<span class="sd">         align_corners     half_pixel                            i_input                                  </span>
<span class="sd">        ================= ============== =================================================================</span>
<span class="sd">              True             True       Not supported.</span>
<span class="sd">        ----------------- -------------- -----------------------------------------------------------------</span>
<span class="sd">              True             False      i_output * (size_input - 1) / (size_output - 1)                 </span>
<span class="sd">        ----------------- -------------- -----------------------------------------------------------------</span>
<span class="sd">              False            True       (i_output + 0.5) * size_input / size_output - 0.5               </span>
<span class="sd">        ----------------- -------------- -----------------------------------------------------------------</span>
<span class="sd">              False            False      i_output * size_input / size_output                             </span>
<span class="sd">        ================= ============== =================================================================</span>


<span class="sd">    In the case of the `nearest` mode and ``half_pixel_for_nn`` is ``True``, </span>
<span class="sd">    the input coordinate i_input is computed by the output coordinate i_output as</span>

<span class="sd">    .. code-block::</span>

<span class="sd">      i_input = (i_output + 0.5) * size_input / size_output.</span>


<span class="sd">    Example:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        x_data = np.random.rand(64, 3, 224, 224)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(x_data)</span>

<span class="sd">        # Resize by scales</span>
<span class="sd">        y = F.interpolate(x, scale=(2, 2), mode=&#39;linear&#39;)</span>
<span class="sd">        print(y.shape)  # (64, 3, 448, 448)</span>
<span class="sd">        y.forward()</span>
<span class="sd">        print(y.d)  # Print output</span>

<span class="sd">        # Resize to a size</span>
<span class="sd">        y2 = F.interpolate(x, output_size=(320, 257), mode=&#39;linear&#39;)</span>
<span class="sd">        print(y2.shape)  # (64, 3, 320, 257)</span>
<span class="sd">        y2.forward()</span>
<span class="sd">        print(y2.d)  # Print output</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array with an arbitrary number of dimensions.</span>
<span class="sd">        scale(tuple of ints): Scale factors along axes. The default is</span>
<span class="sd">            ``None``, and if this is omitted, ``output_size`` must be specified.</span>
<span class="sd">        output_size(tuple of ints): The output sizes for axes. If this is</span>
<span class="sd">            given, the scale factors are determined by the output sizes and the</span>
<span class="sd">            input sizes. The default is ``None``, and if this is omitted,</span>
<span class="sd">            ``scale`` must be specified.</span>
<span class="sd">        mode(str): Interpolation mode chosen from (&#39;linear&#39;|&#39;nearest&#39;).</span>
<span class="sd">            The default is &#39;linear&#39;.</span>
<span class="sd">        align_corners(bool): If true, the corner pixels of input and output</span>
<span class="sd">            arrays are aligned, such that the output corner pixels have the</span>
<span class="sd">            same values with the input corner pixels. Default is ``False``.</span>
<span class="sd">        half_pixel:</span>
<span class="sd">            If true, in the coordinate transformation, 0.5 is added to the output coordinate</span>
<span class="sd">            and 0.5 is subtracted from the input coordinate after scaling. Default is ``False``.</span>
<span class="sd">        half_pixel_for_nn: </span>
<span class="sd">            This is a special argument to support the backward-compatibility of the nearest neighbor interpolation.</span>
<span class="sd">            Default is ``False``. When in ``True``, the implementation of nearest neighbor interpolation</span>
<span class="sd">            is the old one.</span>
<span class="sd">        channel_last: Last dimension is the channel (NHWC order) if True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        Up to the version 1.8.0, the default of `align_corners` was ``None``, and it becomes ``True``</span>
<span class="sd">        if `mode` is linear, otherwise ``False``.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        Up to the version 1.8.0, the nearest `mode` interpolation corresponds to</span>
<span class="sd">        the nearest `mode` and `half_pixel_for_nn` = ``True`` after the version 1.8.0.</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">interpolate</span> <span class="k">as</span> <span class="n">interpolate_base</span>
    <span class="kn">import</span> <span class="nn">math</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">output_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Either scale or output_size must be given&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">output_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">channel_last</span> \
            <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">):]</span>
        <span class="n">output_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">d</span><span class="p">))</span>
                       <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">scale</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">interpolate_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">half_pixel</span><span class="p">,</span> <span class="n">half_pixel_for_nn</span><span class="p">,</span> <span class="n">channel_last</span><span class="p">)</span></div>


<div class="viewcode-block" id="sort"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.sort">[docs]</a><span class="k">def</span> <span class="nf">sort</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_index</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sorts the elements of `x` along a given `axis` in ascending order</span>
<span class="sd">    by value. A negative `axis` counts from the last dimension of `x`,</span>
<span class="sd">    so the default of -1 sorts along the last dimension. If `reverse`</span>
<span class="sd">    is True, then the elements are soreted in descending order.</span>

<span class="sd">    If `with_index` is True, result is a tuple ``(sorted, indices)``</span>
<span class="sd">    or only ``indices`` if `only_index` is True. Setting `only_index`</span>
<span class="sd">    to True implies that `with_index` is also True.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        nn.set_auto_forward(True)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))</span>

<span class="sd">        sorted = F.sort(x)</span>
<span class="sd">        assert np.allclose(sorted.d, np.sort(x.d))</span>

<span class="sd">        sorted, indices = F.sort(x, with_index=True)</span>
<span class="sd">        assert np.allclose(sorted.d, np.sort(x.d))</span>
<span class="sd">        assert np.all(indices.d == np.argsort(x.d))</span>

<span class="sd">        indices = F.sort(x, only_index=True)</span>
<span class="sd">        assert np.all(indices.d == np.argsort(x.d))</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array</span>
<span class="sd">        axis(int): Axis along which to sort.</span>
<span class="sd">        reverse(bool): Sort in descending order.</span>
<span class="sd">        with_index(bool): Return sorted values and index.</span>
<span class="sd">        only_index(bool): Return only the sort index.</span>

<span class="sd">    Returns: ~nnabla.Variable `sorted` or ~nnabla.Variable `indices` or (~nnabla.Variable `sorted`, ~nnabla.Variable `indices`)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">sort</span> <span class="k">as</span> <span class="n">sort_base</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">with_index</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">only_index</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">sort_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="n">with_index</span><span class="p">,</span> <span class="n">only_index</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="tile"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.tile">[docs]</a><span class="k">def</span> <span class="nf">tile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward `x` repeated the number of times given by `reps`. If `reps` is</span>
<span class="sd">    a sequence, the output has dimension of ``d = max(len(reps), x.ndim)`` and</span>
<span class="sd">    either `x` is promoted to be d-dimensional by prepending new axes or `reps`</span>
<span class="sd">    is promoted to x.ndim by prepending 1&#39;s.</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): Input N-D array.</span>
<span class="sd">        reps(int or sequence of int): Repetitions of `x` along each axis.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np, nnabla as nn, nnabla.functions as F</span>
<span class="sd">    &gt;&gt;&gt; F.tile(nn.Variable([2, 3]), 3).shape    # reps is promoted to [1, 3]</span>
<span class="sd">    (2, 9)</span>
<span class="sd">    &gt;&gt;&gt; F.tile(nn.Variable([3]), [2, 3]).shape  # x is promoted to shape (1, 3)</span>
<span class="sd">    (2, 9)</span>
<span class="sd">    &gt;&gt;&gt; nn.set_auto_forward(True)</span>
<span class="sd">    &gt;&gt;&gt; x = nn.Variable.from_numpy_array(np.array([1, 2, 3]))</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, 3).d)</span>
<span class="sd">    [1. 2. 3. 1. 2. 3. 1. 2. 3.]</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, [2, 3]).d)</span>
<span class="sd">    [[1. 2. 3. 1. 2. 3. 1. 2. 3.]</span>
<span class="sd">     [1. 2. 3. 1. 2. 3. 1. 2. 3.]]</span>
<span class="sd">    &gt;&gt;&gt; x = nn.Variable.from_numpy_array(np.array([[1, 3], [2, 4]]))</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, 3).d)</span>
<span class="sd">    [[1. 3. 1. 3. 1. 3.]</span>
<span class="sd">     [2. 4. 2. 4. 2. 4.]]</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, [2, 3]).d)</span>
<span class="sd">    [[1. 3. 1. 3. 1. 3.]</span>
<span class="sd">     [2. 4. 2. 4. 2. 4.]</span>
<span class="sd">     [1. 3. 1. 3. 1. 3.]</span>
<span class="sd">     [2. 4. 2. 4. 2. 4.]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">tile</span> <span class="k">as</span> <span class="n">tile_base</span>
    <span class="n">reps</span> <span class="o">=</span> <span class="p">[</span><span class="n">reps</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reps</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">reps</span>
    <span class="k">return</span> <span class="n">tile_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reps</span><span class="p">)</span></div>


<div class="viewcode-block" id="stft"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.stft">[docs]</a><span class="k">def</span> <span class="nf">stft</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">window_type</span><span class="o">=</span><span class="s1">&#39;hanning&#39;</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">,</span> <span class="n">as_istft_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the short-time Fourier transform</span>

<span class="sd">    Args:</span>
<span class="sd">        x (~nnabla.Variable): Time domain sequence of size `batch_size x sample_size`.</span>
<span class="sd">        window_size (int): Size of STFT analysis window.</span>
<span class="sd">        stride (int): Number of samples that we shift the window, also called `hop size`.</span>
<span class="sd">        fft_size (int): Size of the FFT, the output will have `fft_size // 2+ 1` frequency bins.</span>
<span class="sd">        window_type (str): Analysis window, can be either `hanning`, `hamming` or `rectangular`.</span>
<span class="sd">            For convenience, also `window_type=None` is supported which is equivalent to `window_type=&#39;rectangular&#39;`.</span>
<span class="sd">        center (bool): If `True`, then the signal `x` is padded by half the FFT size using reflection padding.</span>
<span class="sd">        pad_mode (str): Padding mode, which can be `&#39;constant&#39;` or `&#39;reflect&#39;`. `&#39;constant&#39;` pads with `0`.</span>
<span class="sd">        as_istft_backward: If `True`, then forward execution behaves as backward execution of ISTFT, </span>
<span class="sd">            treating input `x` as output gradient of ISTFT and outputs `y_r` and `y_i` as inputs gradient of ISTFT. </span>
<span class="sd">            This option is only used in nn.grad operator.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Returns real and imaginary parts of STFT result.</span>

<span class="sd">        * :obj:`~nnabla.Variable`: Real part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">        * :obj:`~nnabla.Variable`: Imaginary part of STFT of size `batch x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">stft</span> <span class="k">as</span> <span class="n">stft_base</span>
    <span class="k">if</span> <span class="n">window_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">window_type</span> <span class="o">=</span> <span class="s2">&quot;rectangular&quot;</span>
    <span class="k">return</span> <span class="n">stft_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">window_type</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">pad_mode</span><span class="p">,</span> <span class="n">as_istft_backward</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_stft_v1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">window_type</span><span class="o">=</span><span class="s1">&#39;hanning&#39;</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the short-time Fourier transform</span>

<span class="sd">    Args:</span>
<span class="sd">        x (~nnabla.Variable): Time domain sequence of size `batch_size x sample_size`.</span>
<span class="sd">        window_size (int): Size of STFT analysis window.</span>
<span class="sd">        stride (int): Number of samples that we shift the window, also called `hop size`.</span>
<span class="sd">        fft_size (int): Size of the FFT, the output will have `fft_size // 2+ 1` frequency bins.</span>
<span class="sd">        window_type (str): Analysis window, can be either `hanning`, `hamming` or `rectangular`.</span>
<span class="sd">            For convenience, also `window_type=None` is supported which is equivalent to `window_type=&#39;rectangular&#39;`.</span>
<span class="sd">        center (bool): If `True`, then the signal `x` is padded by half the FFT size using reflection padding.</span>
<span class="sd">        pad_mode (str): Padding mode, which can be `&#39;constant&#39;` or `&#39;reflect&#39;`. `&#39;constant&#39;` pads with `0`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Returns real and imaginary parts of STFT result.</span>

<span class="sd">        * :obj:`~nnabla.Variable`: Real part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">        * :obj:`~nnabla.Variable`: Imaginary part of STFT of size `batch x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">nnabla.parameter</span> <span class="kn">import</span> <span class="n">get_parameter</span><span class="p">,</span> <span class="n">get_parameter_or_create</span>
    <span class="n">conv_r</span> <span class="o">=</span> <span class="n">get_parameter</span><span class="p">(</span><span class="s1">&#39;conv_r&#39;</span><span class="p">)</span>
    <span class="n">conv_i</span> <span class="o">=</span> <span class="n">get_parameter</span><span class="p">(</span><span class="s1">&#39;conv_i&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">conv_r</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">conv_i</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s1">&#39;hanning&#39;</span><span class="p">:</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hanning</span><span class="p">(</span><span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s1">&#39;hamming&#39;</span><span class="p">:</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hamming</span><span class="p">(</span><span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s1">&#39;rectangular&#39;</span> <span class="ow">or</span> <span class="n">window_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown window type </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">window_type</span><span class="p">))</span>

        <span class="c1"># pad window if `fft_size &gt; window_size`</span>
        <span class="k">if</span> <span class="n">fft_size</span> <span class="o">&gt;</span> <span class="n">window_size</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">fft_size</span> <span class="o">-</span> <span class="n">window_size</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">window_func</span><span class="p">,</span> <span class="p">(</span><span class="n">diff</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">diff</span> <span class="o">-</span> <span class="n">diff</span><span class="o">//</span><span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">fft_size</span> <span class="o">&lt;</span> <span class="n">window_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;FFT size has to be as least as large as window size.&quot;</span><span class="p">)</span>

        <span class="c1"># compute STFT filter coefficients</span>
        <span class="n">mat_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">))</span>
        <span class="n">mat_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fft_size</span><span class="p">):</span>
                <span class="n">mat_r</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="n">fft_size</span><span class="p">)</span>
                <span class="n">mat_i</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="n">fft_size</span><span class="p">)</span>
        <span class="n">mat_r</span> <span class="o">=</span> <span class="n">mat_r</span> <span class="o">*</span> <span class="n">window_func</span>
        <span class="n">mat_i</span> <span class="o">=</span> <span class="n">mat_i</span> <span class="o">*</span> <span class="n">window_func</span>

        <span class="n">conv_r</span> <span class="o">=</span> <span class="n">get_parameter_or_create</span><span class="p">(</span>
            <span class="s1">&#39;conv_r&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">mat_r</span><span class="p">,</span> <span class="n">need_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">conv_i</span> <span class="o">=</span> <span class="n">get_parameter_or_create</span><span class="p">(</span>
            <span class="s1">&#39;conv_i&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">mat_i</span><span class="p">,</span> <span class="n">need_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">center</span><span class="p">:</span>
        <span class="c1"># pad at begin/end (per default this is a reflection padding)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">fft_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">fft_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>

    <span class="c1"># add channel dimension</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># compute STFT</span>
    <span class="n">y_r</span> <span class="o">=</span> <span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_r</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="n">stride</span><span class="p">,))</span>
    <span class="n">y_i</span> <span class="o">=</span> <span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_i</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="n">stride</span><span class="p">,))</span>

    <span class="k">return</span> <span class="n">y_r</span><span class="p">,</span> <span class="n">y_i</span>


<div class="viewcode-block" id="istft"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.istft">[docs]</a><span class="k">def</span> <span class="nf">istft</span><span class="p">(</span><span class="n">y_r</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">window_type</span><span class="o">=</span><span class="s1">&#39;hanning&#39;</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">,</span> <span class="n">as_stft_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the inverse shoft-time Fourier transform</span>

<span class="sd">    Note: We use a constant square inverse window for the reconstruction</span>
<span class="sd">    of the time-domain signal, therefore, the first and last</span>
<span class="sd">    `window_size - stride` are not perfectly reconstructed.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_r (~nnabla.Variable): Real part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">        y_i (~nnabla.Variable): Imaginary part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">        window_size (int): Size of STFT analysis window.</span>
<span class="sd">        stride (int): Number of samples that we shift the window, also called `hop size`.</span>
<span class="sd">        fft_size (int): Size of the FFT, (STFT has `fft_size // 2 + 1` frequency bins).</span>
<span class="sd">        window_type (str): Analysis window, can be either `hanning`, `hamming` or `rectangular`.</span>
<span class="sd">            For convenience, also `window_type=None` is supported which is equivalent to `window_type=&#39;rectangular&#39;`.</span>
<span class="sd">        center (bool): If `True`, then it is assumed that the time-domain signal has centered frames.</span>
<span class="sd">        pad_mode (str): Padding mode corresponding to STFT `pad_mode`, which can be `&#39;constant&#39;` or `&#39;reflect&#39;`. `&#39;constant&#39;` pads with `0`.</span>
<span class="sd">            This option is ignored for the normal use of ISTFT. You need to set the same `pad_mode` only when `as_stft_backward == True`.</span>
<span class="sd">        as_stft_backward (bool): If `True`, then forward execution behaves as backward execution of STFT,</span>
<span class="sd">            treating inputs `y_r` and `y_i` as outputs gradient of STFT and output `x` as input gradient of STFT.</span>
<span class="sd">            This option is only used in nn.grad operator.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: Time domain sequence of size `batch_size x sample_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">istft</span> <span class="k">as</span> <span class="n">istft_base</span>
    <span class="k">if</span> <span class="n">window_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">window_type</span> <span class="o">=</span> <span class="s2">&quot;rectangular&quot;</span>
    <span class="k">return</span> <span class="n">istft_base</span><span class="p">(</span><span class="n">y_r</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">window_type</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">pad_mode</span><span class="p">,</span> <span class="n">as_stft_backward</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_istft_v1</span><span class="p">(</span><span class="n">y_r</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">window_type</span><span class="o">=</span><span class="s1">&#39;hanning&#39;</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the inverse shoft-time Fourier transform</span>

<span class="sd">    Note: We use a constant square inverse window for the reconstruction</span>
<span class="sd">    of the time-domain signal, therefore, the first and last</span>
<span class="sd">    `window_size - stride` are not perfectly reconstructed.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_r (~nnabla.Variable): Real part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">        y_i (~nnabla.Variable): Imaginary part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`.</span>
<span class="sd">        window_size (int): Size of STFT analysis window.</span>
<span class="sd">        stride (int): Number of samples that we shift the window, also called `hop size`.</span>
<span class="sd">        fft_size (int): Size of the FFT, (STFT has `fft_size // 2 + 1` frequency bins).</span>
<span class="sd">        window_type (str): Analysis window, can be either `hanning`, `hamming` or `rectangular`.</span>
<span class="sd">            For convenience, also `window_type=None` is supported which is equivalent to `window_type=&#39;rectangular&#39;`.</span>
<span class="sd">        center (bool): If `True`, then it is assumed that the time-domain signal has centered frames.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: Time domain sequence of size `batch_size x sample_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">nnabla.parameter</span> <span class="kn">import</span> <span class="n">get_parameter</span><span class="p">,</span> <span class="n">get_parameter_or_create</span>
    <span class="n">conv_cos</span> <span class="o">=</span> <span class="n">get_parameter</span><span class="p">(</span><span class="s1">&#39;conv_cos&#39;</span><span class="p">)</span>
    <span class="n">conv_sin</span> <span class="o">=</span> <span class="n">get_parameter</span><span class="p">(</span><span class="s1">&#39;conv_sin&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">conv_cos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">conv_sin</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s1">&#39;hanning&#39;</span><span class="p">:</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hanning</span><span class="p">(</span><span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s1">&#39;hamming&#39;</span><span class="p">:</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hamming</span><span class="p">(</span><span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s1">&#39;rectangular&#39;</span> <span class="ow">or</span> <span class="n">window_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown window type </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">window_type</span><span class="p">))</span>

        <span class="c1"># pad window if `fft_size &gt; window_size`</span>
        <span class="k">if</span> <span class="n">fft_size</span> <span class="o">&gt;</span> <span class="n">window_size</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">fft_size</span> <span class="o">-</span> <span class="n">window_size</span>
            <span class="n">window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">window_func</span><span class="p">,</span> <span class="p">(</span><span class="n">diff</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">diff</span> <span class="o">-</span> <span class="n">diff</span><span class="o">//</span><span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">fft_size</span> <span class="o">&lt;</span> <span class="n">window_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;FFT size has to be as least as large as window size.&quot;</span><span class="p">)</span>

        <span class="c1"># compute inverse STFT filter coefficients</span>
        <span class="k">if</span> <span class="n">fft_size</span> <span class="o">%</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;FFT size needs to be a multiple of stride.&quot;</span><span class="p">)</span>

        <span class="n">inv_window_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">window_func</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
            <span class="n">inv_window_func</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">window_func</span><span class="p">),</span> <span class="n">s</span><span class="p">)</span>

        <span class="n">mat_cos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">))</span>
        <span class="n">mat_sin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fft_size</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">w</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">w</span> <span class="o">==</span> <span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span> <span class="k">else</span> <span class="mf">2.0</span>
            <span class="n">alpha</span> <span class="o">/=</span> <span class="n">fft_size</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fft_size</span><span class="p">):</span>
                <span class="n">mat_cos</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> \
                    <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="n">fft_size</span><span class="p">)</span>
                <span class="n">mat_sin</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> \
                    <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="n">fft_size</span><span class="p">)</span>
        <span class="n">mat_cos</span> <span class="o">=</span> <span class="n">mat_cos</span> <span class="o">*</span> <span class="n">window_func</span> <span class="o">/</span> <span class="n">inv_window_func</span>
        <span class="n">mat_sin</span> <span class="o">=</span> <span class="n">mat_sin</span> <span class="o">*</span> <span class="n">window_func</span> <span class="o">/</span> <span class="n">inv_window_func</span>

        <span class="n">conv_cos</span> <span class="o">=</span> <span class="n">get_parameter_or_create</span><span class="p">(</span>
            <span class="s1">&#39;conv_cos&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">mat_cos</span><span class="p">,</span> <span class="n">need_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">conv_sin</span> <span class="o">=</span> <span class="n">get_parameter_or_create</span><span class="p">(</span>
            <span class="s1">&#39;conv_sin&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">mat_sin</span><span class="p">,</span> <span class="n">need_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># compute inverse STFT</span>
    <span class="n">x_cos</span> <span class="o">=</span> <span class="n">deconvolution</span><span class="p">(</span><span class="n">y_r</span><span class="p">,</span> <span class="n">conv_cos</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="n">stride</span><span class="p">,))</span>
    <span class="n">x_sin</span> <span class="o">=</span> <span class="n">deconvolution</span><span class="p">(</span><span class="n">y_i</span><span class="p">,</span> <span class="n">conv_sin</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="n">stride</span><span class="p">,))</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">x_cos</span> <span class="o">-</span> <span class="n">x_sin</span><span class="p">,</span> <span class="p">(</span><span class="n">x_cos</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_cos</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">center</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="n">fft_size</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">x</span>


<div class="viewcode-block" id="gather_nd"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.gather_nd">[docs]</a><span class="k">def</span> <span class="nf">gather_nd</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Gather elements or slices from `data` according to `indices`, which must</span>
<span class="sd">    be at least two-dimensional with the first dimension :math:`M` being less or</span>
<span class="sd">    equal to the :math:`N` dimensions of `data`. Given `data` with shape</span>
<span class="sd">    :math:`(X_0, X_1, ..., X_{N-1})` and indices with shape :math:`(M, Y_0, ...,</span>
<span class="sd">    Y_{K-1})` output has shape :math:`(Y_0, ..., Y_{K-1}, X_M, ..., X_{N-1})`.</span>
<span class="sd">    If :math:`M == N`, output shape is simply :math:`(Y_0, ..., Y_{K-1})`.</span>

<span class="sd">    The forward of :func:`~nnabla.functions.gather_nd` is equivalent to:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">      def gather_nd(data, index):</span>
<span class="sd">          import numpy as np</span>
<span class="sd">          tmp_index = index.reshape(index.shape[0], -1)</span>
<span class="sd">          tmp_index = (idx + (Ellipsis,) for idx in zip(*new_index))</span>
<span class="sd">          out_shape = index.shape[1:] + data.shape[index.shape[0]:]</span>
<span class="sd">          return np.vstack(data[idx] for idx in tmp_index).reshape(*out_shape)</span>

<span class="sd">    Examples:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np, nnabla as nn, nnabla.functions as F</span>
<span class="sd">    &gt;&gt;&gt; nn.set_auto_forward(True)</span>
<span class="sd">    &gt;&gt;&gt; data = F.arange(1, 11).reshape([2, 5])</span>
<span class="sd">    &gt;&gt;&gt; print(data.d)</span>
<span class="sd">    [[ 1.  2.  3.  4.  5.]</span>
<span class="sd">     [ 6.  7.  8.  9. 10.]]</span>
<span class="sd">    &gt;&gt;&gt; F.gather_nd(data, [[1, 1, 0]]).shape</span>
<span class="sd">    (3, 5)</span>
<span class="sd">    &gt;&gt;&gt; F.gather_nd(data, [[1, 1, 0], [0, 1, 0]]).shape</span>
<span class="sd">    (3,)</span>
<span class="sd">    &gt;&gt;&gt; print(F.gather_nd(data, [[1, 1, 0], [0, 1, 0]]).d)</span>
<span class="sd">    [6. 7. 1.]</span>
<span class="sd">    &gt;&gt;&gt; print(F.gather_nd(data, [[1, 1, 0]]).d)</span>
<span class="sd">    [[ 6.  7.  8.  9. 10.]</span>
<span class="sd">     [ 6.  7.  8.  9. 10.]</span>
<span class="sd">     [ 1.  2.  3.  4.  5.]]</span>

<span class="sd">    When `indices` is provided as a :obj:`~nnabla.Variable` it will be possible</span>
<span class="sd">    to change the actual index values after function creation. It is important</span>
<span class="sd">    to note that out-of-bound indices raise errors when running on CPU but are</span>
<span class="sd">    ignored when using an accelerated computation context.</span>

<span class="sd">    &gt;&gt;&gt; indices = nn.Variable((2, 1))</span>
<span class="sd">    &gt;&gt;&gt; indices.d = [[0], [0]]</span>
<span class="sd">    &gt;&gt;&gt; y = F.gather_nd(data, indices)</span>
<span class="sd">    &gt;&gt;&gt; print(y.d)</span>
<span class="sd">    [1.]</span>
<span class="sd">    &gt;&gt;&gt; indices.d = [[1], [4]]</span>
<span class="sd">    &gt;&gt;&gt; y.forward()</span>
<span class="sd">    &gt;&gt;&gt; print(y.d)</span>
<span class="sd">    [10.]</span>

<span class="sd">    Args:</span>
<span class="sd">        data(~nnabla.Variable, ~nnabla.NdArray): input data</span>
<span class="sd">        indices(list, numpy.ndarray, ~nnabla.Variable, ~nnabla.NdArray): gather indices</span>

<span class="sd">    Returns: ~nnabla.Variable or ~nnabla.NdArray of gathered elements.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">gather_nd</span> <span class="k">as</span> <span class="n">gather_nd_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">NdArray</span><span class="p">)):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gather_nd_base</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span></div>


<div class="viewcode-block" id="scatter_nd"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.scatter_nd">[docs]</a><span class="k">def</span> <span class="nf">scatter_nd</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scatter `data` according to `indices` into a new array of given `shape`</span>
<span class="sd">    or an existing array provided as `out`. Exactly one of the `shape` or `out`</span>
<span class="sd">    argument must be given. Given output `shape`, or shape of `out` array,</span>
<span class="sd">    :math:`(X_0,X_1,\ldots,X_{N-1})` and `indices` shape</span>
<span class="sd">    :math:`(M,Y_0,\ldots,Y_{K-1})` the input `data` shape is</span>
<span class="sd">    :math:`(Y_0,\ldots,Y_{K-1},X_M,\ldots,X_{N-1})`, where :math:`M&lt;=N`. If</span>
<span class="sd">    :math:`M==N` the `data` shape is simply :math:`(Y_0,\ldots,Y_{K-1})`.</span>
<span class="sd">    Note that `indices` are treated as integers and potentially converted.</span>

<span class="sd">    The forward of :func:`~nnabla.functions.scatter_nd` is equivalent to:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">      def scatter_nd(data, indices, shape=None, out=None):</span>
<span class="sd">          assert (shape and not out) or (out and not shape)</span>
<span class="sd">          if isinstance(indices, numpy.ndarray)</span>
<span class="sd">              indices = indices.tolist()</span>
<span class="sd">          result = out if out else numpy.zeros(shape)</span>
<span class="sd">          result[indices] = data</span>
<span class="sd">          return result</span>

<span class="sd">    Examples:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np, nnabla as nn, nnabla.functions as F</span>
<span class="sd">    &gt;&gt;&gt; nn.set_auto_forward(True)</span>
<span class="sd">    &gt;&gt;&gt; data = nn.Variable.from_numpy_array(np.array([9, 10, 11, 12]))</span>
<span class="sd">    &gt;&gt;&gt; indices = nn.Variable.from_numpy_array(np.array([[4, 3, 1, 7]]))</span>
<span class="sd">    &gt;&gt;&gt; scattered = F.scatter_nd(data, indices, shape=(8,))</span>
<span class="sd">    &gt;&gt;&gt; print(scatterd.d)</span>
<span class="sd">    [ 0. 11.  0. 10.  9.  0.  0. 12.]</span>
<span class="sd">    &gt;&gt;&gt; print(F.gather_nd(scattered, indices).d)</span>
<span class="sd">    [ 9. 10. 11. 12.]</span>

<span class="sd">    Args:</span>
<span class="sd">        data(~nnabla.Variable, ~nnabla.NdArray): input data</span>
<span class="sd">        indices(list, numpy.ndarray, ~nnabla.Variable, ~nnabla.NdArray): scatter indices</span>
<span class="sd">        shape(tuple, list): shape of new output array</span>
<span class="sd">        out(~nnabla.Variable, ~nnabla.NdArray): existing output array</span>
<span class="sd">        add(tool): Add the input data to the same destination specified by the indices.</span>

<span class="sd">    Returns: ~nnabla.Variable or ~nnabla.NdArray of given `shape`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">scatter_nd</span> <span class="k">as</span> <span class="n">scatter_nd_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">NdArray</span><span class="p">)):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;One of `shape` or `out` argument must be supplied.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape</span> <span class="ow">and</span> <span class="n">out</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Only one of `shape` or `out` argument may be used.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">out</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">NdArray</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`out` argument must be NdArray or Variable type.&quot;</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">scatter_nd_base</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">add</span><span class="p">)</span></div>


<div class="viewcode-block" id="scatter_add"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.scatter_add">[docs]</a><span class="k">def</span> <span class="nf">scatter_add</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Add all values from `x1` into the `x0` according to index specified by `indices`.</span>
<span class="sd">    This function adds `x1` into the copy of `x0` and outputs the copy.</span>
<span class="sd">    The original `x0` will not be changed.</span>
<span class="sd">    `x0`, `indices` and `x1` must have same number of dimensions.</span>

<span class="sd">    The forward of :func:`~nnabla.functions.scatter_add` is equivalent to:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">      def scatter_add(x0, indices, x1, axis):</span>
<span class="sd">          # Assuming each input is 3 dimensional</span>
<span class="sd">          import numpy as np</span>
<span class="sd">          output = np.copy(x0)</span>
<span class="sd">          for i in range(indices.shape[0]):</span>
<span class="sd">              for j in range(indices.shape[1]):</span>
<span class="sd">                  for k in range(indices.shape[2]):</span>
<span class="sd">                      if axis == 0:</span>
<span class="sd">                          output[indices[i][j][k]][j][k] += x1[i][j][k]</span>
<span class="sd">                      elif axis == 1:</span>
<span class="sd">                          output[i][indices[i][j][k]][k] += x1[i][j][k]</span>
<span class="sd">                      elif axis == 2:</span>
<span class="sd">                          output[i][j][indices[i][j][k]] += x1[i][j][k]</span>
<span class="sd">          return output</span>

<span class="sd">    Args:</span>
<span class="sd">        x0(~nnabla.Variable): N-D array which the data is added to its copy.</span>
<span class="sd">        indices(~nnabla.Variable): N-D array scatter indices. </span>
<span class="sd">          The size of each dimension must be equal or smaller than that of x0 except for the specified axis. </span>
<span class="sd">          The value of indices must be smaller than the size of specified axis&#39; dimension of x0. </span>
<span class="sd">          The size of each dimension must be equal or smaller than that of x1. </span>
<span class="sd">          Indices must not be negative.</span>
<span class="sd">        x1(~nnabla.Variable): N-D array which is scattered and added to x0.</span>
<span class="sd">        axis(int): Axis along which to index. The axis must not exceed the inputs&#39; dimension.</span>
<span class="sd">            [default= `0` ]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array which contains the result of scatter addition. The shape is same as x0.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">scatter_add</span> <span class="k">as</span> <span class="n">scatter_add_base</span>
    <span class="k">return</span> <span class="n">scatter_add_base</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span></div>


<div class="viewcode-block" id="multi_head_attention"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.multi_head_attention">[docs]</a><span class="k">def</span> <span class="nf">multi_head_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">q_weight</span><span class="p">,</span> <span class="n">k_weight</span><span class="p">,</span> <span class="n">v_weight</span><span class="p">,</span> <span class="n">out_weight</span><span class="p">,</span> <span class="n">q_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">v_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_bias_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_bias_v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">additive_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;MultiHeadAttention.</span>

<span class="sd">    Computes multi-headed attention with query, key, and value.</span>
<span class="sd">    We use the following notations to describe the inputs and outputs below.</span>
<span class="sd">    :math:`L_T`: target sequence length, :math:`L_S`: source sequence length, :math:`B`: batch size, :math:`D`: input dimension, :math:`E`: embedding dimension, :math:`H`: number of attention heads.</span>

<span class="sd">    References:</span>

<span class="sd">        A. Vaswani et al. &quot;Attention is All You Need.&quot;</span>
<span class="sd">        NIPS. 2017.</span>
<span class="sd">        &lt;https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf&gt;</span>

<span class="sd">    Args:</span>
<span class="sd">        query (~nnabla.Variable): Input N-D array with shape :math:`(L_T, B, D_q)`.</span>
<span class="sd">        key (~nnabla.Variable): Input N-D array with shape :math:`(L_S, B, D_k)`.</span>
<span class="sd">        value (~nnabla.Variable): Input N-D array with shape :math:`(L_S, B, D_v)`.</span>
<span class="sd">        num_heads (int): Number of attention heads. Note that embedding dimensoin E must be divisible by the number of heads. Default is 12 which is conventional.</span>
<span class="sd">        q_weight (~nnabla.Variable): Input N-D array with shape :math:`(D_q, E)`.</span>
<span class="sd">        k_weight (~nnabla.Variable): Input N-D array with shape :math:`(D_k, E)`.</span>
<span class="sd">        v_weight (~nnabla.Variable): Input N-D array with shape :math:`(D_v, E_v)`.</span>
<span class="sd">        out_weight (~nnabla.Variable): Input N-D array with shape :math:`(D_v, E_{out})`.</span>
<span class="sd">        q_bias (~nnabla.Variable, optional): Input N-D array with shape :math:`(E, )`.</span>
<span class="sd">        k_bias (~nnabla.Variable, optional): Input N-D array with shape :math:`(E, )`.</span>
<span class="sd">        v_bias (~nnabla.Variable, optional): Input N-D array with shape :math:`(E_v, )`.</span>
<span class="sd">        out_bias (~nnabla.Variable, optional): Input N-D array with shape :math:`(E_{out}, )`.</span>
<span class="sd">        attn_bias_k (~nnabla.Variable, optional): Input N-D array with shape :math:`(E, )`.</span>
<span class="sd">        attn_bias_v (~nnabla.Variable, optional): Input N-D array with shape :math:`(E_v, )`.</span>
<span class="sd">        dropout (float, optional): Dropout ratio applied to parameters. Default is 0.</span>
<span class="sd">        additive_mask (~nnabla.Variable, optional): Input N-D array with shape :math:`(L_T, L_S)`. Values will be added to the attention layer to prevent attention to certain positions.</span>
<span class="sd">        key_padding_mask (~nnabla.Variable, optional): Input N-D array with shape :math:`(B, L_S)`. Specified padding elements will be ignored by the attention layer. Values must be either 1 or 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: Output :math:`y` with shape :math:`(L_T, B, E_{out})`</span>
<span class="sd">        ~nnabla.Variable: Output :math:`h_n` with shape :math:`(B, L_T, L_S)`</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

    <span class="n">tgt_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">src_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">q_embed_dim</span> <span class="o">=</span> <span class="n">q_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">k_embed_dim</span> <span class="o">=</span> <span class="n">k_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">v_embed_dim</span> <span class="o">=</span> <span class="n">v_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">src_len</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">head_dim</span> <span class="o">=</span> <span class="n">q_embed_dim</span> <span class="o">//</span> <span class="n">num_heads</span>
    <span class="n">head_vdim</span> <span class="o">=</span> <span class="n">v_embed_dim</span> <span class="o">//</span> <span class="n">num_heads</span>
    <span class="k">assert</span> <span class="n">q_embed_dim</span> <span class="o">==</span> <span class="n">k_embed_dim</span><span class="p">,</span> <span class="s2">&quot;embedding dimensions must be the same for query and key.&quot;</span>
    <span class="k">assert</span> <span class="n">head_dim</span> <span class="o">*</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="n">q_embed_dim</span><span class="p">,</span> <span class="s2">&quot;embedding dimension must be divisibile by num_heads </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">num_heads</span>
    <span class="k">assert</span> <span class="n">head_vdim</span> <span class="o">*</span> \
        <span class="n">num_heads</span> <span class="o">==</span> <span class="n">v_embed_dim</span><span class="p">,</span> <span class="s2">&quot;v_embed_dim must be divisibile by num_heads </span><span class="si">%d</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">num_heads</span>

    <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_size</span>
        <span class="k">assert</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">src_len</span>

    <span class="c1"># query:(L_T, B, E) --&gt; q:(L_T, B, E)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">affine</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">q_weight</span><span class="p">,</span> <span class="n">q_bias</span><span class="p">,</span> <span class="n">base_axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># key:(L_S, B, D_k) --&gt; k:(L_S, B, E_k)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">affine</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">k_weight</span><span class="p">,</span> <span class="n">k_bias</span><span class="p">,</span> <span class="n">base_axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># value:(L_S, B, D_v) --&gt; v:(L_S, B, E_v)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">affine</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">v_weight</span><span class="p">,</span> <span class="n">v_bias</span><span class="p">,</span> <span class="n">base_axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">q</span> <span class="o">*=</span> <span class="nb">float</span><span class="p">(</span><span class="n">head_dim</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>

    <span class="k">if</span> <span class="n">attn_bias_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">attn_bias_k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">attn_bias_k</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k_embed_dim</span><span class="p">))</span>
        <span class="n">attn_bias_v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">attn_bias_v</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">v_embed_dim</span><span class="p">))</span>
        <span class="n">src_len</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">attn_bias_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">attn_bias_k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
            <span class="n">attn_bias_k</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">attn_bias_k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">attn_bias_v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
            <span class="n">attn_bias_v</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">attn_bias_v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">attn_bias_k</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">attn_bias_v</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">additive_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># additive_mask: (L_T, L_S) --&gt; (L_T, L_S + 1)</span>
            <span class="n">additive_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">additive_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># key_padding_mask: (B, L_S) --&gt; (B, L_S + 1)</span>
            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">q</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="n">tgt_len</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># q:(B*H, L_T, head_dim)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># k:(B*H, L_S, head_dim)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">head_vdim</span><span class="p">)),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># v:(B*H, L_S, head_vdim)</span>

    <span class="c1"># attn_output_weights: (B*H, L_T, L_S)</span>
    <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">batch_matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">list</span><span class="p">(</span><span class="n">attn_output_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">[</span>
        <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">tgt_len</span><span class="p">,</span> <span class="n">src_len</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">additive_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">additive_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">additive_mask</span><span class="p">,</span> <span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">additive_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="n">attn_output_weights</span> <span class="o">+=</span> <span class="n">additive_mask</span>

    <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">attn_output_weights</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">tgt_len</span><span class="p">,</span> <span class="n">src_len</span><span class="p">))</span>
        <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">src_len</span><span class="p">)),</span>
                <span class="n">attn_output_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>  <span class="c1"># Condition</span>
            <span class="n">F</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">),</span>
                       <span class="n">shape</span><span class="o">=</span><span class="n">attn_output_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>  <span class="c1"># If true</span>
            <span class="n">attn_output_weights</span><span class="p">)</span>  <span class="c1"># If false</span>
        <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">attn_output_weights</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">tgt_len</span><span class="p">,</span> <span class="n">src_len</span><span class="p">))</span>

    <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
        <span class="n">attn_output_weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">attn_output_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span>
            <span class="n">attn_output_weights</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="c1"># (B*H, L_T, L_S) x (B*H, L_S, head_vdim) --&gt; (B*H, L_T, head_vdim)</span>
    <span class="n">attn_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">batch_matmul</span><span class="p">(</span><span class="n">attn_output_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">list</span><span class="p">(</span><span class="n">attn_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">[</span>
        <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">tgt_len</span><span class="p">,</span> <span class="n">head_vdim</span><span class="p">]</span>
    <span class="n">attn_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
        <span class="n">attn_output</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="p">(</span><span class="n">tgt_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">v_embed_dim</span><span class="p">))</span>  <span class="c1"># attn_output: (L_T, B, E_v)</span>

    <span class="n">attn_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">affine</span><span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="n">out_weight</span><span class="p">,</span> <span class="n">out_bias</span><span class="p">,</span> <span class="n">base_axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span></div>


<div class="viewcode-block" id="patch_correlation"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.patch_correlation">[docs]</a><span class="k">def</span> <span class="nf">patch_correlation</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">patch</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">shift</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">patch_step</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                      <span class="n">shift_step</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                      <span class="n">channel_last</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multiplicative patch-wise comparison between inputs `x1` and `x2`, which</span>
<span class="sd">    must both be 4-dimensional NCHW (with `channel_last=False`) or NHWC (with</span>
<span class="sd">    `channel_last=True`) arrays (where *N* is the number of samples, *H* and</span>
<span class="sd">    *W* are the sample height and width and *C* is the number of channels).</span>
<span class="sd">    The function returns a 5-D array with shape :math:`(N, C_y, C_x, H_o, W_o)`</span>
<span class="sd">    where :math:`H_o, W_o` are determined by the possible patch locations within</span>
<span class="sd">    the, optionally padded, input image sizeand :math:`C_y, C_x` are determined</span>
<span class="sd">    by the optionally shifted patch positions.</span>

<span class="sd">    Mathematically, the patch correlation is formulated as</span>

<span class="sd">    .. math::</span>

<span class="sd">       O(s_y, s_x, h_0, w_0) =</span>
<span class="sd">       \sum_{c} \sum_{k_h} \sum_{k_w} I_1(c, h + k_h, w + k_w) \times I_2(c, h + k_h + s_h, w + k_w + s_w), </span>

<span class="sd">    where :math:`I_1(c, h, w)` and :math:`I_2(c, h, w)` are the inputs at :math:`c`-th channel, </span>
<span class="sd">    :math:`h`-th height, and :math:`w`-th width, :math:`k_h, k_w` indices for the patch size </span>
<span class="sd">    and :math:`s_h, s_w` indices for the shifts.</span>

<span class="sd">    A single correlation value (per sample) is produced if the patch extends</span>
<span class="sd">    to the image dimensions and all other parameters use the default values.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np, nnabla as nn, nnabla.functions as F</span>
<span class="sd">    &gt;&gt;&gt; N, C, H, W = (1, 2, 3, 4)</span>
<span class="sd">    &gt;&gt;&gt; x = nn.Variable.from_numpy_array(np.ones([N, C, H, W]))</span>
<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, patch=(H, W)).d</span>
<span class="sd">    array([[[[[24.]]]]], dtype=float32)</span>

<span class="sd">    A patch that is smaller than the image size moves horizontal and vertical</span>
<span class="sd">    producing a value per position. The `patch_step` argument may be used to</span>
<span class="sd">    control the position increments.</span>

<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, patch=(H-1, W-1)).d</span>
<span class="sd">    array([[[[[12., 12.],</span>
<span class="sd">              [12., 12.]]]]], dtype=float32)</span>
<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, patch=(H-1, W-1), patch_step=(2, 1)).d</span>
<span class="sd">    array([[[[[12., 12.]]]]], dtype=float32)</span>

<span class="sd">    Multiple correlations may be performed at each position between the patch</span>
<span class="sd">    from `x1` and patches from `x2` at relative offsets striding the maximum</span>
<span class="sd">    vertical and horizontal distance given by the `shift` values at increments</span>
<span class="sd">    of `shift_step`. The shifted correlation values can be obtained for the</span>
<span class="sd">    from the second and third output dimension for the vertical and horizontal</span>
<span class="sd">    shifts.</span>

<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, (H, 1), shift=(0, 1)).shape</span>
<span class="sd">    (1, 1, 3, 1, 4)</span>
<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, (H, 1), shift=(0, 1)).d</span>
<span class="sd">    array([[[[[0., 6., 6., 6.]],</span>
<span class="sd">             [[6., 6., 6., 6.]],</span>
<span class="sd">             [[6., 6., 6., 0.]]]]], dtype=float32)</span>
<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, (H, 1), shift=(0, 1), shift_step=(1, 2)).d</span>
<span class="sd">    array([[[[[0., 6., 6., 6.]],</span>
<span class="sd">             [[6., 6., 6., 0.]]]]], dtype=float32)</span>

<span class="sd">    Padding with zero values may be applied individually to the top, bottom,</span>
<span class="sd">    left and right side of the input image.</span>

<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x, x, patch=(H, W), padding=(0, 1, W, W)).d</span>
<span class="sd">    array([[[[[ 0.,  6., 12., 18., 24., 18., 12.,  6.,  0.],</span>
<span class="sd">              [ 0.,  4.,  8., 12., 16., 12.,  8.,  4.,  0.]]]]], dtype=float32)</span>

<span class="sd">    This function may be used to implement the FlowNetC correlation layer.</span>

<span class="sd">    &gt;&gt;&gt; N, C, H, W = (1, 256, 44, 60)</span>
<span class="sd">    &gt;&gt;&gt; x1, x2 = nn.Variable((N, C, H, W)), nn.Variable((N, C, H, W))</span>
<span class="sd">    &gt;&gt;&gt; F.patch_correlation(x1, x2, shift=20, shift_step=2).shape</span>
<span class="sd">    (1, 21, 21, 44, 60)</span>

<span class="sd">    References:</span>

<span class="sd">        * `Fischer et al., FlowNet: Learning Optical Flow with Convolutional</span>
<span class="sd">          Networks. &lt;https://arxiv.org/abs/1504.06852&gt;`_</span>

<span class="sd">    Args:</span>
<span class="sd">        x1(~nnabla.Variable): Input N-D array with shape :math:`(N, C, H, W)`</span>
<span class="sd">            or :math:`(N, H, W, C)`.</span>
<span class="sd">        x2(~nnabla.Variable): Input N-D array with shape :math:`(N, C, H, W)`</span>
<span class="sd">            or :math:`(N, H, W, C)`.</span>
<span class="sd">        patch: A tuple with height and width of the correlation patch. A single</span>
<span class="sd">            integer expands to identical height and width.</span>
<span class="sd">        shift: A tuple of maximum vertical and horizontal displacement of</span>
<span class="sd">            patches from `x2` that are correlated with a single patch from `x1`.</span>
<span class="sd">            A single integer expands to identical vertical and horizontal</span>
<span class="sd">            displacement.</span>
<span class="sd">        patch_step: A tuple of vertical and horizontal increments for advancing</span>
<span class="sd">            the position of the correlation patch within the input image shape.</span>
<span class="sd">            A single integer expands to identical vertical and horizontal</span>
<span class="sd">            increments.</span>
<span class="sd">        shift_step: A tuple of vertical and horizontal increments for advancing</span>
<span class="sd">            the relative offset position within the shift range. A single</span>
<span class="sd">            integer expands to identical vertical and horizontal increments.</span>
<span class="sd">        padding: A tuple of top, bottom, left and right padding extent. A tuple</span>
<span class="sd">            of two values yields identical top/bottom and left/right padding</span>
<span class="sd">            from the first and second tuple value. A single integer expands to</span>
<span class="sd">            indential padding extent for all sides.</span>
<span class="sd">        channel_last: Last dimension is the channel (NHWC order) if True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array with shape :math:`(N, C_y, C_x, H_o, W_o)` or :math:`(N, H, W, C_y, C_x)` if `channel_last=True`.</span>

<span class="sd">          A spatial size of the output is calculated as</span>

<span class="sd">          .. math:: </span>

<span class="sd">            H_o = \frac{H + (top\_pad + bottom\_pad) - patch_v}{patch\_step_v} + 1.</span>

<span class="sd">          A channel size of the ouptut is calculated as</span>

<span class="sd">          .. math::</span>

<span class="sd">            C_y = \frac{2 \times shift_v}{shift\_step_v} + 1.</span>

<span class="sd">          :math:`W_o` and :math:`C_x` are the same calculation with differenct components.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">patch_correlation</span> <span class="k">as</span> <span class="n">patch_correlation_base</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Both inputs x1 and x2 must have 4 dimensions.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Both inputs x1 and x2 must have equal shape.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">patch</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">patch</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">shift</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch_step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">patch_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">patch_step</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shift_step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shift_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">shift_step</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span><span class="n">padding</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">padding</span><span class="p">):</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">channel_last</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">x2</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">x2</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">patch_correlation_base</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">patch</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">patch_step</span><span class="p">,</span> <span class="n">shift_step</span><span class="p">,</span>
                               <span class="n">padding</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">channel_last</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">y</span></div>


<span class="k">def</span> <span class="nf">quantize_linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span>
                    <span class="n">round_mode</span><span class="o">=</span><span class="s2">&quot;HALF_AWAY_FROM_ZERO&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Quantize linearly inputs with the scale and zero point.</span>

<span class="sd">      .. math::</span>

<span class="sd">          y = saturate(round(x / scale) + zero_point).</span>

<span class="sd">    :math:`saturate` rage is determined by `dtype` and :math:`round` mode is selected</span>
<span class="sd">    by `round_mode`. :math:`zero_point` is constrained by the `dtype` range and its values are</span>
<span class="sd">    rounded by `round_mode`.</span>

<span class="sd">    This function normally aligns with ONNX QuantizeLinear.</span>


<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        scale (Variable): Scale variable.</span>
<span class="sd">        zero_point (Variable): Zero point variable.</span>
<span class="sd">        round_mode (str): Rounding mode. HALF_AWAY_FROM_ZERO or HALF_TO_EVEN.</span>
<span class="sd">        narrow_range (bool): If true, this function does not use the minimum quantized value. For</span>
<span class="sd">            example, if `dtype` is int8 (the range is in [-128, 127]), the output range</span>
<span class="sd">            is corrected in [-127, 127].</span>
<span class="sd">        dtype (numpy.dtype): Data type for the output. Currently np.int8 or np.uint8 are supported.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">quantize_linear</span> <span class="k">as</span> <span class="n">quantize_linear_base</span>
    <span class="n">int_dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">np_dtpye_to_int</span><span class="p">[</span><span class="n">dtype</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">quantize_linear_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span>
                             <span class="n">round_mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">int_dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span> <span class="nf">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a one-dimensional vector/tensor of size `num` whose values are evenly spaced from `start` to `end`, inclusive.</span>

<span class="sd">    Args:</span>
<span class="sd">        start(float): Start value.</span>
<span class="sd">        stop(float): End value.</span>
<span class="sd">        num(int): Size of the constructed vector/tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: 1-D array with the generated values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="kn">import</span> <span class="n">linspace</span> <span class="k">as</span> <span class="n">linspace_base</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39; object cannot be interpreted as an integer&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">num</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Number of samples, </span><span class="si">{}</span><span class="s2">, must be non-negative.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">linspace_base</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>