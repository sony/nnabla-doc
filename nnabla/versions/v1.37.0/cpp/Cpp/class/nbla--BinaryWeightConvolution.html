<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>class nbla::BinaryWeightConvolution &mdash; Neural Network Libraries 1.37.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="class nbla::BitShift" href="nbla--BitShift.html" />
    <link rel="prev" title="class nbla::BinaryWeightAffine" href="nbla--BinaryWeightAffine.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Neural Network Libraries
          </a>
              <div class="version">
                1.37.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../python.html">Python Package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../cpp.html">C++ API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../installation.html">Build C++ libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../command_line_interface.html">C++ Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../examples.html">C++ API Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../doc.html">C++ API Document</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../cpp_api.html">NNABLA C++ API Document</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../class.html">NNABLA Class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../struct.html">NNABLA Struct</a></li>
<li class="toctree-l4"><a class="reference internal" href="../namespace.html">NNABLA Namespace</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../cpp.html">C++ API</a></li>
          <li class="breadcrumb-item"><a href="../../doc.html">C++ API Document</a></li>
          <li class="breadcrumb-item"><a href="../../cpp_api.html">NNABLA C++ API Document</a></li>
          <li class="breadcrumb-item"><a href="../class.html">NNABLA Class</a></li>
      <li class="breadcrumb-item active">class nbla::BinaryWeightConvolution</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/cpp/Cpp/class/nbla--BinaryWeightConvolution.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="class-nbla-binaryweightconvolution">
<h1>class nbla::BinaryWeightConvolution<a class="headerlink" href="#class-nbla-binaryweightconvolution" title="Permalink to this heading"></a></h1>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4I0EN4nbla23BinaryWeightConvolutionE">
<span id="_CPPv3I0EN4nbla23BinaryWeightConvolutionE"></span><span id="_CPPv2I0EN4nbla23BinaryWeightConvolutionE"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classnbla_1_1BinaryWeightConvolution"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">BinaryWeightConvolution</span></span></span><span class="w"> </span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="k"><span class="pre">public</span></span><span class="w"> </span><a class="reference internal" href="../namespace/nbla.html#_CPPv44nbla" title="nbla"><span class="n"><span class="pre">nbla</span></span></a><span class="p"><span class="pre">::</span></span><a class="reference internal" href="nbla--BaseFunction.html#_CPPv4IDpEN4nbla12BaseFunctionE" title="nbla::BaseFunction"><span class="n"><span class="pre">BaseFunction</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="kt"><span class="pre">float</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4I0EN4nbla23BinaryWeightConvolutionE" title="Permalink to this definition"></a><br /></dt>
<dd><p>N-D Binary Weight <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Convolution"><span class="std std-ref">Convolution</span></a> with bias. </p>
<p><p>Reference: Rastegari, Mohammad, et al. “XNOR-Net: ImageNet Classification Using</p>
<p>Binary Convolutional Neural Networks.” arXiv preprint arXiv:1603.05279 (2016).</p>
</p>
<p>NOTES:</p>
<p>1) if you would like to share weights between some layers, please make sure to share the standard, floating value weights (input parameter #2) and not the binarized weights (input parameter #3)</p>
<p>2) Only after a call to <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function_1ab4008cfbf032b728ded183647516075f"><span class="std std-ref">forward()</span></a> the weights and the binary weights are in sync, not after a call to <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function_1a2062f16de445fc0d1d5fe4ded349933a"><span class="std std-ref">backward()</span></a>. If wanting to store the parameters of the network, remember to call <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function_1ab4008cfbf032b728ded183647516075f"><span class="std std-ref">forward()</span></a> once before doing so, otherwise the weights and the binary weights will not be in sync.</p>
<p>Inputs ( <span class="math notranslate nohighlight">\(B\)</span> is base_axis):<ul class="simple">
<li><p>Input <span class="math notranslate nohighlight">\((B + 1 + N)\)</span>-D array ( <span class="math notranslate nohighlight">\(M_1 \times ... \times M_B \times C \times L_1 \times ... \times L_N\)</span>).</p></li>
<li><p>Weight <span class="math notranslate nohighlight">\((2 + N)\)</span>-D array ( <span class="math notranslate nohighlight">\(C' \times C \times K_1 \times ... \times K_N\)</span>).</p></li>
<li><p>Binary Weight <span class="math notranslate nohighlight">\((2 + N)\)</span>-D array ( <span class="math notranslate nohighlight">\(C' \times C \times K_1 \times ... \times K_N\)</span>).</p></li>
<li><p>Alpha <span class="math notranslate nohighlight">\(1\)</span>-D array ( <span class="math notranslate nohighlight">\(C'\)</span>).</p></li>
<li><p>(optional) Bias vector ( <span class="math notranslate nohighlight">\(C'\)</span>).</p></li>
</ul>
</p>
<p>Outputs:<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((B + 1 + N)\)</span>-D array ( <span class="math notranslate nohighlight">\( M_1 \times ... \times M_B \times C' \times L'_1 \times ... \times L'_N \)</span>).</p></li>
</ul>
</p>
<p><div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For Dilated <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Convolution"><span class="std std-ref">Convolution</span></a> (a.k.a a trous), refer to:<ul class="simple">
<li><p>Chen et al., DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Convolution"><span class="std std-ref">Convolution</span></a>, and Fully Connected CRFs. <a class="reference external" href="https://arxiv.org/abs/1606.00915">https://arxiv.org/abs/1606.00915</a></p></li>
<li><p>Yu et al., Multi-Scale <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Context"><span class="std std-ref">Context</span></a> Aggregation by Dilated Convolutions. <a class="reference external" href="https://arxiv.org/abs/1511.07122">https://arxiv.org/abs/1511.07122</a></p></li>
</ul>
</p>
</div>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>T</strong> – Data type for computation. </p>
</dd>
<dt class="field-even">Param base_axis<span class="colon">:</span></dt>
<dd class="field-even"><p>Base axis of <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Convolution"><span class="std std-ref">Convolution</span></a> operation. Dimensions up to base_axis is treated as sample dimension. </p>
</dd>
<dt class="field-odd">Param pad<span class="colon">:</span></dt>
<dd class="field-odd"><p>Padding sizes for dimensions. </p>
</dd>
<dt class="field-even">Param stride<span class="colon">:</span></dt>
<dd class="field-even"><p>Stride sizes for dimensions. </p>
</dd>
<dt class="field-odd">Param dilation<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dilation sizes for dimensions. </p>
</dd>
<dt class="field-even">Param group<span class="colon">:</span></dt>
<dd class="field-even"><p>Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction. </p>
</dd>
<dt class="field-odd">Param quantize_zero_to<span class="colon">:</span></dt>
<dd class="field-odd"><p>Input value at zero is quantized to this value.</p>
</dd>
</dl>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK4nbla23BinaryWeightConvolution4copyEv">
<span id="_CPPv3NK4nbla23BinaryWeightConvolution4copyEv"></span><span id="_CPPv2NK4nbla23BinaryWeightConvolution4copyEv"></span><span id="nbla::BinaryWeightConvolution::copyC"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1ab124b73cefe2044f4268fc5d5429184e"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="nbla--Function.html#_CPPv4N4nbla8FunctionE" title="nbla::Function"><span class="n"><span class="pre">Function</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">copy</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK4nbla23BinaryWeightConvolution4copyEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Copy another instance of <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function"><span class="std std-ref">Function</span></a> with the same context. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla23BinaryWeightConvolution8in_typesEv">
<span id="_CPPv3N4nbla23BinaryWeightConvolution8in_typesEv"></span><span id="_CPPv2N4nbla23BinaryWeightConvolution8in_typesEv"></span><span id="nbla::BinaryWeightConvolution::in_types"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1aa58caf4e8669067124bebde960c2be92"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="../namespace/nbla.html#_CPPv4N4nbla6dtypesE" title="nbla::dtypes"><span class="n"><span class="pre">dtypes</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">in_types</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla23BinaryWeightConvolution8in_typesEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get input dtypes. </p>
<p>Last in_type will be used repeatedly if size of in_types is smaller than size of inputs </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla23BinaryWeightConvolution9out_typesEv">
<span id="_CPPv3N4nbla23BinaryWeightConvolution9out_typesEv"></span><span id="_CPPv2N4nbla23BinaryWeightConvolution9out_typesEv"></span><span id="nbla::BinaryWeightConvolution::out_types"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1a2ed0c1f236a39e6f68d7b7440373a069"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="../namespace/nbla.html#_CPPv4N4nbla6dtypesE" title="nbla::dtypes"><span class="n"><span class="pre">dtypes</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">out_types</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla23BinaryWeightConvolution9out_typesEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get output dtypes. </p>
<p>Last out_type will be used repeatedly if size of out_types is smaller than size of outputs </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla23BinaryWeightConvolution10min_inputsEv">
<span id="_CPPv3N4nbla23BinaryWeightConvolution10min_inputsEv"></span><span id="_CPPv2N4nbla23BinaryWeightConvolution10min_inputsEv"></span><span id="nbla::BinaryWeightConvolution::min_inputs"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1afce5b4d9650d5fe5c7868e8e9bf1c6c6"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">min_inputs</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla23BinaryWeightConvolution10min_inputsEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get minimum number of inputs. </p>
<p>This is meant to be used in setup function with in_types which is used to get maximum number of inputs. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla23BinaryWeightConvolution11min_outputsEv">
<span id="_CPPv3N4nbla23BinaryWeightConvolution11min_outputsEv"></span><span id="_CPPv2N4nbla23BinaryWeightConvolution11min_outputsEv"></span><span id="nbla::BinaryWeightConvolution::min_outputs"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1a44b0402a6635b715f0bd6862568ad92b"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">min_outputs</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla23BinaryWeightConvolution11min_outputsEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get minimum number of outputs. </p>
<p>This is meant to be used in setup function with out_types which is used to get max number of outputs. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla23BinaryWeightConvolution4nameEv">
<span id="_CPPv3N4nbla23BinaryWeightConvolution4nameEv"></span><span id="_CPPv2N4nbla23BinaryWeightConvolution4nameEv"></span><span id="nbla::BinaryWeightConvolution::name"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1a97676bb97beb6bda645c86c78f8c1bdf"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">name</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla23BinaryWeightConvolution4nameEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get function name in string. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla23BinaryWeightConvolution21allowed_array_classesEv">
<span id="_CPPv3N4nbla23BinaryWeightConvolution21allowed_array_classesEv"></span><span id="_CPPv2N4nbla23BinaryWeightConvolution21allowed_array_classesEv"></span><span id="nbla::BinaryWeightConvolution::allowed_array_classes"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1ab4e3343ff7f0c0a862b7d10add535a6f"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">allowed_array_classes</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla23BinaryWeightConvolution21allowed_array_classesEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get array classes that are allowed to be specified by <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Context"><span class="std std-ref">Context</span></a>. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK4nbla23BinaryWeightConvolution24grad_depends_output_dataEii">
<span id="_CPPv3NK4nbla23BinaryWeightConvolution24grad_depends_output_dataEii"></span><span id="_CPPv2NK4nbla23BinaryWeightConvolution24grad_depends_output_dataEii"></span><span id="nbla::BinaryWeightConvolution::grad_depends_output_data__i.iC"></span><span class="target" id="classnbla_1_1BinaryWeightConvolution_1a6283199874216fb69619ec6cf3e6a7a5"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">grad_depends_output_data</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">i</span></span>, <span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">o</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK4nbla23BinaryWeightConvolution24grad_depends_output_dataEii" title="Permalink to this definition"></a><br /></dt>
<dd><p>Dependency flag for checking if in-grad depends on out-data. </p>
<p>Checking if i-th input’ gradient computation requires o-th output’s data or not.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If any of inputs requires an output variable data when computing its gradient, this function must be overridden to return appropriate boolean value. Otherwise, backward computation will be incorrect. </p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>i</strong> – <strong>[in]</strong> Input variable index. </p></li>
<li><p><strong>o</strong> – <strong>[in]</strong> Output variable index.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="nbla--BinaryWeightAffine.html" class="btn btn-neutral float-left" title="class nbla::BinaryWeightAffine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nbla--BitShift.html" class="btn btn-neutral float-right" title="class nbla::BitShift" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>