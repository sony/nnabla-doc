<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quantization-Aware-Training Tutorial &mdash; Neural Network Libraries 1.33.1 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Python Command Line Interface" href="../command_line_interface.html" />
    <link rel="prev" title="Function list and converter" href="function_list_and_converter.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Neural Network Libraries
          </a>
              <div class="version">
                1.33.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../python.html">Python Package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../installation.html">Python Package Installation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../tutorial.html">Python API Tutorial</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="by_examples.html">NNabla by Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="python_api.html">NNabla Python API Demonstration Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_finetuning.html">NNabla Models Finetuning Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_finetuning.html#finetuning-more">Finetuning more</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging.html">Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_and_static_nn.html">Static vs Dynamic Neural Networks in NNabla</a></li>
<li class="toctree-l3"><a class="reference internal" href="graph_converters.html">Graph Converters</a></li>
<li class="toctree-l3"><a class="reference internal" href="mixed_precision_training.html">Mixed Precision Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="multi_device_training.html">Data Parallel Distributed Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="function_list_and_converter.html">Function list and converter</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Quantization-Aware-Training Tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-is-model-quantization-aware-training">What is model Quantization-Aware-Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantization-aware-training-with-nnabla">Quantization-Aware-Training with NNabla</a></li>
<li class="toctree-l4"><a class="reference internal" href="#performance-of-the-quantized-model">Performance of the quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deploy-the-model-with-tensorrt">Deploy the model with TensorRT</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../command_line_interface.html">Python Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html">Python API Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html">Python API Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../../python.html">Python Package</a></li>
          <li class="breadcrumb-item"><a href="../tutorial.html">Python API Tutorial</a></li>
      <li class="breadcrumb-item active">Quantization-Aware-Training Tutorial</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/python/tutorial/quantization_aware_training.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quantization-aware-training-tutorial">
<h1>Quantization-Aware-Training Tutorial<a class="headerlink" href="#quantization-aware-training-tutorial" title="Permalink to this headline"></a></h1>
<section id="what-is-model-quantization-aware-training">
<h2>What is model Quantization-Aware-Training<a class="headerlink" href="#what-is-model-quantization-aware-training" title="Permalink to this headline"></a></h2>
<p>In general, the weights and the activations of artificial neural networks are represented by float32; on the other hand, model quantization means use lower precision to represent numbers, such as float16, int8 and uint8.</p>
<p>By reducing the precision we can reduce model size and memory occupancy. What’s more, on some devices we can also shorten the inference time.</p>
<p>However, using lower precision instead of float32 will introduces quantization error to the model. Quantization-Aware-Training (QAT) mitigates the quantization errors by simulating quantization effect at training time.</p>
</section>
<section id="quantization-aware-training-with-nnabla">
<h2>Quantization-Aware-Training with NNabla<a class="headerlink" href="#quantization-aware-training-with-nnabla" title="Permalink to this headline"></a></h2>
<p>In nnabla, we divide QAT into two stages, RERORDING and TRAINING.
In RECORDING stage, we will collect and record the dynamic range of each parameter and buffer.
In TRAINING stage, we will insert Quantization&amp;Dequantization node to simulate the quantization effect.</p>
<p>We provide QATScheduler to support Quantization-Aware-Training.
Here is some sample code about QATScheduler.</p>
<section id="create-qatscheduler">
<h3>Create QATScheduler<a class="headerlink" href="#create-qatscheduler" title="Permalink to this headline"></a></h3>
<p>Firstly, we need to create a QATScheduler. QATScheduler will convert the network automatically to make it support Quantization-Aware-Training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nnabla.utils.qnn</span> <span class="kn">import</span> <span class="n">QATScheduler</span><span class="p">,</span> <span class="n">QATConfig</span><span class="p">,</span> <span class="n">PrecisionMode</span>
<span class="c1"># Create training network</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Create validation network</span>
<span class="n">vpred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">vimage</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># configure of QATScheduler</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">QATConfig</span><span class="p">()</span>
<span class="n">config</span><span class="o">.</span><span class="n">bn_folding</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">config</span><span class="o">.</span><span class="n">bn_self_folding</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">config</span><span class="o">.</span><span class="n">channel_last</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">config</span><span class="o">.</span><span class="n">precision_mode</span> <span class="o">=</span> <span class="n">PrecisionMode</span><span class="o">.</span><span class="n">SIM_QNN</span>
<span class="n">config</span><span class="o">.</span><span class="n">skip_bias</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">config</span><span class="o">.</span><span class="n">niter_to_recording</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">config</span><span class="o">.</span><span class="n">niter_to_training</span> <span class="o">=</span> <span class="n">steps_per_epoch</span> <span class="o">*</span> <span class="mi">2</span>
<span class="c1"># Create a QATScheduler object</span>
<span class="n">qat_scheduler</span> <span class="o">=</span> <span class="n">QATScheduler</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">)</span>
<span class="c1"># register the training network to QATScheduler</span>
<span class="n">qat_scheduler</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="c1"># register the validation network to QATScheduler</span>
<span class="n">qat_scheduler</span><span class="p">(</span><span class="n">vpred</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="modify-your-training-loop">
<h3>Modify your training loop<a class="headerlink" href="#modify-your-training-loop" title="Permalink to this headline"></a></h3>
<p>In general, Your training loop should look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_step</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
    <span class="n">image</span><span class="o">.</span><span class="n">d</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backword</span><span class="p">()</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
<p>Compare with the training loop above. You just need to insert a line of code.
Inside the ‘step’ function, it records your training step and converts the network when the step reaches ‘niter_to_recording’ or ‘niter_to_recording’.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_step</span><span class="p">):</span>
    <span class="c1"># Run qat_scheduler step by step</span>
    <span class="n">qat_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
    <span class="n">image</span><span class="o">.</span><span class="n">d</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backword</span><span class="p">()</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
<span class="c1"># Save the QAT model</span>
<span class="n">qat_scheduler</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;your_model.nnp&#39;</span><span class="p">,</span> <span class="n">vimage</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">deploy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="performance-of-the-quantized-model">
<h2>Performance of the quantized model<a class="headerlink" href="#performance-of-the-quantized-model" title="Permalink to this headline"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 16%" />
<col style="width: 35%" />
<col style="width: 31%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>with BN-folding</p></th>
<th class="head"><p>float32 model validation error(%)</p></th>
<th class="head"><p>QAT model validation error(%)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mobilenetv1</p></td>
<td><p>NO</p></td>
<td><p>28.05</p></td>
<td><p>27.53</p></td>
</tr>
<tr class="row-odd"><td><p>Resnet18</p></td>
<td><p>NO</p></td>
<td><p>29.66</p></td>
<td><p>28.71</p></td>
</tr>
<tr class="row-even"><td><p>Resnet50</p></td>
<td><p>NO</p></td>
<td><p>23.46</p></td>
<td><p>23.19</p></td>
</tr>
<tr class="row-odd"><td><p>Mobilenetv1</p></td>
<td><p>YES</p></td>
<td><p>28.05</p></td>
<td><p>27.92</p></td>
</tr>
<tr class="row-even"><td><p>Resnet18</p></td>
<td><p>YES</p></td>
<td><p>29.66</p></td>
<td><p>28.63</p></td>
</tr>
<tr class="row-odd"><td><p>Resnet50</p></td>
<td><p>YES</p></td>
<td><p>23.46</p></td>
<td><p>23.16</p></td>
</tr>
</tbody>
</table>
<p>Above is some Quantization-Aware-Training experimental results on imagenet dataset.</p>
</section>
<section id="deploy-the-model-with-tensorrt">
<h2>Deploy the model with TensorRT<a class="headerlink" href="#deploy-the-model-with-tensorrt" title="Permalink to this headline"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 8%" />
<col style="width: 14%" />
<col style="width: 20%" />
<col style="width: 19%" />
<col style="width: 20%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>with pow2</p></th>
<th class="head"><p>with BN-folding</p></th>
<th class="head"><p>maximum absolute error</p></th>
<th class="head"><p>mean absolute error</p></th>
<th class="head"><p>maximum relative error</p></th>
<th class="head"><p>mean relative error</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NO</p></td>
<td><p>NO</p></td>
<td><p>0.0144</p></td>
<td><p>0.0094</p></td>
<td><p>9.9737</p></td>
<td><p>0.0907</p></td>
</tr>
<tr class="row-odd"><td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>4.639e-04</p></td>
<td><p>1.577e-04</p></td>
<td><p>13.3496</p></td>
<td><p>0.0151</p></td>
</tr>
<tr class="row-even"><td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>0.0378</p></td>
<td><p>0.0287</p></td>
<td><p>21.7627</p></td>
<td><p>0.0433</p></td>
</tr>
<tr class="row-odd"><td><p>YES</p></td>
<td><p>YES</p></td>
<td><p>4.673e-07</p></td>
<td><p>3.465e-07</p></td>
<td><p>0.00069</p></td>
<td><p>2.588e-08</p></td>
</tr>
</tbody>
</table>
<p>You can also deploy the NNabla QAT model with other framework by using our <a class="reference internal" href="../file_format_converter/file_format_converter.html#file-format-converter"><span class="std std-ref">File format converter</span></a> to convert .nnp to other format.
Above is the comparision between the output of NNabla and the output of TensorRT. The model we used to compare is mobilenetv1.
If you want to deploy the model with TensorRT, we recommend that you enable these options in QATConfig: ‘bn_folding’, ‘bn_self_folding’, ‘pow2’, otherwise, the error between NNabla and TensorRT may become large. See also QATTensorRTConfig (lined).</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="function_list_and_converter.html" class="btn btn-neutral float-left" title="Function list and converter" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../command_line_interface.html" class="btn btn-neutral float-right" title="Python Command Line Interface" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>