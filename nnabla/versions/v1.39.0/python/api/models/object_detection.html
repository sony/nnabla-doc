<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Object Detection Models &mdash; Neural Network Libraries 1.39.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Semantic Segmentation Models" href="semantic_segmentation.html" />
    <link rel="prev" title="ImageNet Models" href="imagenet.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Neural Network Libraries
          </a>
              <div class="version">
                1.39.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../python.html">Python Package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../installation.html">Python Package Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorial.html">Python API Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../command_line_interface.html">Python Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../examples.html">Python API Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../api.html">Python API Reference</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../common.html">Common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nd_array.html">NdArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../variable.html">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../computation_graph.html">Computation Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../function.html">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parametric_function.html">Parametric Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../grad.html">Grad</a></li>
<li class="toctree-l3"><a class="reference internal" href="../solver.html">Solvers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../callback.html">Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../communicator.html">Communicator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../monitor.html">Monitors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils.html">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ext.html">Extensions</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../models.html">Pretrained Models</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="imagenet.html">ImageNet Models</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Object Detection Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="semantic_segmentation.html">Semantic Segmentation Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../lms.html">Out-of-core execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../module.html">Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../graph_def.html">Graph Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sequential.html">Sequential</a></li>
<li class="toctree-l3"><a class="reference internal" href="../experimental.html">Experimental</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../python.html">Python Package</a></li>
          <li class="breadcrumb-item"><a href="../../api.html">Python API Reference</a></li>
          <li class="breadcrumb-item"><a href="../models.html">Pretrained Models</a></li>
      <li class="breadcrumb-item active">Object Detection Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/python/api/models/object_detection.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="object-detection-models">
<h1>Object Detection Models<a class="headerlink" href="#object-detection-models" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>This subpackage provides a pre-trained state-of-the-art models for the purpose of object detection which is trained on <a class="reference external" href="http://www.image-net.org/">ImageNet</a> dataset and fine-tuned on
<a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a> and <a class="reference external" href="http://www.cocodataset.org/">MS COCO</a> dataset.</p>
<p>The pre-trained models can be used for both inference and training as following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import required modules</span>
<span class="kn">import</span> <span class="nn">nnabla</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">nnabla.models.object_detection</span> <span class="kn">import</span> <span class="n">YoloV2</span>
<span class="kn">from</span> <span class="nn">nnabla.models.object_detection.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LetterBoxTransform</span><span class="p">,</span>
    <span class="n">draw_bounding_boxes</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nnabla.utils.image_utils</span> <span class="kn">import</span> <span class="n">imread</span><span class="p">,</span> <span class="n">imsave</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Set device</span>
<span class="kn">from</span> <span class="nn">nnabla.ext_utils</span> <span class="kn">import</span> <span class="n">get_extension_context</span>
<span class="n">nn</span><span class="o">.</span><span class="n">set_default_context</span><span class="p">(</span><span class="n">get_extension_context</span><span class="p">(</span><span class="s1">&#39;cudnn&#39;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">))</span>

<span class="c1"># Load and create a detection model</span>
<span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">608</span><span class="p">,</span> <span class="mi">608</span>
<span class="n">yolov2</span> <span class="o">=</span> <span class="n">YoloV2</span><span class="p">(</span><span class="s1">&#39;coco&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">yolov2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Load an image and scale it to fit inside the (h, w) frame</span>
<span class="n">img_orig</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="s1">&#39;dog.jpg&#39;</span><span class="p">)</span>
<span class="n">lbt</span> <span class="o">=</span> <span class="n">LetterBoxTransform</span><span class="p">(</span><span class="n">img_orig</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

<span class="c1"># Execute detection</span>
<span class="n">x</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">lbt</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">clear_buffer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Draw bounding boxes to the original image</span>
<span class="n">bboxes</span> <span class="o">=</span> <span class="n">lbt</span><span class="o">.</span><span class="n">inverse_coordinate_transform</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">img_draw</span> <span class="o">=</span> <span class="n">draw_bounding_boxes</span><span class="p">(</span>
    <span class="n">img_orig</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">yolov2</span><span class="o">.</span><span class="n">get_category_names</span><span class="p">())</span>
<span class="n">imsave</span><span class="p">(</span><span class="s2">&quot;detected.jpg&quot;</span><span class="p">,</span> <span class="n">img_draw</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-default" id="id3">
<caption><span class="caption-text">Available models trained on COCO dataset</span><a class="headerlink" href="#id3" title="Permalink to this table">ÔÉÅ</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Class</p></th>
<th class="head"><p>mAP</p></th>
<th class="head"><p>Training framework</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://nnabla.org/pretrained-models/nnp_models/object_detection/yolov2-coco.nnp">YOLO v2</a></p></td>
<td><p>YoloV2</p></td>
<td><p>44.12</p></td>
<td><p>Darknet</p></td>
<td><p>Weights converted from <a class="reference external" href="https://pjreddie.com/darknet/yolov2/">author‚Äôs model</a></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id4">
<caption><span class="caption-text">Available models trained on VOC dataset</span><a class="headerlink" href="#id4" title="Permalink to this table">ÔÉÅ</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Class</p></th>
<th class="head"><p>mAP</p></th>
<th class="head"><p>Training framework</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://nnabla.org/pretrained-models/nnp_models/object_detection/yolov2-voc.nnp">YOLO v2</a></p></td>
<td><p>YoloV2</p></td>
<td><p>76.00</p></td>
<td><p>Darknet</p></td>
<td><p>Weights converted from <a class="reference external" href="https://pjreddie.com/darknet/yolov2/">author‚Äôs model</a></p></td>
</tr>
</tbody>
</table>
<section id="module-nnabla.models.object_detection.base">
<span id="common-interfaces"></span><h2>Common interfaces<a class="headerlink" href="#module-nnabla.models.object_detection.base" title="Permalink to this heading">ÔÉÅ</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="nnabla.models.object_detection.base.ObjectDetection">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nnabla.models.object_detection.base.</span></span><span class="sig-name descname"><span class="pre">ObjectDetection</span></span><a class="reference internal" href="../../../_modules/nnabla/models/object_detection/base.html#ObjectDetection"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.models.object_detection.base.ObjectDetection" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="nnabla.models.object_detection.base.ObjectDetection.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_from</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_up_to</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'detection'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">returns_net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/nnabla/models/object_detection/base.html#ObjectDetection.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.models.object_detection.base.ObjectDetection.__call__" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Create a network (computation graph) from a loaded model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_var</strong> (<a class="reference internal" href="../variable.html#nnabla.Variable" title="nnabla.Variable"><em>Variable</em></a><em>, </em><em>optional</em>) ‚Äì If given, input variable is replaced with the given variable and a network is constructed on top of the variable. Otherwise, a variable with batch size as 1 and a default shape from <code class="docutils literal notranslate"><span class="pre">self.input_shape</span></code>.</p></li>
<li><p><strong>use_up_to</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) ‚Äì Network is constructed up to a variable specified by a string. A list of string-variable correspondences in a model is described in documentation for each model class.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) ‚Äì This option enables additional training (fine-tuning, transfer learning etc.) for the constructed network. If True, the <code class="docutils literal notranslate"><span class="pre">batch_stat</span></code> option in batch normalization is turned <code class="docutils literal notranslate"><span class="pre">True</span></code>, and <code class="docutils literal notranslate"><span class="pre">need_grad</span></code> attribute in trainable variables (conv weights and gamma and beta of bn etc.) is turned <code class="docutils literal notranslate"><span class="pre">True</span></code>. The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>returns_net</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) ‚Äì When <code class="docutils literal notranslate"><span class="pre">True</span></code>, it returns a <a class="reference internal" href="../utils/save_load.html#nnabla.utils.nnp_graph.NnpNetwork" title="nnabla.utils.nnp_graph.NnpNetwork"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NnpNetwork</span></code></a> object. Otherwise, It only returns the last variable of the constructed network. The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, or </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) ‚Äì Verbose level. With <code class="docutils literal notranslate"><span class="pre">0</span></code>, it says nothing during network construction.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nnabla.models.object_detection.base.ObjectDetection.input_shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_shape</span></span><a class="headerlink" href="#nnabla.models.object_detection.base.ObjectDetection.input_shape" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Should returns default image size (channel, height, width) as a tuple.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-nnabla.models.object_detection.utils"></span><dl class="py class">
<dt class="sig sig-object py" id="nnabla.models.object_detection.utils.LetterBoxTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nnabla.models.object_detection.utils.</span></span><span class="sig-name descname"><span class="pre">LetterBoxTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/nnabla/models/object_detection/utils.html#LetterBoxTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.models.object_detection.utils.LetterBoxTransform" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Create an object holding a new letterboxed image as <code class="xref any docutils literal notranslate"><span class="pre">image</span></code> attribute.</p>
<p>Letterboxing is defined as scaling the input image to fit inside the
desired output image frame (letterbox) while preserving the aspect
ratio of the original image. The pixels that are not filled with the
original image pixels become 127.</p>
<p>The created object also provides a functionality to convert bounding box
coordinates back to the original image frame.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.26)"><em>numpy.ndarray</em></a>) ‚Äì An uint8 3-channel image</p></li>
<li><p><strong>height</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) ‚Äì Letterbox height</p></li>
<li><p><strong>width</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) ‚Äì Letterbox width</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nnabla.models.object_detection.utils.LetterBoxTransform.inverse_coordinate_transform">
<span class="sig-name descname"><span class="pre">inverse_coordinate_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">coords</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/nnabla/models/object_detection/utils.html#LetterBoxTransform.inverse_coordinate_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.models.object_detection.utils.LetterBoxTransform.inverse_coordinate_transform" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Convert the bounding boxes back to the original image frame.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>coords</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.26)"><em>numpy.ndarray</em></a>) ‚Äì <a class="reference internal" href="../experimentals/mixed_precision_trainings.html#nnabla.experimental.mixed_precision_training.DynamicLossScalingUpdater.N" title="nnabla.experimental.mixed_precision_training.DynamicLossScalingUpdater.N"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">N</span></code></a> x <code class="xref any docutils literal notranslate"><span class="pre">M</span></code> array where <code class="xref any docutils literal notranslate"><span class="pre">M</span> <span class="pre">&gt;=</span> <span class="pre">4</span></code> and first 4 elements
of <code class="xref any docutils literal notranslate"><span class="pre">M</span></code> are <code class="xref any docutils literal notranslate"><span class="pre">x</span></code>, <code class="xref any docutils literal notranslate"><span class="pre">y</span></code> (center coordinates of bounding box),
<code class="xref any docutils literal notranslate"><span class="pre">w</span></code> and <code class="xref any docutils literal notranslate"><span class="pre">h</span></code> (bouding box width and height).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nnabla.models.object_detection.utils.draw_bounding_boxes">
<span class="sig-prename descclassname"><span class="pre">nnabla.models.object_detection.utils.</span></span><span class="sig-name descname"><span class="pre">draw_bounding_boxes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bboxes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/nnabla/models/object_detection/utils.html#draw_bounding_boxes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.models.object_detection.utils.draw_bounding_boxes" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>The transformed cordinates are further used to draw bounding boxes for the detected objects.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.26)"><em>numpy.ndarray</em></a>) ‚Äì Input image</p></li>
<li><p><strong>bboxes</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.26)"><em>numpy.ndarray</em></a>) ‚Äì Transformed bounding box coorinates from the model.</p></li>
<li><p><strong>names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) ‚Äì Name of categories in the dataset</p></li>
<li><p><strong>colors</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em> of </em><em>3 ints</em>) ‚Äì Colors for bunding boxes</p></li>
<li><p><strong>thresh</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) ‚Äì Threshold of bounding boxes.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-nnabla.models.object_detection">
<span id="list-of-models"></span><h2>List of models<a class="headerlink" href="#module-nnabla.models.object_detection" title="Permalink to this heading">ÔÉÅ</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="nnabla.models.object_detection.YoloV2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nnabla.models.object_detection.</span></span><span class="sig-name descname"><span class="pre">YoloV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'voc'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/nnabla/models/object_detection/yolov2.html#YoloV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.models.object_detection.YoloV2" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>The following is a list of string that can be specified to <code class="docutils literal notranslate"><span class="pre">use_up_to</span></code> option in <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method;</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'detection'</span></code> (default): The output from the last convolution (detection layer) after post-processing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'convdetect'</span></code>: The output of last convolution without post-processing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'lastconv'</span></code>: Network till the convolution layer+relu which comes before detection convolution layer.</p></li>
</ul>
<p class="rubric">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1612.08242">Joseph Redmon et al., YOLO9000: Better, Faster, Stronger.</a></p></li>
</ul>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="imagenet.html" class="btn btn-neutral float-left" title="ImageNet Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="semantic_segmentation.html" class="btn btn-neutral float-right" title="Semantic Segmentation Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>