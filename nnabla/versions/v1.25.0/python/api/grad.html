<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Grad &mdash; Neural Network Libraries 1.25.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Solvers" href="solver.html" />
    <link rel="prev" title="Parametric Functions" href="parametric_function.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Neural Network Libraries
          </a>
              <div class="version">
                1.25.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../python.html">Python Package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../installation.html">Python Package Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial.html">Python API Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../command_line_interface.html">Python Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html">Python API Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html">Python API Reference</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="common.html">Common</a></li>
<li class="toctree-l3"><a class="reference internal" href="nd_array.html">NdArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="variable.html">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="computation_graph.html">Computation Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="function.html">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="parametric_function.html">Parametric Functions</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Grad</a></li>
<li class="toctree-l3"><a class="reference internal" href="solver.html">Solvers</a></li>
<li class="toctree-l3"><a class="reference internal" href="communicator.html">Communicator</a></li>
<li class="toctree-l3"><a class="reference internal" href="monitor.html">Monitors</a></li>
<li class="toctree-l3"><a class="reference internal" href="utils.html">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="ext.html">Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="models.html">Pretrained Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="lms.html">Out-of-core execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="module.html">Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="graph_def.html">Graph Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="sequential.html">Sequential</a></li>
<li class="toctree-l3"><a class="reference internal" href="experimental.html">Experimental</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../python.html">Python Package</a> &raquo;</li>
          <li><a href="../api.html">Python API Reference</a> &raquo;</li>
      <li>Grad</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/python/api/grad.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-nnabla.grad">
<span id="grad"></span><h1>Grad<a class="headerlink" href="#module-nnabla.grad" title="Permalink to this headline"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="nnabla.grad.grad">
<span class="sig-prename descclassname"><span class="pre">nnabla.grad.</span></span><span class="sig-name descname"><span class="pre">grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bind_grad_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/grad.html#grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.grad.grad" title="Permalink to this definition"></a></dt>
<dd><p>Gradient function for the outputs with respect to the inputs.</p>
<p>The grad function computes the sum of gradients of the outputs w.r.t. the inputs.</p>
<div class="math notranslate nohighlight">
\[g_i = \sum_{j} {\frac{\partial y_j}{\partial x_i}},\]</div>
<p><span class="math notranslate nohighlight">\(y_j\)</span> is each output, <span class="math notranslate nohighlight">\(x_i\)</span> is each input, and <span class="math notranslate nohighlight">\(g_i\)</span> is the sum of the gradient of <span class="math notranslate nohighlight">\(y_j\)</span> w.r.t. <span class="math notranslate nohighlight">\(x_i\)</span> over all <span class="math notranslate nohighlight">\(j\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (list of <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a> or <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a>) – Outputs of the differentiable function.</p></li>
<li><p><strong>inputs</strong> (list of <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a> or <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a>) – Inputs w.r.t. which the gradients of outputs are computed.</p></li>
<li><p><strong>grad_outputs</strong> (None, scalar, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, <a class="reference internal" href="nd_array.html#nnabla.NdArray" title="nnabla.NdArray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.NdArray</span></code></a>, or list of scalar, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, or <a class="reference internal" href="nd_array.html#nnabla.NdArray" title="nnabla.NdArray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnabla.NdArray</span></code></a>,) – Gradient outputs corresponding to outputs. This is same as the grad argument of <a class="reference internal" href="variable.html#nnabla.Variable.backward" title="nnabla.Variable.backward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></a>. Default is None, so 1 is used as the in-coming gradient at the very beginning of the Variable in the gradient graph.</p></li>
<li><p><strong>persistent_outputs</strong> (list of <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><code class="xref any docutils literal notranslate"><span class="pre">bool</span></code></a>) – Outputs become persistent accordingly. If not specified, all outputs become persistent.</p></li>
<li><p><strong>bind_grad_output</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><code class="xref any docutils literal notranslate"><span class="pre">bool</span></code></a>) – Bind data to grad of input variable. This is useful for the case where one wants to use the gradient graph for training a neural network using the first-order gradients only. Default is False.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Returns</dt><dd><p>List of <a class="reference internal" href="variable.html#nnabla.Variable" title="nnabla.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code></a>.</p>
<p>If the backpropagation does not reach input(s), the corresponding returned value(s) are <a class="reference internal" href="nd_array.html#nnabla.NdArray.zero" title="nnabla.NdArray.zero"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">zero</span></code></a>
(i.e., the gradients w.r.t. inputs are zero) and not connected as a part of the gradient graph.</p>
</dd>
</dl>
<p>Example (Gradient Penalty):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.functions</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">nnabla.parametric_functions</span> <span class="k">as</span> <span class="nn">PF</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">nnabla.ext_utils</span> <span class="kn">import</span> <span class="n">get_extension_context</span>

<span class="c1"># Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">set_default_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>

<span class="c1"># Input and label</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Network</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pooling</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv2&quot;</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pooling</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">affine</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;pred&quot;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="c1"># Grad</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss</span><span class="p">]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
<span class="n">grads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>  <span class="c1"># gradients of the parameters</span>

<span class="c1"># Backward of the outputs w.r.t. the parameters by constraining the gradient norms.</span>
<span class="n">t</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># or 1</span>
<span class="n">gp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">])</span>
<span class="n">loss</span> <span class="o">+=</span> <span class="n">gp</span>
<span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p>Example (Higer-order Gradients):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">nnabla.functions</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">need_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">grad</span><span class="p">([</span><span class="n">dx</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">x</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">dx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">dnx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">dnx</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">d</span><span class="p">),</span> <span class="n">dnx</span><span class="o">.</span><span class="n">d</span><span class="p">))</span>
<span class="n">dnx</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">d</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">g</span><span class="p">))</span>

<span class="c1"># Show the supported status for each function</span>
<span class="kn">from</span> <span class="nn">nnabla.backward_functions</span> <span class="kn">import</span> <span class="n">show_registry</span>
<span class="n">show_registry</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nnabla.backward_functions.register">
<span class="sig-prename descclassname"><span class="pre">nnabla.backward_functions.</span></span><span class="sig-name descname"><span class="pre">register</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/backward_functions.html#register"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.backward_functions.register" title="Permalink to this definition"></a></dt>
<dd><p>Register the backward function to a function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The function class name, for example, Affine.</p></li>
<li><p><strong>func</strong> (<em>function</em>) – The function to be called as the backward function to the function <code class="xref any docutils literal notranslate"><span class="pre">func_name</span></code>..
Arguments of the func must be (ctx: nn.Context, inputs: list of nn.Variable, <a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs)..
The inputs are the ones to the function of the <code class="xref any docutils literal notranslate"><span class="pre">func_name</span></code>. The kwargs are
the arguments of the function. For example, if the <code class="xref any docutils literal notranslate"><span class="pre">func_name</span></code> is Affine,
func is <code class="xref any docutils literal notranslate"><span class="pre">affine_backward</span></code>, the inputs are data, weights, and bias if necessary, and
kwargs = dict(base_axis=base_axis).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nnabla.backward_functions.show_registry">
<span class="sig-prename descclassname"><span class="pre">nnabla.backward_functions.</span></span><span class="sig-name descname"><span class="pre">show_registry</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nnabla/backward_functions.html#show_registry"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnabla.backward_functions.show_registry" title="Permalink to this definition"></a></dt>
<dd><p>Show all backward fuctions registry</p>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="parametric_function.html" class="btn btn-neutral float-left" title="Parametric Functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="solver.html" class="btn btn-neutral float-right" title="Solvers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>