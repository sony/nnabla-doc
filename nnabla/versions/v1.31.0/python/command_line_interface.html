<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Python Command Line Interface &mdash; Neural Network Libraries 1.31.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Python API Examples" href="examples.html" />
    <link rel="prev" title="Quantization-Aware-Training Tutorial" href="tutorial/quantization_aware_training.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Neural Network Libraries
          </a>
              <div class="version">
                1.31.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../python.html">Python Package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="installation.html">Python Package Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial.html">Python API Tutorial</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Python Command Line Interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#work-with-nnp">Work with NNP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#profile">Profile</a></li>
<li class="toctree-l4"><a class="reference internal" href="#forward">Forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compare-with-cpu">Compare with CPU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-manipulation">Dataset manipulation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#encode-parameter">Encode parameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decode-parameter">Decode parameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#convert-dataset">Convert dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-image-classification-dataset">Create image classification dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#upload-dataset-to-neural-network-console">Upload dataset to Neural Network Console</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-dataset-archive-for-neural-network-console">Create dataset archive for Neural Network Console</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#file-format-converter">File format converter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dump-content-of-supported-format">Dump content of supported format</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-nnb-config-file-template">Generate NNB config file template</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">File format converter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#optimize-pb-model">Optimize pb model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#plot-monitor-class-output-files">Plot Monitor class output files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#monitorseries">MonitorSeries</a></li>
<li class="toctree-l4"><a class="reference internal" href="#monitortimeelapsed">MonitorTimeElapsed</a></li>
<li class="toctree-l4"><a class="reference internal" href="#draw-a-graph-from-nnp-or-nntxt-files">Draw a graph from NNP or .nntxt files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#development">Development</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#generate-function-information">Generate function information</a></li>
<li class="toctree-l4"><a class="reference internal" href="#display-version">Display version</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="examples.html">Python API Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html">Python API Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../python.html">Python Package</a> &raquo;</li>
      <li>Python Command Line Interface</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/python/command_line_interface.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="python-command-line-interface">
<h1>Python Command Line Interface<a class="headerlink" href="#python-command-line-interface" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>Nnabla has command line interface utility which can do train, forward(inference),
convert param and dataset, measure performance, file format converter and so on.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli [-h] [-m]
                  {train,infer,forward,encode_param,decode_param,profile,conv_dataset,compare_with_cpu,create_image_classification_dataset,upload,create_tar,function_info,optimize,dump,nnb_template,convert,plot_series,plot_timer,draw_graph,version}
                  ...

Command line interface for NNabla(Version 1.0.11.dev1, Build 181226024531)

positional arguments:
  {train,infer,forward,encode_param,decode_param,profile,conv_dataset,compare_with_cpu,create_image_classification_dataset,upload,create_tar,function_info,optimize,dump,nnb_template,convert,plot_series,plot_timer,draw_graph,version}
    train               Training with NNP.
    infer               Do inference with NNP and binary data file input.
    forward             Do evaluation with NNP and test dataset.
    encode_param        Encode plain text to parameter format.
    decode_param        Decode parameter to plain text.
    profile             Profiling performance with NNP.
    conv_dataset        Convert CSV dataset to cache.
    compare_with_cpu    Compare performance between two nntxt.
    create_image_classification_dataset
                        Create dataset from image files.
    upload              Upload dataset to Neural Network Console.
    create_tar          Create tar file for Neural Network Console.
    function_info       Output function info.
    optimize            Optimize pb model.
    dump                Dump network with supported format.
    nnb_template        Generate NNB config file template.
    convert             File format converter.
    plot_series         Plot *.series.txt files.
    plot_timer          Plot *.timer.txt files.
    draw_graph          Draw a graph in a NNP or nntxt file with graphviz.
    version             Print version and build number.

optional arguments:
  -h, --help            show this help message and exit
  -m, --mpi             exec with mpi.
</pre></div>
</div>
<section id="work-with-nnp">
<h2>Work with NNP<a class="headerlink" href="#work-with-nnp" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli train [-h] -c CONFIG [-p PARAM] -o OUTDIR

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to nntxt
  -p PARAM, --param PARAM
                        path to parameter file
  -o OUTDIR, --outdir OUTDIR
                        output directory
</pre></div>
</div>
</section>
<section id="profile">
<h3>Profile<a class="headerlink" href="#profile" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli profile [-h] -c CONFIG -o OUTDIR

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to nntxt
  -o OUTDIR, --outdir OUTDIR
                        output directory
</pre></div>
</div>
</section>
<section id="forward">
<h3>Forward<a class="headerlink" href="#forward" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli forward [-h] -c CONFIG [-p PARAM] [-d DATASET] -o OUTDIR [-b BATCH_SIZE]

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to nntxt
  -p PARAM, --param PARAM
                        path to parameter file
  -d DATASET, --dataset DATASET
                        path to CSV dataset
  -o OUTDIR, --outdir OUTDIR
                        output directory
  -b BATCH_SIZE, --batch_size BATCH_SIZE
                        Batch size to use batch size in nnp file set -1.
</pre></div>
</div>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli infer [-h] -c CONFIG [-o OUTPUT] [-p PARAM] [-b BATCH_SIZE] inputs [inputs ...]

positional arguments:
  inputs

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to nntxt
  -o OUTPUT, --output OUTPUT
                        output file prefix
  -p PARAM, --param PARAM
                        path to parameter file
  -b BATCH_SIZE, --batch_size BATCH_SIZE
                        Batch size to use batch size in nnp file set -1.
</pre></div>
</div>
</section>
<section id="compare-with-cpu">
<h3>Compare with CPU<a class="headerlink" href="#compare-with-cpu" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli compare_with_cpu [-h] -c CONFIG -c2 CONFIG2 -o OUTDIR

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to nntxt
  -c2 CONFIG2, --config2 CONFIG2
                        path to cpu nntxt
  -o OUTDIR, --outdir OUTDIR
                        output directory
</pre></div>
</div>
</section>
</section>
<section id="dataset-manipulation">
<h2>Dataset manipulation<a class="headerlink" href="#dataset-manipulation" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="encode-parameter">
<h3>Encode parameter<a class="headerlink" href="#encode-parameter" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli encode_param [-h] -i INDIR [-p PARAM]

optional arguments:
  -h, --help            show this help message and exit
  -i INDIR, --indir INDIR
                        input directory
  -p PARAM, --param PARAM
                        path to parameter file
</pre></div>
</div>
</section>
<section id="decode-parameter">
<h3>Decode parameter<a class="headerlink" href="#decode-parameter" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli decode_param [-h] [-p PARAM] -o OUTDIR

optional arguments:
  -h, --help            show this help message and exit
  -p PARAM, --param PARAM
                        path to parameter file
  -o OUTDIR, --outdir OUTDIR
                        output directory
</pre></div>
</div>
</section>
<section id="convert-dataset">
<h3>Convert dataset<a class="headerlink" href="#convert-dataset" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli conv_dataset [-h] [-F] [-S] [-N] source destination

positional arguments:
  source
  destination

optional arguments:
  -h, --help       show this help message and exit
  -F, --force      force overwrite destination
  -S, --shuffle    shuffle data
  -N, --normalize  normalize data range
</pre></div>
</div>
</section>
<section id="create-image-classification-dataset">
<h3>Create image classification dataset<a class="headerlink" href="#create-image-classification-dataset" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli create_image_classification_dataset [-h] -i SOURCEDIR -o OUTDIR -c CHANNEL -w WIDTH -g HEIGHT -m MODE -s SHUFFLE -f1 FILE1 [-r1 RATIO1] [-f2 FILE2]
                                                      [-r2 RATIO2]

optional arguments:
  -h, --help            show this help message and exit
  -i SOURCEDIR, --sourcedir SOURCEDIR
                        source directory with directories for each class
  -o OUTDIR, --outdir OUTDIR
                        output directory
  -c CHANNEL, --channel CHANNEL
                        number of output color channels
  -w WIDTH, --width WIDTH
                        width of output image
  -g HEIGHT, --height HEIGHT
                        height of output image
  -m MODE, --mode MODE  shaping mode (trimming or padding)
  -s SHUFFLE, --shuffle SHUFFLE
                        shuffle mode (true or false)
  -f1 FILE1, --file1 FILE1
                        output file name 1
  -r1 RATIO1, --ratio1 RATIO1
                        output file ratio(%) 1
  -f2 FILE2, --file2 FILE2
                        output file name 2
  -r2 RATIO2, --ratio2 RATIO2
                        output file ratio(%) 2
</pre></div>
</div>
</section>
<section id="upload-dataset-to-neural-network-console">
<h3>Upload dataset to Neural Network Console<a class="headerlink" href="#upload-dataset-to-neural-network-console" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli upload [-h] [-e ENDPOINT] token filename

positional arguments:
  token                 token for upload
  filename              filename to upload

optional arguments:
  -h, --help            show this help message and exit
  -e ENDPOINT, --endpoint ENDPOINT
                        set endpoint uri
</pre></div>
</div>
</section>
<section id="create-dataset-archive-for-neural-network-console">
<h3>Create dataset archive for Neural Network Console<a class="headerlink" href="#create-dataset-archive-for-neural-network-console" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli create_tar [-h] source destination

positional arguments:
  source       CSV dataset
  destination  TAR filename

optional arguments:
  -h, --help   show this help message and exit
</pre></div>
</div>
</section>
</section>
<section id="file-format-converter">
<h2>File format converter<a class="headerlink" href="#file-format-converter" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>For detailed information please see <a class="reference internal" href="file_format_converter/file_format_converter.html"><span class="doc">File format converter</span></a>.</p>
<section id="dump-content-of-supported-format">
<h3>Dump content of supported format<a class="headerlink" href="#dump-content-of-supported-format" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli dump [-h] [-v] [-F] [-V] [--dump-limit DUMP_LIMIT]
                       [-n DUMP_VARIABLE_NAME] [-I IMPORT_FORMAT]
                       [-E NNP_IMPORT_EXECUTOR_INDEX]
                       [--nnp-exclude-preprocess] [--nnp-no-expand-network]
                       FILE [FILE ...]

positional arguments:
  FILE                  File or directory name(s) to convert.

optional arguments:
  -h, --help            show this help message and exit
  -v, --dump-verbose    [dump] verbose output.
  -F, --dump-functions  [dump] dump function list.
  -V, --dump-variables  [dump] dump variable list.
  --dump-limit DUMP_LIMIT
                        [dump] limit num of items.
  -n DUMP_VARIABLE_NAME, --dump-variable-name DUMP_VARIABLE_NAME
                        [dump] Specific variable name to display.
  -I IMPORT_FORMAT, --import-format IMPORT_FORMAT
                        [import] import format. (one of [NNP,ONNX])
  -E NNP_IMPORT_EXECUTOR_INDEX, --nnp-import-executor-index NNP_IMPORT_EXECUTOR_INDEX
                        [import][NNP] import only specified executor.
  --nnp-exclude-preprocess
                        [import][NNP] EXPERIMENTAL exclude preprocess
                        functions when import.
  --nnp-no-expand-network
                        [import][NNP] expand network with repeat or recurrent.
</pre></div>
</div>
</section>
<section id="generate-nnb-config-file-template">
<h3>Generate NNB config file template<a class="headerlink" href="#generate-nnb-config-file-template" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli nnb_template [-h] [-I IMPORT_FORMAT]
                               [--nnp-no-expand-network] [-b BATCH_SIZE]
                               [-T DEFAULT_VARIABLE_TYPE]
                               FILE [FILE ...]

positional arguments:
  FILE                  File or directory name(s) to convert.

optional arguments:
  -h, --help            show this help message and exit
  -I IMPORT_FORMAT, --import-format IMPORT_FORMAT
                        [import] import format. (one of [NNP,ONNX])
  --nnp-no-expand-network
                        [import][NNP] expand network with repeat or recurrent.
  -b BATCH_SIZE, --batch-size BATCH_SIZE
                        [export] overwrite batch size.
  -T DEFAULT_VARIABLE_TYPE, --default-variable-type DEFAULT_VARIABLE_TYPE
                        Default type of variable
</pre></div>
</div>
</section>
<section id="id1">
<h3>File format converter<a class="headerlink" href="#id1" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli convert [-h] [-I IMPORT_FORMAT] [--nnp-no-expand-network]
                          [-O EXPORT_FORMAT] [-f] [-b BATCH_SIZE]
                          [--nnp-parameter-h5] [--nnp-parameter-nntxt]
                          [--nnp-exclude-parameter] [-T DEFAULT_VARIABLE_TYPE]
                          [-s SETTINGS] [-c CONFIG] [-d DEFINE_VERSION] [--api API]
                          [--enable-optimize-pb] [--outputs OUTPUTS]
                          [--inputs INPUTS] FILE [FILE ...]

positional arguments:
  FILE                  File or directory name(s) to convert.
                        (When convert ckpt format of the tensorflow model,
                        If the version of the checkpoint is V1, need to enter the `.ckpt` file,
                        otherwise need to enter the `.meta` file.)

optional arguments:
  -h, --help            show this help message and exit
  -I IMPORT_FORMAT, --import-format IMPORT_FORMAT
                        [import] import format. (one of [NNP,ONNX,TF_CKPT_V1,TF_CKPT_V2,TF_PB,SAVED_MODEL,TFLITE])
  --nnp-no-expand-network
                        [import][NNP] expand network with repeat or recurrent.
  --outputs OUTPUTS
                        [import][tensorflow] The name(s) of the output nodes, comma separated.
                                             Only needed when convert CKPT format.
  --inputs INPUTS
                        [import][tensorflow] The name(s) of the input nodes, comma separated.
                                             Only needed when convert CKPT format.
  -O EXPORT_FORMAT, --export-format EXPORT_FORMAT
                        [export] export format. (one of [NNP,NNB,CSRC,ONNX,SAVED_MODEL,TFLITE,TF_PB],
                                 the export file format is &#39;CSRC&#39; or &#39;SAVED_MODEL&#39; that
                                 argument &#39;--export-format&#39; will have to be set!!!)
  -f, --force           [export] overwrite output file.
  -b BATCH_SIZE, --batch-size BATCH_SIZE
                        [export] overwrite batch size.
  --nnp-parameter-h5    [export][NNP] store parameter with h5 format
  --nnp-parameter-nntxt
                        [export][NNP] store parameter into nntxt
  --nnp-exclude-parameter
                        [export][NNP] output without parameter
  -T DEFAULT_VARIABLE_TYPE, --default-variable-type DEFAULT_VARIABLE_TYPE
                        Default type of variable
  -s SETTINGS, --settings SETTINGS
                        Settings in YAML format file.
  -c CONFIG, --config CONFIG
                        [export] config target function list.
  -d DEFINE_VERSION, --define_version
                        [export][ONNX] define onnx opset version. e.g. opset_6
                        [export][ONNX] define convert to onnx for SNPE. e.g. opset_snpe
                        [export][ONNX] define convert to onnx for TensorRT. e.g. opset_tensorrt
                        [export][NNB] define binary format version. e.g. nnb_3
  --api API             [export][NNB] Set API Level to convert to, default is highest API Level.
  --enable-optimize-pb  [export][tensorflow] enable optimization when export to pb.
  --channel_last        [export][TFLite] Specify the data_format of the NNP network,
                                         data_format default is channel_first.
  --quantization        [export][TFLite] export to INT8 quantized tflite model.
  --dataset             [export][TFLite] Specify the path of represent dataset which will be passed to INT8 quantized tflite converter.
</pre></div>
</div>
</section>
<section id="optimize-pb-model">
<h3>Optimize pb model<a class="headerlink" href="#optimize-pb-model" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli optimize [-h] input_pb_file output_pb_file

positional arguments:
  input_pb_file       Input pre-optimized pb model.
  output_pb_file      Output optimized pb model.
</pre></div>
</div>
</section>
</section>
<section id="plot-monitor-class-output-files">
<h2>Plot Monitor class output files<a class="headerlink" href="#plot-monitor-class-output-files" title="Permalink to this heading">ÔÉÅ</a></h2>
<p><strong>Note</strong>:</p>
<ul class="simple">
<li><p>Plotting subcommands require matplotlib package.</p></li>
<li><p>By default, the following commands show a plot on your display using a
backend rendering engine of matplotlib depending on your environment.
If you want to save a plot as an image or a vector data, use <code class="docutils literal notranslate"><span class="pre">-o</span></code> option to
specifiy a file name where a plot is saved.</p></li>
</ul>
<section id="monitorseries">
<h3>MonitorSeries<a class="headerlink" href="#monitorseries" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli plot_series [-h] [-l LABEL] [-o OUTFILE] [-x XLABEL]
                              [-y YLABEL] [-t TITLE] [-T YLIM_MAX]
                              [-B YLIM_MIN] [-R XLIM_MAX] [-L XLIM_MIN]
                              infile [infile ...]

Plot *.series.txt files produced by nnabla.monitor.MonitorSeries class.

Example:

    nnabla_cli plot_series -x &quot;Epochs&quot; -y &quot;Squared error loss&quot; -T 10 -l &quot;config A&quot; -l &quot;config B&quot; result_a/Training-loss.series.txt result_b/Training-loss.series.txt

positional arguments:
  infile                Path to input file.

optional arguments:
  -h, --help            show this help message and exit
  -l LABEL, --label LABEL
                        Label of each plot.
  -o OUTFILE, --outfile OUTFILE
                        Path to output file.
  -x XLABEL, --xlabel XLABEL
                        X-axis label of plot.
  -y YLABEL, --ylabel YLABEL
                        Y-axis label of plot.
  -t TITLE, --title TITLE
                        Title of plot.
  -T YLIM_MAX, --ylim-max YLIM_MAX
                        Y-axis plot range max.
  -B YLIM_MIN, --ylim-min YLIM_MIN
                        Y-axis plot range min.
  -R XLIM_MAX, --xlim-max XLIM_MAX
                        X-axis plot range max.
  -L XLIM_MIN, --xlim-min XLIM_MIN
                        X-axis plot range min.
</pre></div>
</div>
</section>
<section id="monitortimeelapsed">
<h3>MonitorTimeElapsed<a class="headerlink" href="#monitortimeelapsed" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli plot_timer [-h] [-l LABEL] [-o OUTFILE] [-x XLABEL]
                             [-y YLABEL] [-t TITLE] [-T YLIM_MAX]
                             [-B YLIM_MIN] [-R XLIM_MAX] [-L XLIM_MIN] [-e]
                             [-u TIME_UNIT]
                             infile [infile ...]

Plot *.timer.txt files produced by nnabla.MonitorTimeElapsed class.

Example:

    nnabla_cli plot_timer -x &quot;Epochs&quot; -l &quot;config A&quot; -l &quot;config B&quot; result_a/Epoch-time.timer.txt result_b/Epoch-time.timer.txt

positional arguments:
  infile                Path to input file.

optional arguments:
  -h, --help            show this help message and exit
  -l LABEL, --label LABEL
                        Label of each plot.
  -o OUTFILE, --outfile OUTFILE
                        Path to output file.
  -x XLABEL, --xlabel XLABEL
                        X-axis label of plot.
  -y YLABEL, --ylabel YLABEL
                        Y-axis label of plot.
  -t TITLE, --title TITLE
                        Title of plot.
  -T YLIM_MAX, --ylim-max YLIM_MAX
                        Y-axis plot range max.
  -B YLIM_MIN, --ylim-min YLIM_MIN
                        Y-axis plot range min.
  -R XLIM_MAX, --xlim-max XLIM_MAX
                        X-axis plot range max.
  -L XLIM_MIN, --xlim-min XLIM_MIN
                        X-axis plot range min.
  -e, --elapsed         Plot total elapsed time. By default, it plots elapsed time per iteration.
  -u TIME_UNIT, --time-unit TIME_UNIT
                        Time unit chosen from {s|m|h|d}.
</pre></div>
</div>
</section>
<section id="draw-a-graph-from-nnp-or-nntxt-files">
<h3>Draw a graph from NNP or .nntxt files<a class="headerlink" href="#draw-a-graph-from-nnp-or-nntxt-files" title="Permalink to this heading">ÔÉÅ</a></h3>
<p><strong>Note</strong>:</p>
<ul class="simple">
<li><p>This feature requires <code class="docutils literal notranslate"><span class="pre">graphviz</span></code> installed as a <a class="reference external" href="https://graphviz.readthedocs.io/en/stable/manual.html#installation">Python package</a>. The <code class="docutils literal notranslate"><span class="pre">graphviz</span></code> Python is a interface to <a class="reference external" href="https://www.graphviz.org/">graphviz library</a> which is not installed by <code class="docutils literal notranslate"><span class="pre">pip</span></code> command. You have to install it using <code class="docutils literal notranslate"><span class="pre">apt</span></code> on Ubuntu for example.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli draw_graph [-h] [-o OUTPUT_DIR] [-n NETWORK] [-f FORMAT]
                             input

Draw a graph in a NNP or nntxt file with graphviz.

Example:

    nnabla_cli draw_graph -o output-folder path-to-nnp.nnp

positional arguments:
  input                 Path to input nnp or nntxt.

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        Output directory.
  -n NETWORK, --network NETWORK
                        Network names to be drawn.
  -f FORMAT, --format FORMAT
                        Graph saving format compatible with graphviz (`pdf`, `png`, ...).
</pre></div>
</div>
</section>
</section>
<section id="development">
<h2>Development<a class="headerlink" href="#development" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="generate-function-information">
<h3>Generate function information<a class="headerlink" href="#generate-function-information" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli function_info [-h] [-o OUTFILE] [-f FUNC_SET] [-c CONFIG]
                                [-t TARGET] [-q --query] [--nnp-no-expand-network]
                                [--api API] [FILE] [FILE ...]

positional arguments:
  FILE                  Path to nnp file.

optional arguments:
  -h, --help  show this help message and exit
  -o OUTFILE, --output OUTFILE
                      output filename, *.txt or *.yaml, the default is stdout.
  -f FUNC_SET, --all_support FUNC_SET
                      select function set: NNB, ONNX, the default is nnabla.
  -c CONFIG, --config CONFIG
                      user config file for target constraint, *.txt file of the
                      function list or the &quot;opset_&quot; args.
  -t, --target
                      output target function list.
  -q, --query
                      query the detail of a function.
  --nnp-no-expand-network
                      [import][NNP] expand network with repeat or recurrent.
  --api API           List up api levels
</pre></div>
</div>
</section>
<section id="display-version">
<h3>Display version<a class="headerlink" href="#display-version" title="Permalink to this heading">ÔÉÅ</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: nnabla_cli version [-h]

optional arguments:
  -h, --help  show this help message and exit
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tutorial/quantization_aware_training.html" class="btn btn-neutral float-left" title="Quantization-Aware-Training Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="examples.html" class="btn btn-neutral float-right" title="Python API Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>