

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>NNabla CUDA extension package installation using PIP &mdash; Neural Network Libraries 1.17.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Neural Network Libraries
          

          
          </a>

          
            
            
              <div class="version">
                1.17.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../python.html">Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Neural Network Libraries</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>NNabla CUDA extension package installation using PIP</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/python/pip_installation_cuda.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="nnabla-cuda-extension-package-installation-using-pip">
<span id="pip-installation-cuda"></span><h1>NNabla CUDA extension package installation using PIP<a class="headerlink" href="#nnabla-cuda-extension-package-installation-using-pip" title="Permalink to this headline">¶</a></h1>
<p>Note: please refer to the <a class="reference internal" href="installation.html#pip-os-specific"><span class="std std-ref">OS specific workflows</span></a> for the OS specific dependencies setup.</p>
<p>By installing the NNabla CUDA extension package <code class="docutils literal notranslate"><span class="pre">nnabla-ext-cuda</span></code>, you can accelerate the computation by NVIDIA CUDA GPU (CUDA must be setup on your environment accordingly).</p>
<p>Several pip packages of NNabla CUDA extension are provided for each CUDA version and its corresponding cuDNN version as following.</p>
<div class="section" id="cuda-vs-cudnn-compatibility">
<span id="cuda-cudnn-compatibility"></span><h2>CUDA vs cuDNN Compatibility<a class="headerlink" href="#cuda-vs-cudnn-compatibility" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 24%" />
<col style="width: 41%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package name</p></th>
<th class="head"><p>CUDA version</p></th>
<th class="head"><p>cuDNN version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>nnabla-ext-cuda100</p></td>
<td><p>10.0</p></td>
<td><p>7.6(Linux &amp; Win)</p></td>
</tr>
<tr class="row-odd"><td><p>nnabla-ext-cuda102</p></td>
<td><p>10.2</p></td>
<td><p>8.0(Linux &amp; Win)</p></td>
</tr>
<tr class="row-even"><td><p>nnabla-ext-cuda110</p></td>
<td><p>11.0</p></td>
<td><p>8.0(Linux &amp; Win)</p></td>
</tr>
</tbody>
</table>
<p>The latest CUDA version is always preferred if your GPU accepts.</p>
<p>Currently, for each NNabla CUDA extension package, it may be not compatible with some specific GPUs.</p>
<p>After nnabla-ext-cuda package is installed, you can manually check whether your GPU is usable.
For example, you can check GPU with device_id 0 by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnabla_ext.cudnn</span>
<span class="n">device_id</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="n">nnabla_ext</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">check_gpu</span><span class="p">(</span><span class="n">device_id</span><span class="p">)</span>
</pre></div>
</div>
<p>Above code will run successfully if your GPU is usable, otherwise, an error will be reported.</p>
<p>nnabla-ext-cuda package will also try to check the compatibility of your GPUs automatically when you use ‘cuda’ or ‘cudnn’ extension.
By default, it will list and check all gpus in your machine. Error will be reported if there is incompatible card.</p>
<p>You can set environment variable ‘AVAILABLE_GPU_NAMES’ to tell it which GPU is usable, ‘AVAILABLE_GPU_NAMES’ is a white list, GPU in ‘AVAILABLE_GPU_NAMES’ will not cause error.
For example, if you think GeForce RTX 3070 and GeForce RTX 3090 are usable, you can set environment variable as following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">AVAILABLE_GPU_NAMES</span><span class="o">=</span><span class="s2">&quot;GeForce RTX 3070,GeForce RTX 3090&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>The following is an example of installing the extension for CUDA 10.2</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install nnabla-ext-cuda102
</pre></div>
</div>
<p>and check if all works.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -c <span class="s2">&quot;import nnabla_ext.cuda, nnabla_ext.cudnn&quot;</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">2018</span>-06-26 <span class="m">15</span>:20:36,085 <span class="o">[</span>nnabla<span class="o">][</span>INFO<span class="o">]</span>: Initializing CPU extension...
<span class="m">2018</span>-06-26 <span class="m">15</span>:20:36,257 <span class="o">[</span>nnabla<span class="o">][</span>INFO<span class="o">]</span>: Initializing CUDA extension...
<span class="m">2018</span>-06-26 <span class="m">15</span>:20:36,257 <span class="o">[</span>nnabla<span class="o">][</span>INFO<span class="o">]</span>: Initializing cuDNN extension...
</pre></div>
</div>
<p><strong>Note</strong>: If you want to make sure the latest version will be installed, try to uninstall previously installed one with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">uninstall</span> <span class="pre">-y</span> <span class="pre">nnabla</span> <span class="pre">nnabla-ext-cuda100</span></code> beforehand.</p>
</div>
<div class="section" id="installation-with-multi-gpu-supported">
<span id="pip-installation-distributed"></span><h2>Installation with Multi-GPU supported<a class="headerlink" href="#installation-with-multi-gpu-supported" title="Permalink to this headline">¶</a></h2>
<p>Multi-GPU wheel package is only available on python3.6+.</p>
</div>
<div class="section" id="id1">
<span id="id2"></span><h2>CUDA vs cuDNN Compatibility<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>You can install as the following.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install nnabla
pip install nnabla-ext-cuda100-nccl2-mpi2-1-1
</pre></div>
</div>
<p>If you already installed NNabla, uninstall all of it, or start from a clean environment which you create using Anaconda, venv.</p>
<p>You should also install OpenMPI and NCCL in addition to CUDA and CuDNN.</p>
<p>If you are using Ubuntu18.04 and choose mpi2.1.1, you can install mpi with following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo apt install -y --no-install-recommends openmpi-bin libopenmpi-dev
</pre></div>
</div>
<p>Otherwise, you must install openmpi with following command.(MPIVER=3.1.6 or 2.1.1)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">MPIVER</span><span class="o">=</span><span class="m">3</span>.1.6
curl -O https://download.open-mpi.org/release/open-mpi/v<span class="si">${</span><span class="nv">MPIVER</span><span class="p">%.*</span><span class="si">}</span>/openmpi-<span class="si">${</span><span class="nv">MPIVER</span><span class="si">}</span>.tar.bz2
tar xvf openmpi-<span class="si">${</span><span class="nv">MPIVER</span><span class="si">}</span>.tar.bz2
<span class="nb">cd</span> openmpi-<span class="si">${</span><span class="nv">MPIVER</span><span class="si">}</span>
./configure --with-sge
make
sudo make install
</pre></div>
</div>
</div>
<div class="section" id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Permalink to this headline">¶</a></h2>
<div class="section" id="q-how-do-i-install-cuda">
<h3>Q. How do I install CUDA?<a class="headerlink" href="#q-how-do-i-install-cuda" title="Permalink to this headline">¶</a></h3>
<p>NNabla CUDA extension requires both CUDA toolkit and cuDNN library. You should select a proper CUDA version according to your CUDA device capability. See <a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html">the official installation guide</a>. NNabla supports CUDA versions later than 8.0. See <span class="xref std std-ref">the table</span> for the cuDNN compatibility with the specific CUDA versions.</p>
</div>
<div class="section" id="q-how-do-i-install-nccl">
<h3>Q. How do I install NCCL<a class="headerlink" href="#q-how-do-i-install-nccl" title="Permalink to this headline">¶</a></h3>
<p>Please visit <a class="reference external" href="https://developer.nvidia.com/nccl">NCCL</a>, then follow the instruction.</p>
</div>
<div class="section" id="q-how-do-i-check-proper-version-of-cudnn">
<h3>Q. How do I check proper version of cuDNN<a class="headerlink" href="#q-how-do-i-check-proper-version-of-cudnn" title="Permalink to this headline">¶</a></h3>
<p>Enter the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -c <span class="s2">&quot;import nnabla_ext.cuda, nnabla_ext.cudnn&quot;</span>
</pre></div>
</div>
<p>If there is a version mismatch on your machine, you can see proper versions in the error message.
Following is a sample error message.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>nnabla<span class="o">][</span>INFO<span class="o">]</span>: Initializing CPU extension...
Please install CUDA version <span class="m">10</span>.2.
  and cuDNN version <span class="m">8</span>.0
  Or install correct nnabla-ext-cuda <span class="k">for</span> installed version of CUDA/cuDNN.
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017, Sony Corporation.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>