

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nnabla.functions &mdash; Neural Network Libraries 1.0.16 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Neural Network Libraries
          

          
          </a>

          
            
            
              <div class="version">
                1.0.16
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../python.html">Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neural Network Libraries</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>nnabla.functions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nnabla.functions</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2017 Sony Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="n">reduce</span> <span class="k">as</span> <span class="n">rd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<div class="viewcode-block" id="sum"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.sum">[docs]</a><span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction along axes with sum operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which the sum is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">sum_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">sum_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<div class="viewcode-block" id="mean"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.mean">[docs]</a><span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction along axes with mean operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which mean is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">mean</span> <span class="k">as</span> <span class="n">mean_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mean_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<div class="viewcode-block" id="max"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.max">[docs]</a><span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_index</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduce the input N-D array `x` along the given `axis` using the max</span>
<span class="sd">    operation. The `axis` argument may be a single integer to reduce</span>
<span class="sd">    over one axis, a tuple of integers to reduce over multiple axes,</span>
<span class="sd">    or ``None`` to reduce over all axes. If `keepdims` is ``True``,</span>
<span class="sd">    the output will keep all reduced dimensions with size 1. If</span>
<span class="sd">    `with_index` is True, result is a tuple ``(sorted, indices)`` or</span>
<span class="sd">    only ``indices`` if `only_index` is True. Setting `only_index` to</span>
<span class="sd">    True implies that `with_index` is also True.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        nn.set_auto_forward(True)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))</span>

<span class="sd">        maxval = F.max(x, axis=1)</span>
<span class="sd">        assert np.allclose(maxval.d, np.max(x.d, axis=1))</span>

<span class="sd">        maxval, indices = F.max(x, axis=1, with_index=True)</span>
<span class="sd">        assert np.allclose(maxval.d, np.max(x.d, axis=1))</span>
<span class="sd">        assert np.all(indices.d == np.argmax(x.d, axis=1))</span>

<span class="sd">        indices = F.max(x, axis=1, only_index=True)</span>
<span class="sd">        assert np.all(indices.d == np.argmax(x.d, axis=1))</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which max is</span>
<span class="sd">            calculated. The default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims(bool): Keep reduced axes as dimension with 1 element.</span>
<span class="sd">        with_index(bool): Return tuple of max values and index.</span>
<span class="sd">        only_index(bool): Return only the index of max values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="nb">max</span> <span class="k">as</span> <span class="n">max_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">with_index</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">only_index</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">max_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">with_index</span><span class="p">,</span> <span class="n">only_index</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="min"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.min">[docs]</a><span class="k">def</span> <span class="nf">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_index</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduce the input N-D array `x` along the given `axis` using the min</span>
<span class="sd">    operation. The `axis` argument may be a single integer to reduce</span>
<span class="sd">    over one axis, a tuple of integers to reduce over multiple axes,</span>
<span class="sd">    or ``None`` to reduce over all axes. If `keepdims` is ``True``,</span>
<span class="sd">    the output will keep all reduced dimensions with size 1. If</span>
<span class="sd">    `with_index` is True, result is a tuple ``(sorted, indices)`` or</span>
<span class="sd">    only ``indices`` if `only_index` is True. Setting `only_index` to</span>
<span class="sd">    True implies that `with_index` is also True.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        nn.set_auto_forward(True)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))</span>

<span class="sd">        minval = F.min(x, axis=1)</span>
<span class="sd">        assert np.allclose(minval.d, np.min(x.d, axis=1))</span>

<span class="sd">        minval, indices = F.min(x, axis=1, with_index=True)</span>
<span class="sd">        assert np.allclose(minval.d, np.min(x.d, axis=1))</span>
<span class="sd">        assert np.all(indices.d == np.argmin(x.d, axis=1))</span>

<span class="sd">        indices = F.min(x, axis=1, only_index=True)</span>
<span class="sd">        assert np.all(indices.d == np.argmin(x.d, axis=1))</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which min is</span>
<span class="sd">            calculated. The default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims(bool): Keep reduced axes as dimension with 1 element.</span>
<span class="sd">        with_index(bool): Return tuple of min values and index.</span>
<span class="sd">        only_index(bool): Return only the index of min values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="nb">min</span> <span class="k">as</span> <span class="n">min_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">with_index</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">only_index</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">min_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">with_index</span><span class="p">,</span> <span class="n">only_index</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="prod"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.prod">[docs]</a><span class="k">def</span> <span class="nf">prod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction along axes with product operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which product is</span>
<span class="sd">            calculated. Passing the default value `None` will reduce all dimensions.</span>
<span class="sd">        keepdims (bool): Flag whether the reduced axes are kept as a dimension with 1 element.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Backward computation is not accurate in a zero value input.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">prod</span> <span class="k">as</span> <span class="n">prod_base</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">prod_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">reduce</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reduction function with given operation.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input.</span>
<span class="sd">        op (str): &#39;sum&#39; or &#39;mean&#39;.</span>

<span class="sd">    Note:</span>
<span class="sd">        This is deprecated. Use ``mean`` or ``sum`` instead.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;Deprecated API. Use ``sum`` or ``mean`` instead.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">reduce_sum</span><span class="p">,</span> <span class="n">reduce_mean</span>
    <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>


<div class="viewcode-block" id="split"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.split">[docs]</a><span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Split arrays at the specified axis.</span>

<span class="sd">    It returns a number corresponding the size of the given</span>
<span class="sd">    axis (i.e ``x.shape[axis]``) of :obj:`~nnabla.Variable` s.</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array</span>
<span class="sd">        axis(int): Axis</span>

<span class="sd">    Returns: A :obj:`tuple` of :obj:`~nnabla.Variable` s</span>

<span class="sd">    See Also:</span>
<span class="sd">        :func:`nnabla.function_bases.split`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">split</span> <span class="k">as</span> <span class="n">split_base</span>
    <span class="k">return</span> <span class="n">split_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">])</span></div>


<span class="nd">@function_api</span>
<span class="k">def</span> <span class="nf">slice</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Slice arrays along specified axis. This function </span>
<span class="sd">    complies with python slice wherre `slice(None, None, -1)` and </span>
<span class="sd">    `slice(-1, None, -1)` are the special case, which flips the </span>
<span class="sd">    input array and results in the output array from the end to the beginning</span>
<span class="sd">    of the input array along the corresponding dimension.</span>


<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array</span>
<span class="sd">        start(repeated int64): Start indices for each axis</span>
<span class="sd">            [default=``(0,) * len(x.shape)``]</span>
<span class="sd">        stop(repeated int64): Stop indices for each axis</span>
<span class="sd">            [default=``tuple(x.shape)``]</span>
<span class="sd">        step(repeated int64): Step indices for each axis</span>
<span class="sd">            [default=``(1,) * len(x.shape)``]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: Sliced N-D array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">copy</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">stop</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="nb">slice</span> <span class="k">as</span> <span class="n">slice_base</span>
    <span class="k">if</span> <span class="n">start</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stop</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sss</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">)):</span>
        <span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="o">=</span> <span class="n">sss</span>
        <span class="c1"># SPECIAL CASE: slice(-1, None, &lt;0) or slice(None, None, &lt;0)</span>
        <span class="n">SLICE_NONE</span> <span class="o">=</span> <span class="mh">0x7fffffff</span>
        <span class="k">if</span> <span class="n">s0</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">start</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">SLICE_NONE</span>
        <span class="k">if</span> <span class="n">s1</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stop</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">SLICE_NONE</span>
        <span class="k">if</span> <span class="n">s2</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">step</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">SLICE_NONE</span>
    <span class="k">return</span> <span class="n">slice_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>


<div class="viewcode-block" id="batch_normalization"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.batch_normalization">[docs]</a><span class="k">def</span> <span class="nf">batch_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">batch_stat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_stat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Batch normalization.</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{eqnarray}</span>
<span class="sd">          \mu &amp;=&amp; \frac{1}{M} \sum x_i \\</span>
<span class="sd">          \sigma^2 &amp;=&amp; \frac{1}{M} \sum \left(x_i - \mu\right)^2 \\</span>
<span class="sd">          \hat{x}_i &amp;=&amp; \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} \\</span>
<span class="sd">          y_i &amp;=&amp; \hat{x}_i \gamma + \beta.</span>
<span class="sd">        \end{eqnarray}</span>


<span class="sd">    At testing time, the mean and variance values used are those that were computed during training by moving average.</span>

<span class="sd">    References:</span>

<span class="sd">        * `Ioffe and Szegedy, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.</span>
<span class="sd">          &lt;https://arxiv.org/abs/1502.03167&gt;`_</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array of input.</span>
<span class="sd">        beta(~nnabla.Variable): N-D array of beta which is learned.</span>
<span class="sd">        gamma(~nnabla.Variable): N-D array of gamma which is learned.</span>
<span class="sd">        mean(~nnabla.Variable): N-D array of running mean (modified during forward execution).</span>
<span class="sd">        variance(~nnabla.Variable): N-D array of running variance (modified during forward execution).</span>
<span class="sd">        axes(repeated int64): Axes mean and variance are taken.</span>
<span class="sd">        decay_rate(float): Decay rate of running mean and variance.</span>
<span class="sd">        eps(float): Tiny value to avoid zero division by std.</span>
<span class="sd">        batch_stat(bool): Use mini-batch statistics rather than running ones.</span>
<span class="sd">        output_stat(bool): It true, the batch statistics of mean and variance,</span>
<span class="sd">            will be returned as Variables. They are also differentiable.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Returns batch normalization output as :obj:`~nnabla.Variable`.</span>
<span class="sd">        If ``output_stat=True``, it also returns the mean and variance</span>
<span class="sd">        of the mini-batch</span>

<span class="sd">        * :obj:`~nnabla.Variable`: Output of the batch normalization</span>
<span class="sd">        * :obj:`~nnabla.Variable`: Mean (if ``output_stat=True`)</span>
<span class="sd">        * :obj:`~nnabla.Variable`: Variance (if ``output_stat=True`)</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.batch_normalization``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">batch_normalization</span> <span class="k">as</span> <span class="n">batch_normalization_base</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">output_stat</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">batch_stat</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">output_stat</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">batch_stat</span> <span class="ow">and</span> <span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">parent</span> <span class="ow">or</span> <span class="n">variance</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;if batch_stat is True, mean and variable must not have a parent function&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_normalization_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span>
                                        <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span>
                                        <span class="n">decay_rate</span><span class="o">=</span><span class="n">decay_rate</span><span class="p">,</span>
                                        <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                                        <span class="n">batch_stat</span><span class="o">=</span><span class="n">batch_stat</span><span class="p">,</span>
                                        <span class="n">n_outputs</span><span class="o">=</span><span class="n">n_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transpose_and_reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
        <span class="n">transposed</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">transpose_axes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reshape</span><span class="p">(</span><span class="n">transposed</span><span class="p">,</span> <span class="p">[</span><span class="n">rd</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">transposed</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)])]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">transposed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">):])),</span> <span class="n">transposed</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">def</span> <span class="nf">inverse_transpose_and_reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">variable_shape</span><span class="p">):</span>
        <span class="n">un_reshaped</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">variable_shape</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)]</span> <span class="o">+</span> <span class="n">variable_shape</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">):]))</span>
        <span class="k">return</span> <span class="n">transpose</span><span class="p">(</span><span class="n">un_reshaped</span><span class="p">,</span> <span class="n">inv_transpose_axes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_tranpose_args</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
        <span class="n">transpose_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">axes</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">axes</span><span class="p">)]</span>
        <span class="n">inv_transpose_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">transpose_axes</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">transpose_axes</span><span class="p">,</span> <span class="n">inv_transpose_axes</span>

    <span class="n">transpose_axes</span><span class="p">,</span> <span class="n">inv_transpose_axes</span> <span class="o">=</span> <span class="n">get_tranpose_args</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">axes</span><span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">transposed_inp_shape</span> <span class="o">=</span> <span class="n">transpose_and_reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
    <span class="n">beta</span><span class="p">,</span> <span class="n">transposed_beta_shape</span> <span class="o">=</span> <span class="n">transpose_and_reshape</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
    <span class="n">gamma</span><span class="p">,</span> <span class="n">transposed_gamma_shape</span> <span class="o">=</span> <span class="n">transpose_and_reshape</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">transposed_mean_shape</span> <span class="o">=</span> <span class="n">transpose_and_reshape</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
    <span class="n">variance</span><span class="p">,</span> <span class="n">transposed_variance_shape</span> <span class="o">=</span> <span class="n">transpose_and_reshape</span><span class="p">(</span><span class="n">variance</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_outputs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">batch_normalization_base</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span>
                                       <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">decay_rate</span><span class="o">=</span><span class="n">decay_rate</span><span class="p">,</span>
                                       <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                                       <span class="n">batch_stat</span><span class="o">=</span><span class="n">batch_stat</span><span class="p">,</span>
                                       <span class="n">n_outputs</span><span class="o">=</span><span class="n">n_outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inverse_transpose_and_reshape</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">transposed_inp_shape</span><span class="p">)</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span> <span class="o">=</span> <span class="n">batch_normalization_base</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span>
                                                   <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                   <span class="n">decay_rate</span><span class="o">=</span><span class="n">decay_rate</span><span class="p">,</span>
                                                   <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                                                   <span class="n">batch_stat</span><span class="o">=</span><span class="n">batch_stat</span><span class="p">,</span>
                                                   <span class="n">n_outputs</span><span class="o">=</span><span class="n">n_outputs</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">inverse_transpose_and_reshape</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">transposed_inp_shape</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">inverse_transpose_and_reshape</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">transposed_mean_shape</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">inverse_transpose_and_reshape</span><span class="p">(</span>
        <span class="n">variance</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">transposed_variance_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span></div>


<div class="viewcode-block" id="mean_subtraction"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.mean_subtraction">[docs]</a><span class="k">def</span> <span class="nf">mean_subtraction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">base_axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">update_running_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    It subtracts the mean of the elements of the input array,</span>
<span class="sd">    and normalizes it to :math:`0`. Preprocessing arrays with this function has the effect of improving accuracy</span>
<span class="sd">    in various tasks such as image classification.</span>

<span class="sd">    At training time, this function is defined as</span>

<span class="sd">    .. math::</span>
<span class="sd">        \begin{eqnarray}</span>
<span class="sd">          \mu &amp;=&amp; \frac{1}{M} \sum x_i \\</span>
<span class="sd">          y_i &amp;=&amp; x_i - \mu</span>
<span class="sd">        \end{eqnarray}</span>

<span class="sd">    At testing time, the mean values used are those that were computed during training by moving average.</span>

<span class="sd">    Note:</span>
<span class="sd">        The backward performs an approximated differentiation that takes into account only the latest mini-batch.</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array of input.</span>
<span class="sd">        mean(~nnabla.Variable): N-D array of running mean (modified during forward execution).</span>
<span class="sd">        t(~nnabla.Variable): Scalar of num of iteration of running mean (modified during forward execution).</span>
<span class="sd">        base_axis(int): Base axis of Mean Subtraction operation. Dimensions up to base_axis is treated as sample dimension.</span>
<span class="sd">            [default=``1``]</span>
<span class="sd">        update_running_mean(bool): Update running mean during forward execution.</span>
<span class="sd">            [default=``True``]</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.mean_subtraction``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">mean_subtraction</span> <span class="k">as</span> <span class="n">mean_subtraction_base</span>
    <span class="k">return</span> <span class="n">mean_subtraction_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>
                                 <span class="n">base_axis</span><span class="o">=</span><span class="n">base_axis</span><span class="p">,</span>
                                 <span class="n">update_running_mean</span><span class="o">=</span><span class="n">update_running_mean</span><span class="p">)</span></div>


<div class="viewcode-block" id="fixed_point_quantize"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.fixed_point_quantize">[docs]</a><span class="k">def</span> <span class="nf">fixed_point_quantize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mi">2</span><span class="o">**-</span><span class="mi">4</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fixed Point Quantize</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        sign (bool): Indicate the signed number or the unsigned number. Default is true.</span>
<span class="sd">        n (int): Bit width used. Note that `sign` consumes one bit. :math:`n-1` is used for number representation in `signed` case.   </span>
<span class="sd">        delta (float): Step size.</span>
<span class="sd">        quantize (bool): If true, quantize input, otherwise not.</span>
<span class="sd">        ste_fine_grained (bool): If true, STE is not 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.fixed_point_quantize``.</span>

<span class="sd">    In the forward pass, </span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{equation}</span>
<span class="sd">            q_i= \left\{</span>
<span class="sd">               \begin{array}{ll}</span>
<span class="sd">                    max &amp; if \ \ \ x_i &gt; max \\</span>
<span class="sd">                    sign(x_i) \times floor(|x_i| \delta^{-1} + 2^{-1}) \times \delta &amp; if \ \ min \le x_i \le max \\</span>
<span class="sd">                    min &amp; if \ \ x_i &lt; min \\</span>
<span class="sd">               \end{array} \right.,</span>
<span class="sd">        \end{equation}</span>

<span class="sd">    where :math:`\delta` is the step size, </span>
<span class="sd">    :math:`(min, max) :=(- (2^{n-1} - 1)\delta, (2^{n-1} - 1)\delta)` if :math:`sign` is true, </span>
<span class="sd">    :math:`(min, max) := (0, (2^n - 1) \delta)` otherwise, and  </span>
<span class="sd">    :math:`n` is the total bit-width used.</span>

<span class="sd">    In the backward pass when using `ste_fine_grained` as false,  </span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{equation}</span>
<span class="sd">            \frac{\partial q_i}{\partial x_i} = 1.</span>
<span class="sd">        \end{equation}</span>

<span class="sd">    In the backward pass when using `ste_fine_grained` as true,  </span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{equation}</span>
<span class="sd">            \frac{\partial q_i}{\partial x_i}= \left\{</span>
<span class="sd">                    \begin{array}{ll}</span>
<span class="sd">                                0 &amp; if \ \ \ x_i &gt; max \\</span>
<span class="sd">                            1 &amp; if \ \ min \le x_i \le max \\</span>
<span class="sd">                            0 &amp; if \ \ x_i &lt; min \\</span>
<span class="sd">                    \end{array} \right..</span>
<span class="sd">        \end{equation}</span>

<span class="sd">    .. note::</span>

<span class="sd">        Quantized values are stored as floating point number, since this function is for simulation purposes.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">fixed_point_quantize</span> <span class="k">as</span> <span class="n">fixed_point_quantize_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">quantize</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">fixed_point_quantize_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="pow2_quantize"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.pow2_quantize">[docs]</a><span class="k">def</span> <span class="nf">pow2_quantize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pow2 Quantize</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        sign (bool): Indicate the signed number or the unsigned number. Default is true.</span>
<span class="sd">        with_zero (bool): Indicate using zero as a quantized value. Default is true. Note that `zero` consumes one bit.</span>
<span class="sd">        n (int): Bit width used. Note that `sign` consumes one bit. :math:`n-1` is used for number representation in `signed` case. Default is 8.   </span>
<span class="sd">        m (int): :math:`2^m` is the upper bound of the dynamic range and :math:`-2^m` is the lower bound, :math:`m \in \mathcal{Z}`. Default is 1.</span>
<span class="sd">        quantize (bool): If true, quantize input, otherwise not.</span>
<span class="sd">        ste_fine_grained (bool): If true, STE is not 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    See Also:</span>
<span class="sd">        ``nnabla.function_bases.pow2_quantize``.</span>

<span class="sd">    In the forward pass of `signed` case,  </span>

<span class="sd">    .. math::</span>

<span class="sd">       q_i= \left\{</span>
<span class="sd">           \begin{array}{ll}</span>
<span class="sd">                        max_{+} &amp; if \ \ \overline{q_i} &gt; max_{+} \\</span>
<span class="sd">                        \overline{q_i} &amp; if \ \ min_{+} \le \overline{q_i} \le max_{+} \\</span>
<span class="sd">                  min_{+} &amp; if \ \ 0 \le \overline{q_i} &lt; min_{+} \\</span>
<span class="sd">                  min_{-} &amp; if \ \ min_{-} &lt; \overline{q_i} &lt; 0 \\</span>
<span class="sd">                  \overline{q_i} &amp; if \ \ max_{-} \le \overline{q_i} \le min_{-}\\</span>
<span class="sd">                max_{-} &amp; if \ \ \overline{q_i} &lt; max_{-} \\</span>
<span class="sd">           \end{array} \right.,</span>

<span class="sd">    where </span>

<span class="sd">    .. math::</span>

<span class="sd">       &amp;&amp; max_{+} = 2^{m}, min_{+} = 2^{m - (2^{n-1} - 1)},\\  </span>
<span class="sd">       &amp;&amp; max_{-} = -2^{m}, min_{-} = -2^{m - (2^{n-1} - 1)},\\</span>
<span class="sd">       &amp;&amp; \overline{q_i} = sign(x_i) \times 2^{round(\log_2 |x_i|)}.</span>

<span class="sd">    This quantization uses the geometric mean between two power-of-two numbers </span>
<span class="sd">    as quantization threshold.   </span>

<span class="sd">    In the forward pass of `unsigned` case,  </span>

<span class="sd">    .. math::</span>

<span class="sd">       q_i= \left\{</span>
<span class="sd">           \begin{array}{ll}</span>
<span class="sd">                        max &amp; if \ \ \overline{q_i} &gt; max \\</span>
<span class="sd">                        \overline{q_i} &amp; if \ \ min \le \overline{q_i} \le max \\</span>
<span class="sd">                  min &amp; if \ \ 0 &lt; \overline{q_i} &lt; min \\</span>
<span class="sd">           \end{array} \right.,</span>

<span class="sd">    where </span>

<span class="sd">    .. math::</span>

<span class="sd">       &amp;&amp; max = 2^{m}, min = 2^{m - (2^{n} - 1)},\\  </span>
<span class="sd">       &amp;&amp; \overline{q_i} = 2^{int(\log_2 |x_i|)}.</span>


<span class="sd">    When using `with_zero` as true, a pruning threshold is used to round an input to </span>
<span class="sd">    0 or :math:`min`. The pruning threshold is defined in this function as the following, </span>

<span class="sd">    .. math::</span>

<span class="sd">       pruning\ threshold = min \times 2^{-\frac{1}{2}}.</span>

<span class="sd">    If an absolute value of the input is lesser than this value, the input is rounded to 0, otherwise :math:`min`. </span>

<span class="sd">    In the backward pass when using ste_fine_grained as false,</span>

<span class="sd">    .. math::</span>

<span class="sd">       \frac{\partial q_i}{\partial x_i} = 1.</span>

<span class="sd">    In the backward pass when using ste_fine_grained as true,</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial q_i}{\partial x_i}= \left\{</span>
<span class="sd">           \begin{array}{ll}</span>
<span class="sd">                    0 &amp; if \ \ \overline{q_i} &gt; max_{+} \\</span>
<span class="sd">                        1 &amp; if \ \ otherwise \\</span>
<span class="sd">                0 &amp; if \ \ \overline{q_i} &lt; max_{-} \\</span>
<span class="sd">           \end{array} \right.. </span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">pow2_quantize</span> <span class="k">as</span> <span class="n">pow2_quantize_base</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">quantize</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">pow2_quantize_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">with_zero</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">ste_fine_grained</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="clip_by_value"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.clip_by_value">[docs]</a><span class="k">def</span> <span class="nf">clip_by_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Clip inputs by values.</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = \begin{cases}</span>
<span class="sd">                max &amp; (x &gt; max) \\</span>
<span class="sd">                x &amp; (otherwise) \\</span>
<span class="sd">                min &amp; (x &lt; min)</span>
<span class="sd">            \end{cases}.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        min (Variable): A min variable by which `x` is clipped. Note that the shape of `min` must be the same as `x`&#39;s.</span>
<span class="sd">        max (Variable): A max variable by which `x` is clipped. Note that the shape of `max` must be the same as `x`&#39;s</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">maximum2</span> <span class="k">as</span> <span class="n">maximum2_base</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">minimum2</span> <span class="k">as</span> <span class="n">minimum2_base</span>
    <span class="k">return</span> <span class="n">minimum2_base</span><span class="p">(</span><span class="n">maximum2_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="p">),</span> <span class="nb">max</span><span class="p">)</span></div>


<div class="viewcode-block" id="clip_by_norm"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.clip_by_norm">[docs]</a><span class="k">def</span> <span class="nf">clip_by_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clip inputs by its L2 norm when the L2 norm is larger than the threshold value (defined by clip_norm).</span>
<span class="sd">    If it is less than the threshold, inputs are not modified. If it is applied, the operation is represented as</span>

<span class="sd">    .. math::</span>
<span class="sd">      y = N \times \frac{x}{\|x\|_2}.</span>

<span class="sd">    where :math:`x` is the input, :math:`y` is the output,</span>
<span class="sd">    and :math:`N` is `clip_norm`. this is the case that `axes` is not set.</span>
<span class="sd">    When `axes` is set, the norm is computed over `axes`.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Variable): An input variable.</span>
<span class="sd">        clip_norm (`Variable` or `float`): An input scalar variable or float value. Must be positive.</span>
<span class="sd">        axis (None, int or tuple of ints): Axis or axes along which the reduction is performed. Passing the default value `None` will reduce all dimensions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">pow_scalar</span> <span class="k">as</span> <span class="n">pow_scalar_base</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">maximum2</span> <span class="k">as</span> <span class="n">maximum2_base</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">maximum_scalar</span> <span class="k">as</span> <span class="n">maximum_scalar_base</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">sum_base</span>
    <span class="kn">from</span> <span class="nn">._variable</span> <span class="k">import</span> <span class="n">Variable</span> <span class="k">as</span> <span class="n">Variable_base</span>
    <span class="kn">from</span> <span class="nn">._nd_array</span> <span class="k">import</span> <span class="n">NdArray</span> <span class="k">as</span> <span class="n">NdArray_base</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">x_norm</span> <span class="o">=</span> <span class="n">pow_scalar_base</span><span class="p">(</span><span class="n">sum_base</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clip_norm</span><span class="p">,</span> <span class="p">(</span><span class="n">Variable_base</span><span class="p">,</span> <span class="n">NdArray_base</span><span class="p">)):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">clip_norm</span> <span class="o">/</span> <span class="n">maximum2_base</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">clip_norm</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;clip_norm must be positive.&quot;</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">clip_norm</span> <span class="o">/</span> <span class="n">maximum_scalar_base</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span></div>


<div class="viewcode-block" id="interpolate"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.interpolate">[docs]</a><span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Resize an ND array with interpolation.</span>

<span class="sd">    Scaling factors for spatial dimensions are determined by either</span>
<span class="sd">    ``scale`` or ``output_size``.</span>

<span class="sd">    ``nd = len(scale)`` or ``nd = len(output_size)`` determines the number of</span>
<span class="sd">    spatial dimensions, and the last ``nd`` dimensions of the input ``x`` are    </span>
<span class="sd">    considered as the spatial dimensions to be resized.</span>


<span class="sd">    If ``scale`` is given, the ``output_size`` is calculated by</span>
<span class="sd">    ``output_size[i] = floor(scale[i] * x.shape[i - len(scale)])``.</span>

<span class="sd">    Example:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        x_data = np.random.rand(64, 3, 224, 224)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(x_data)</span>

<span class="sd">        # Resize by scales</span>
<span class="sd">        y = F.interpolate(x, scale=(2, 2), mode=&#39;linear&#39;)</span>
<span class="sd">        print(y.shape)  # (64, 3, 448, 448)</span>
<span class="sd">        y.forward()</span>
<span class="sd">        print(y.d)  # Print output</span>

<span class="sd">        # Resize to a size</span>
<span class="sd">        y2 = F.interpolate(x, output_size=(320, 257), mode=&#39;linear&#39;)</span>
<span class="sd">        print(y2.shape)  # (64, 3, 320, 257)</span>
<span class="sd">        y2.forward()</span>
<span class="sd">        print(y2.d)  # Print output</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array with an arbitrary number of dimensions.</span>
<span class="sd">        scale(tuple of ints): Scale factors along axes. The default is</span>
<span class="sd">            ``None``, and if this is omitted, ``output_size`` must be specified.</span>
<span class="sd">        output_size(tuple of ints): The output sizes for axes. If this is</span>
<span class="sd">            given, the scale factors are determined by the output sizes and the</span>
<span class="sd">            input sizes. The default is ``None``, and if this is omitted,</span>
<span class="sd">            ``scale`` must be specified.</span>
<span class="sd">        mode(str): Interpolation mode chosen from (&#39;linear&#39;|&#39;nearest&#39;).</span>
<span class="sd">            The default is &#39;linear&#39;.</span>
<span class="sd">        align_corners(bool): If true, the corner pixels of input and output</span>
<span class="sd">            arrays are aligned, such that the output corner pixels have the</span>
<span class="sd">            same values with the input corner pixels.</span>
<span class="sd">            The default is ``None``, and it becomes ``True`` if mode is</span>
<span class="sd">            &#39;linear&#39;, otherwise ``False``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">interpolate</span> <span class="k">as</span> <span class="n">interpolate_base</span>
    <span class="kn">import</span> <span class="nn">math</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">output_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Either scale or output_size must be given&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">output_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">d</span><span class="p">))</span>
                       <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">):],</span> <span class="n">scale</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">align_corners</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="n">align_corners</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">align_corners</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">interpolate_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">)</span></div>


<div class="viewcode-block" id="sort"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.sort">[docs]</a><span class="k">def</span> <span class="nf">sort</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">only_index</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sorts the elements of `x` along a given `axis` in ascending order</span>
<span class="sd">    by value. A negative `axis` counts from the last dimension of `x`,</span>
<span class="sd">    so the default of -1 sorts along the last dimension. If `reverse`</span>
<span class="sd">    is True, then the elements are soreted in descending order.</span>

<span class="sd">    If `with_index` is True, result is a tuple ``(sorted, indices)``</span>
<span class="sd">    or only ``indices`` if `only_index` is True. Setting `only_index`</span>
<span class="sd">    to True implies that `with_index` is also True.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import nnabla as nn</span>
<span class="sd">        import nnabla.functions as F</span>

<span class="sd">        nn.set_auto_forward(True)</span>
<span class="sd">        x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))</span>

<span class="sd">        sorted = F.sort(x)</span>
<span class="sd">        assert np.allclose(sorted.d, np.sort(x.d))</span>

<span class="sd">        sorted, indices = F.sort(x, with_index=True)</span>
<span class="sd">        assert np.allclose(sorted.d, np.sort(x.d))</span>
<span class="sd">        assert np.all(indices.d == np.argsort(x.d))</span>

<span class="sd">        indices = F.sort(x, only_index=True)</span>
<span class="sd">        assert np.all(indices.d == np.argsort(x.d))</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): N-D array</span>
<span class="sd">        axis(int): Axis along which to sort.</span>
<span class="sd">        reverse(bool): Sort in descending order.</span>
<span class="sd">        with_index(bool): Return sorted values and index.</span>
<span class="sd">        only_index(bool): Return only the sort index.</span>

<span class="sd">    Returns: :obj:`~nnabla.Variable` `sorted` or :obj:`~nnabla.Variable` `indices` or (:obj:`~nnabla.Variable` `sorted`, :obj:`~nnabla.Variable` `indices`)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">sort</span> <span class="k">as</span> <span class="n">sort_base</span>
    <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">with_index</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">only_index</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">sort_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="n">with_index</span><span class="p">,</span> <span class="n">only_index</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="tile"><a class="viewcode-back" href="../../python/api/function.html#nnabla.functions.tile">[docs]</a><span class="k">def</span> <span class="nf">tile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward `x` repeated the number of times given by `reps`. If `reps` is</span>
<span class="sd">    a sequence, the output has dimension of ``d = max(len(reps), x.ndim)`` and</span>
<span class="sd">    either `x` is promoted to be d-dimensional by prepending new axes or `reps`</span>
<span class="sd">    is promoted to x.ndim by prepending 1&#39;s.</span>

<span class="sd">    Args:</span>
<span class="sd">        x(~nnabla.Variable): Input N-D array.</span>
<span class="sd">        reps(int or sequence of int): Repetitions of `x` along each axis.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ~nnabla.Variable: N-D array.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np, nnabla as nn, nnabla.functions as F</span>
<span class="sd">    &gt;&gt;&gt; F.tile(nn.Variable([2, 3], 3).shape    # reps is promoted to [1, 3]</span>
<span class="sd">    (2, 9)</span>
<span class="sd">    &gt;&gt;&gt; F.tile(nn.Variable([3], [2, 3]).shape  # x is promoted to shape (1, 3)</span>
<span class="sd">    (2, 9)</span>
<span class="sd">    &gt;&gt;&gt; nn.set_auto_forward(True)</span>
<span class="sd">    &gt;&gt;&gt; x = nn.Variable.from_numpy_array(np.array([1, 2, 3]))</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, 3).d)</span>
<span class="sd">    [1. 2. 3. 1. 2. 3. 1. 2. 3.]</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, [2, 3]).d)</span>
<span class="sd">    [[1. 2. 3. 1. 2. 3. 1. 2. 3.]</span>
<span class="sd">     [1. 2. 3. 1. 2. 3. 1. 2. 3.]]</span>
<span class="sd">    &gt;&gt;&gt; x = nn.Variable.from_numpy_array(np.array([[1, 3], [2, 4]]))</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, 3).d)</span>
<span class="sd">    [[1. 3. 1. 3. 1. 3.]</span>
<span class="sd">     [2. 4. 2. 4. 2. 4.]]</span>
<span class="sd">    &gt;&gt;&gt; print(F.tile(x, [2, 3]).d)</span>
<span class="sd">    [[1. 3. 1. 3. 1. 3.]</span>
<span class="sd">     [2. 4. 2. 4. 2. 4.]</span>
<span class="sd">     [1. 3. 1. 3. 1. 3.]</span>
<span class="sd">     [2. 4. 2. 4. 2. 4.]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.function_bases</span> <span class="k">import</span> <span class="n">tile</span> <span class="k">as</span> <span class="n">tile_base</span>
    <span class="n">reps</span> <span class="o">=</span> <span class="p">[</span><span class="n">reps</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reps</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">reps</span>
    <span class="k">return</span> <span class="n">tile_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reps</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Sony Corporation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>