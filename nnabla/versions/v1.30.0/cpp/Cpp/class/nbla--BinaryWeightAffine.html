<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>class nbla::BinaryWeightAffine &mdash; Neural Network Libraries 1.30.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="class nbla::BinaryWeightConvolution" href="nbla--BinaryWeightConvolution.html" />
    <link rel="prev" title="class BinaryTanh" href="BinaryTanh.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Neural Network Libraries
          </a>
              <div class="version">
                1.30.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../python.html">Python Package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../cpp.html">C++ API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../installation.html">Build C++ libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../command_line_interface.html">C++ Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../examples.html">C++ API Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../doc.html">C++ API Document</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../cpp_api.html">NNABLA C++ API Document</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../class.html">NNABLA Class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../struct.html">NNABLA Struct</a></li>
<li class="toctree-l4"><a class="reference internal" href="../namespace.html">NNABLA Namespace</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../data_exchange_file_format.html">Data exchange file format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../support_status.html">Support Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Neural Network Libraries</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../cpp.html">C++ API</a> &raquo;</li>
          <li><a href="../../doc.html">C++ API Document</a> &raquo;</li>
          <li><a href="../../cpp_api.html">NNABLA C++ API Document</a> &raquo;</li>
          <li><a href="../class.html">NNABLA Class</a> &raquo;</li>
      <li>class nbla::BinaryWeightAffine</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/cpp/Cpp/class/nbla--BinaryWeightAffine.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="class-nbla-binaryweightaffine">
<h1>class nbla::BinaryWeightAffine<a class="headerlink" href="#class-nbla-binaryweightaffine" title="Permalink to this heading"></a></h1>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4I0EN4nbla18BinaryWeightAffineE">
<span id="_CPPv3I0EN4nbla18BinaryWeightAffineE"></span><span id="_CPPv2I0EN4nbla18BinaryWeightAffineE"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classnbla_1_1BinaryWeightAffine"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">BinaryWeightAffine</span></span></span><span class="w"> </span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="k"><span class="pre">public</span></span><span class="w"> </span><a class="reference internal" href="../namespace/nbla.html#_CPPv44nbla" title="nbla"><span class="n"><span class="pre">nbla</span></span></a><span class="p"><span class="pre">::</span></span><a class="reference internal" href="nbla--BaseFunction.html#_CPPv4IDpEN4nbla12BaseFunctionE" title="nbla::BaseFunction"><span class="n"><span class="pre">BaseFunction</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4I0EN4nbla18BinaryWeightAffineE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Binary weight network version of an affine layer, using deterministic quantization to -1 and 1 (with scaling). </p>
<p><p>Reference: Rastegari, Mohammad, et al. “XNOR-Net: ImageNet Classification Using</p>
<p>Binary Convolutional Neural Networks.” arXiv preprint arXiv:1603.05279 (2016).</p>
</p>
<p>NOTES:</p>
<p>1) if you would like to share weights between some layers, please make sure to share the standard, floating value weights (input parameter #2) and not the binarized weights (input parameter #3)</p>
<p>2) Only after a call to <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function_1ab4008cfbf032b728ded183647516075f"><span class="std std-ref">forward()</span></a> the weights and the binary weights are in sync, not after a call to <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function_1a2062f16de445fc0d1d5fe4ded349933a"><span class="std std-ref">backward()</span></a>. If wanting to store the parameters of the network, remember to call <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function_1ab4008cfbf032b728ded183647516075f"><span class="std std-ref">forward()</span></a> once before doing so, otherwise the weights and the binary weights will not be in sync.</p>
<p><div class="math notranslate nohighlight">
\[ {\mathbf y} = {\mathbf A} {\mathbf x} + {\mathbf b}. \]</div>
</p>
<p>Inputs ( <span class="math notranslate nohighlight">\(B\)</span> is base_axis):<ul class="simple">
<li><p>Input N-D array with shape ( <span class="math notranslate nohighlight">\(M_0 \times ... \times M_{B-1} \times D_B \times ... \times D_N\)</span>). Dimensions before and after base_axis are flattened as if it is a matrix.</p></li>
<li><p>Weight matrix with shape ( <span class="math notranslate nohighlight">\((D_B \times ... \times D_N) \times L\)</span>)</p></li>
<li><p>Binarized weight matrix with shape ( <span class="math notranslate nohighlight">\((D_B \times ... \times D_N) \times L\)</span>)</p></li>
<li><p>(optional) Bias vector ( <span class="math notranslate nohighlight">\(L\)</span>)</p></li>
</ul>
</p>
<p>Outputs:<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((B + 1)\)</span>-D array. ( <span class="math notranslate nohighlight">\( M_0 \times ... \times M_{B-1} \times L \)</span>)</p></li>
</ul>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters</dt>
<dd class="field-odd"><p><strong>T</strong> – Data type for computation. </p>
</dd>
<dt class="field-even">Param base_axis</dt>
<dd class="field-even"><p>Base axis of <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1BinaryConnectAffine"><span class="std std-ref">BinaryConnectAffine</span></a> operation. Dimensions up to base_axis is treated as sample dimension. </p>
</dd>
<dt class="field-odd">Param quantize_zero_to</dt>
<dd class="field-odd"><p>Input value at zero is quantized to this value. </p>
</dd>
</dl>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK4nbla18BinaryWeightAffine4copyEv">
<span id="_CPPv3NK4nbla18BinaryWeightAffine4copyEv"></span><span id="_CPPv2NK4nbla18BinaryWeightAffine4copyEv"></span><span id="nbla::BinaryWeightAffine::copyC"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1ae54a9ab8a140bcce19c5858f357cee2c"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="nbla--Function.html#_CPPv4N4nbla8FunctionE" title="nbla::Function"><span class="n"><span class="pre">Function</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">copy</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK4nbla18BinaryWeightAffine4copyEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Copy another instance of <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Function"><span class="std std-ref">Function</span></a> with the same context. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla18BinaryWeightAffine8in_typesEv">
<span id="_CPPv3N4nbla18BinaryWeightAffine8in_typesEv"></span><span id="_CPPv2N4nbla18BinaryWeightAffine8in_typesEv"></span><span id="nbla::BinaryWeightAffine::in_types"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1a19397b519313d6e4b07c569f03fde8ec"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="../namespace/nbla.html#_CPPv4N4nbla6dtypesE" title="nbla::dtypes"><span class="n"><span class="pre">dtypes</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">in_types</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla18BinaryWeightAffine8in_typesEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get input dtypes. </p>
<p>Last in_type will be used repeatedly if size of in_types is smaller than size of inputs </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla18BinaryWeightAffine9out_typesEv">
<span id="_CPPv3N4nbla18BinaryWeightAffine9out_typesEv"></span><span id="_CPPv2N4nbla18BinaryWeightAffine9out_typesEv"></span><span id="nbla::BinaryWeightAffine::out_types"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1a66d0428d46e181087670ec6628ca78f6"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="../namespace/nbla.html#_CPPv4N4nbla6dtypesE" title="nbla::dtypes"><span class="n"><span class="pre">dtypes</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">out_types</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla18BinaryWeightAffine9out_typesEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get output dtypes. </p>
<p>Last out_type will be used repeatedly if size of out_types is smaller than size of outputs </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla18BinaryWeightAffine10min_inputsEv">
<span id="_CPPv3N4nbla18BinaryWeightAffine10min_inputsEv"></span><span id="_CPPv2N4nbla18BinaryWeightAffine10min_inputsEv"></span><span id="nbla::BinaryWeightAffine::min_inputs"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1a5a3d84ec6afefdd70b5283cc2f0886dc"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">min_inputs</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla18BinaryWeightAffine10min_inputsEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get minimum number of inputs. </p>
<p>This is meant to be used in setup function with in_types which is used to get maximum number of inputs. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla18BinaryWeightAffine11min_outputsEv">
<span id="_CPPv3N4nbla18BinaryWeightAffine11min_outputsEv"></span><span id="_CPPv2N4nbla18BinaryWeightAffine11min_outputsEv"></span><span id="nbla::BinaryWeightAffine::min_outputs"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1a58b5386c846f4abc80e70f579a5976c5"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">min_outputs</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla18BinaryWeightAffine11min_outputsEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get minimum number of outputs. </p>
<p>This is meant to be used in setup function with out_types which is used to get max number of outputs. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla18BinaryWeightAffine4nameEv">
<span id="_CPPv3N4nbla18BinaryWeightAffine4nameEv"></span><span id="_CPPv2N4nbla18BinaryWeightAffine4nameEv"></span><span id="nbla::BinaryWeightAffine::name"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1adecd9d79ce9dd7589d024e9b1a37507e"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">name</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla18BinaryWeightAffine4nameEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get function name in string. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4nbla18BinaryWeightAffine21allowed_array_classesEv">
<span id="_CPPv3N4nbla18BinaryWeightAffine21allowed_array_classesEv"></span><span id="_CPPv2N4nbla18BinaryWeightAffine21allowed_array_classesEv"></span><span id="nbla::BinaryWeightAffine::allowed_array_classes"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1a2c59efd46cb03f2eae0643e21c942876"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">allowed_array_classes</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4nbla18BinaryWeightAffine21allowed_array_classesEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get array classes that are allowed to be specified by <a class="reference internal" href="../namespace/nbla.html#classnbla_1_1Context"><span class="std std-ref">Context</span></a>. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK4nbla18BinaryWeightAffine24grad_depends_output_dataEii">
<span id="_CPPv3NK4nbla18BinaryWeightAffine24grad_depends_output_dataEii"></span><span id="_CPPv2NK4nbla18BinaryWeightAffine24grad_depends_output_dataEii"></span><span id="nbla::BinaryWeightAffine::grad_depends_output_data__i.iC"></span><span class="target" id="classnbla_1_1BinaryWeightAffine_1a965db2667a4af5fc97b8d3ec9970a1d8"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">grad_depends_output_data</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">i</span></span>, <span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">o</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK4nbla18BinaryWeightAffine24grad_depends_output_dataEii" title="Permalink to this definition"></a><br /></dt>
<dd><p>Dependency flag for checking if in-grad depends on out-data. </p>
<p>Checking if i-th input’ gradient computation requires o-th output’s data or not.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If any of inputs requires an output variable data when computing its gradient, this function must be overridden to return appropriate boolean value. Otherwise, backward computation will be incorrect. </p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>i</strong> – <strong>[in]</strong> Input variable index. </p></li>
<li><p><strong>o</strong> – <strong>[in]</strong> Output variable index.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="BinaryTanh.html" class="btn btn-neutral float-left" title="class BinaryTanh" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nbla--BinaryWeightConvolution.html" class="btn btn-neutral float-right" title="class nbla::BinaryWeightConvolution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Sony Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>