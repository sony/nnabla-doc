

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Communicator API &mdash; Neural Network Libraries 1.0.6 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Monitors" href="monitor.html" />
    <link rel="prev" title="Solvers" href="solver.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Neural Network Libraries
          

          
          </a>

          
            
            
              <div class="version">
                1.0.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../python.html">Python Package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../installation.html">Python Package Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial.html">Python API Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../command_line_interface.html">Python Command Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html">Python API Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html">Python API Reference</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="common.html">Common</a></li>
<li class="toctree-l3"><a class="reference internal" href="nd_array.html">NdArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="variable.html">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="function.html">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="parametric_function.html">Parametric Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="solver.html">Solvers</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Communicator API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#communicator-interface">Communicator interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="#list-of-communicators">List of communicators</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="monitor.html">Monitors</a></li>
<li class="toctree-l3"><a class="reference internal" href="utils.html">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="ext.html">Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="experimental.html">Experimental</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../format.html">Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../file_format_converter/file_format_converter.html">File format converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Neural Network Libraries</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../python.html">Python Package</a> &raquo;</li>
        
          <li><a href="../api.html">Python API Reference</a> &raquo;</li>
        
      <li>Communicator API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/python/api/communicator.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="communicator-api">
<h1>Communicator API<a class="headerlink" href="#communicator-api" title="Permalink to this headline">¶</a></h1>
<p>Communicator transfers parameters over the compute graphs.</p>
<span class="target" id="module-nnabla.communicators"></span><p>This is an alias to communicator.py.</p>
<div class="section" id="communicator-interface">
<h2>Communicator interface<a class="headerlink" href="#communicator-interface" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nnabla.communicators.Communicator">
<em class="property">class </em><code class="descclassname">nnabla.communicators.</code><code class="descname">Communicator</code><a class="headerlink" href="#nnabla.communicators.Communicator" title="Permalink to this definition">¶</a></dt>
<dd><p>Communicator interface class.</p>
<p>Communicator exchanges data (e.g., gradient) using MPI-like
collectives. This class is used for the distributed training.</p>
<dl class="method">
<dt id="nnabla.communicators.Communicator.abort">
<code class="descname">abort</code><span class="sig-paren">(</span><em>self</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.abort" title="Permalink to this definition">¶</a></dt>
<dd><p>Terminates MPI execution environment</p>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.add_context_and_parameters">
<code class="descname">add_context_and_parameters</code><span class="sig-paren">(</span><em>self</em>, <em>ctx_param_dict</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.add_context_and_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Add context and parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>ctx_param_dict</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#tuple" title="(in Python v3.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <code class="xref py py-obj docutils literal notranslate"><span class="pre">Context</span></code>, <a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="(in Python v3.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code></a>) – Key of the dictionary is <a class="reference external" href="https://docs.python.org/3.4/library/string.html#module-string" title="(in Python v3.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">string</span></code></a> and value of the
dictionary is <code class="xref py py-obj docutils literal notranslate"><span class="pre">Variable</span></code>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.all_gather">
<code class="descname">all_gather</code><span class="sig-paren">(</span><em>self</em>, <em>ndarray</em>, <em>ndarray_list</em>, <em>string group='world'</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.all_gather" title="Permalink to this definition">¶</a></dt>
<dd><p>All gather over data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ndarray</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – Data to be gathered.</li>
<li><strong>ndarray_list</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – Data to be saved.</li>
<li><strong>group</strong> (<em>string</em>) – Name of a group. This groups is used when the collective is called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>

<span class="c1"># AllGather</span>
<span class="n">comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">y_list</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.all_reduce">
<code class="descname">all_reduce</code><span class="sig-paren">(</span><em>self</em>, <em>data</em>, <em>bool division=False</em>, <em>bool inplace=False</em>, <em>string group='world'</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.all_reduce" title="Permalink to this definition">¶</a></dt>
<dd><p>All reduce over data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code> or list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – </li>
<li><strong>division</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to divide the reduce data by the
number of <cite>contexts</cite> added, or the number of devices.</li>
<li><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to use a packed array. Default is false.
When true, it is memory-efficient but slow. When false,
it is not memory efficient but fast. In both case, one can
get the result in the same memory region.</li>
<li><strong>group</strong> (<em>string</em>) – Name of a group. This groups is used when the collective is called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Data</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># AllReduce</span>
<span class="n">comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.all_reduce_callback">
<code class="descname">all_reduce_callback</code><span class="sig-paren">(</span><em>self</em>, <em>data</em>, <em>size_t pack_size</em>, <em>bool division=False</em>, <em>string group='world'</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.all_reduce_callback" title="Permalink to this definition">¶</a></dt>
<dd><p>All reduce over data.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not support shared parameters (such as RNNs) currently.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code> or list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – </li>
<li><strong>pack_size</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – The number of values contained in the packed data.</li>
<li><strong>division</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to divide the reduce data by the
number of <cite>contexts</cite> added, or the number of devices.</li>
<li><strong>group</strong> (<em>string</em>) – Name of a group. This groups is used when the collective is called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cuda.cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">n_class</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>

<span class="c1"># Data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># Network setting</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">PF</span><span class="o">.</span><span class="n">affine</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
<span class="c1"># AllReduce during backward</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">communicator_callbacks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">all_reduce_callback</span><span class="p">([</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">nn</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.allreduce">
<code class="descname">allreduce</code><span class="sig-paren">(</span><em>self</em>, <em>bool division=False</em>, <em>bool inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.allreduce" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated. See all_reduce, instead.</p>
<p>Allreduce over parameters added.
Currently, <cite>allreduce</cite> is applied to gradient regions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>division</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to divide the reduce data by the
number of <cite>contexts</cite> added, or the number of devices.</li>
<li><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to use a packed array. Default is false.
When true, it is memory-efficient but slow. When false,
it is not memory efficient but fast. In both case, one can
get the result in the same memory region.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.barrier">
<code class="descname">barrier</code><span class="sig-paren">(</span><em>self</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.barrier" title="Permalink to this definition">¶</a></dt>
<dd><p>Blocks until all processes in the communicator have reached this routine.</p>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.bcast">
<code class="descname">bcast</code><span class="sig-paren">(</span><em>self</em>, <em>data</em>, <em>int src</em>, <em>bool inplace=False</em>, <em>string group='world'</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.bcast" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce over data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code> or list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – </li>
<li><strong>src</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – Source rank where the data is broadcasted.</li>
<li><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to use a packed array. Default is false.
When true, it is memory-efficient but slow. When false,
it is not memory efficient but fast. In both case, one can
get the result in the same memory region.</li>
<li><strong>group</strong> (<em>string</em>) – Name of a group. This groups is used when the collective is called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Data</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Bcast</span>
<span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">],</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.clear_context_parameters">
<code class="descname">clear_context_parameters</code><span class="sig-paren">(</span><em>self</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.clear_context_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear all registered contexts and parameters.</p>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.find_group">
<code class="descname">find_group</code><span class="sig-paren">(</span><em>self</em>, <em>group</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.find_group" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the list of ranks in the group. If the group does not exist,
the empty list is returned.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#str" title="(in Python v3.4)"><em>str</em></a>) – Name of the group.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">List of ranks (<cite>int</cite>).</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">ranks (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#list" title="(in Python v3.4)">list</a>)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.init">
<code class="descname">init</code><span class="sig-paren">(</span><em>self</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a communicator.</p>
<p>Initall or initrank, depending multi-threads or multi-processes.
This function <em>MUST</em> be called after all parameters communicated
are added by <cite>add_context_and_parameters</cite>.</p>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.list_groups">
<code class="descname">list_groups</code><span class="sig-paren">(</span><em>self</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.list_groups" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Groups (<cite>str</cite>) of name to ranks (<cite>list</cite>).</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">groups (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="(in Python v3.4)">dict</a>)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nnabla.communicators.Communicator.local_rank">
<code class="descname">local_rank</code><a class="headerlink" href="#nnabla.communicators.Communicator.local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Get local rank of communicator.</p>
</dd></dl>

<dl class="attribute">
<dt id="nnabla.communicators.Communicator.name">
<code class="descname">name</code><a class="headerlink" href="#nnabla.communicators.Communicator.name" title="Permalink to this definition">¶</a></dt>
<dd><p>Get communicator name.</p>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.new_group">
<code class="descname">new_group</code><span class="sig-paren">(</span><em>self</em>, <em>name_ranks</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.new_group" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>name_ranks</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#tuple" title="(in Python v3.4)"><em>tuple</em></a>) – Tuple of name (<cite>str</cite>) and ranks (<cite>list</cite>).</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">group name (str)</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># New group</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="s2">&quot;node0&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="nnabla.communicators.Communicator.rank">
<code class="descname">rank</code><a class="headerlink" href="#nnabla.communicators.Communicator.rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Get rank of communicator.</p>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.reduce">
<code class="descname">reduce</code><span class="sig-paren">(</span><em>self</em>, <em>data</em>, <em>int dst</em>, <em>bool division=False</em>, <em>bool inplace=False</em>, <em>string group='world'</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.reduce" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce over data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code> or list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – </li>
<li><strong>dst</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – Destination rank where the result is saved.</li>
<li><strong>division</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to divide the reduce data by the
number of <cite>contexts</cite> added, or the number of devices.</li>
<li><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – Flag to use a packed array. Default is false.
When true, it is memory-efficient but slow. When false,
it is not memory efficient but fast. In both case, one can
get the result in the same memory region.</li>
<li><strong>group</strong> (<em>string</em>) – Name of a group. This groups is used when the collective is called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Data</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Reduce</span>
<span class="n">comm</span><span class="o">.</span><span class="n">reduce</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">],</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nnabla.communicators.Communicator.reduce_scatter">
<code class="descname">reduce_scatter</code><span class="sig-paren">(</span><em>self</em>, <em>ndarray_list</em>, <em>ndarray</em>, <em>bool division=False</em>, <em>string group='world'</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.Communicator.reduce_scatter" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce scatter over data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ndarray_list</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – Data to be saved.</li>
<li><strong>ndarray</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">NdArray</span></code>) – Data to be gathered.</li>
<li><strong>group</strong> (<em>string</em>) – Name of a group. This groups is used when the collective is called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># ReduceScatter</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="nnabla.communicators.Communicator.size">
<code class="descname">size</code><a class="headerlink" href="#nnabla.communicators.Communicator.size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get size of communicator.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="list-of-communicators">
<h2>List of communicators<a class="headerlink" href="#list-of-communicators" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nnabla.communicators.DataParalellCommunicator">
<code class="descclassname">nnabla.communicators.</code><code class="descname">DataParalellCommunicator</code><span class="sig-paren">(</span><em>CContext ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.DataParalellCommunicator" title="Permalink to this definition">¶</a></dt>
<dd><p>Data Parallel Communicator for Distributed Training.</p>
<p>This class does collectives in a single-process in a machine.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>context</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Context</span></code>) – context used in this communicator.</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-thread data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Networks and Solvers building comes above</span>
<span class="kn">import</span> <span class="nn">nnabla.communicators</span> <span class="kn">as</span> <span class="nn">C</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">DataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>

<span class="c1"># Add contexts and parameters to the communicator</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_devices</span><span class="p">):</span>
    <span class="n">device_scope_name</span> <span class="o">=</span> <span class="s2">&quot;device{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">nn</span><span class="o">.</span><span class="n">parameter_scope</span><span class="p">(</span><span class="n">device_scope_name</span><span class="p">):</span>
        <span class="n">ctx</span> <span class="o">=</span> <span class="n">ctxs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="n">comm</span><span class="o">.</span><span class="n">add_context_and_parameters</span><span class="p">((</span><span class="n">ctx</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">itr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_itr</span><span class="p">):</span>

    <span class="c1"># Forward, zerograd, backward</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_devices</span><span class="p">):</span>
        <span class="n">losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
        <span class="n">solvers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Allreduce</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">allreduce</span><span class="p">()</span>

    <span class="c1"># Update</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_devices</span><span class="p">):</span>
        <span class="n">solvers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="nnabla.communicators.MultiProcessDataParalellCommunicator">
<code class="descclassname">nnabla.communicators.</code><code class="descname">MultiProcessDataParalellCommunicator</code><span class="sig-paren">(</span><em>CContext ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#nnabla.communicators.MultiProcessDataParalellCommunicator" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi Process Data Parallel Communicator for Distributed Training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>context</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Context</span></code>) – context used in this communicator.</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>In case of the multi-process data parallel distributed training,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Communicator and Context</span>
<span class="n">extension_module</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">get_extension_context</span><span class="p">(</span><span class="n">extension_module</span><span class="p">)</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">MultiProcessDataParalellCommunicator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">n_devices</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">size</span>
<span class="n">mpi_rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">rank</span>
<span class="n">device_id</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">local_rank</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">device_id</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">set_default_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>

<span class="c1"># Network and Solver created here</span>

<span class="o">...</span>


<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">itr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_itr</span><span class="p">):</span>
    <span class="c1"># Forward, zerograd, backward</span>
    <span class="n">losse</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Allreduce</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">allreduce</span><span class="p">([</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">nn</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

    <span class="c1"># Update</span>
    <span class="n">solver</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="monitor.html" class="btn btn-neutral float-right" title="Monitors" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="solver.html" class="btn btn-neutral float-left" title="Solvers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Sony Corporation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>